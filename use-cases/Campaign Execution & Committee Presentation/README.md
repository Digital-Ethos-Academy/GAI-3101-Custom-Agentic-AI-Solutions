# Campaign Execution & Committee Presentation ‚Äì Agentic AI Implementation

## Overview

This folder contains a complete agentic AI solution for automating the campaign execution and committee presentation workflow. The solution demonstrates how specialized AI agents can orchestrate the end-to-end process of validating campaign data, preparing analytics, and generating standardized presentation decks for management committees.

**Business Impact:**
- **Lead time reduction**: 40 hours ‚Üí 16.5 hours (~59% improvement)
- **Manual effort savings**: 12 hours ‚Üí 4.5 hours per campaign (~62.5% reduction)
- **Annual cost savings**: $108,000 (for 20 campaigns/month at $60/hour analyst rate)

---

## üìÅ Folder Contents

### Files

| File | Purpose |
|------|---------|
| **campaign-agents-implementation.ipynb** | Comprehensive Jupyter notebook demonstrating progressive implementation of all 12 agentic AI lab techniques applied to the campaign workflow |
| **value-stream-overview.md** | Detailed value stream mapping including current/future-state process analysis, timeline reduction, and ROI calculations |
| **README.md** | This file ‚Äì comprehensive guide to the use case and implementation |

---

## üéØ Problem Statement

**Current Workflow Challenges:**
- Manual data validation and input checking (120 min/campaign)
- Time-consuming ETL and data preparation orchestration (180 min/campaign)
- Manual dashboard monitoring and setup (90 min/campaign)
- Labor-intensive analytical review and KPI validation (120 min/campaign)
- Email composition and status communication (30 min/campaign)
- PowerPoint deck assembly and formatting (180 min/campaign)

**Total Current Lead Time:** 40 hours per campaign (5 business days)

**Stakeholders:** Marketing teams, Business analysts, Management committees

---

## üîÑ Value Stream Process

### Process Steps (6 Steps)

1. **Input Capture & Validation** (PT: 120 min ‚Üí 30 min)
   - Receive campaign brief and input data
   - Cross-check mandatory fields
   - Validate IDs against reference tables
   - Flag data quality issues for clarification

2. **Data Preparation & Evaluation** (PT: 180 min ‚Üí 60 min)
   - Load raw data into BigQuery
   - Compute aggregates and KPI metrics
   - Apply evaluation rules and thresholds
   - Flag anomalies for investigation

3. **Monitoring & Tracking Setup** (PT: 90 min ‚Üí 45 min)
   - Setup/update BigQuery monitoring views
   - Configure rolling update schedules
   - Publish tracking extracts to Cloud Storage
   - Distribute reference files

4. **Analytical Review** (PT: 120 min ‚Üí 60 min)
   - Validate Looker dashboards and KPIs
   - Investigate reported anomalies
   - Generate first-pass insight summaries
   - Document analytical findings

5. **Availability Confirmation** (PT: 30 min ‚Üí 15 min)
   - Compose readiness status email
   - Aggregate Looker dashboard links
   - Propose communication wording
   - Send confirmation to committee

6. **PPT Assembly** (PT: 180 min ‚Üí 60 min)
   - Export charts from Looker
   - Build standardized presentation slides
   - Format layouts per template
   - Save and distribute PowerPoint deck

### Data & System Architecture

```
Marketing/Business Request
         ‚Üì
    Email, Google Sheets
         ‚Üì
    Campaign Analyst
         ‚Üì
    BigQuery (Data Warehouse)
         ‚Üì
    Looker Dashboards
         ‚Üì
    SharePoint / Cloud Storage
         ‚Üì
    Management Committee
    (PowerPoint + Email Confirmation)
```

**Key Systems:**
- **Data Warehouse:** Google BigQuery
- **Analytics:** Looker dashboards
- **Storage:** Cloud Storage, SharePoint
- **Communication:** Email, Looker links

---

## ü§ñ Agentic AI Implementation

### Notebook Structure

The `campaign-agents-implementation.ipynb` notebook progressively demonstrates all 12 lab techniques from the GAI-3101 course, applied to this use case:

#### Part 1: Environment Setup
- Package installation (OpenAI, AutoGen, LangGraph, LangChain)
- API configuration and client initialization
- Sample campaign data for testing

#### Part 2: Foundation ‚Äì Simple Python Agent (Lab 1)
- Base `Agent` class with `_select_action()` and `act()` methods
- 6 specialized campaign agents:
  - `ValidationAgent`: Input validation and data quality checks
  - `DataPreparationAgent`: ETL orchestration and metrics computation
  - `MonitoringAgent`: Monitoring view setup and updates
  - `AnalysisAgent`: KPI validation and insight generation
  - `SchedulingAgent`: Calendar availability checking
  - `PresentationAgent`: PowerPoint slide generation

#### Part 3: Multi-Agent Communication (Lab 2)
- AutoGen `RoundRobinGroupChat` for sequential agent communication
- Workflow: Validator ‚Üí Data Preparer ‚Üí Analyzer ‚Üí Scheduler ‚Üí Presenter
- Message passing and state propagation between agents

#### Part 4: Deliberative Agent with LangGraph (Lab 4)
- `StateGraph` workflow orchestration
- Workflow nodes: planner ‚Üí validator ‚Üí preparer ‚Üí analyzer ‚Üí presenter ‚Üí finalizer
- Conditional routing and error handling
- Demonstrates structured decision-making with LLM integration

#### Part 5: Observation & Action Tools (Labs 6-7)
Implements real-world tool integrations:

**Observation Tools (Data retrieval):**
- `query_bigquery()`: Execute analytics queries on campaign data
- `check_looker_dashboard()`: Fetch dashboard metadata and insights
- `get_stakeholder_calendars()`: Check availability for scheduling

**Action Tools (Execution):**
- `create_ppt_file()`: Generate PowerPoint slides
- `send_email()`: Dispatch status confirmations
- `schedule_meeting()`: Reserve committee presentation time
- `upload_to_sharepoint()`: Distribute tracking files

#### Part 6: Rule-Based Reasoning (Lab 9)
- `RuleBasedValidator` with 6 deterministic validation rules:
  - `required_fields`: Check mandatory data presence
  - `budget_validation`: Verify budget thresholds and ranges
  - `date_validation`: Validate date formats and logical sequences
  - `conversion_sanity`: Check conversion rate bounds (0-100%)
  - `click_sanity`: Verify click counts align with impressions
  - `positive_values`: Ensure all metrics are non-negative
- Implements early error detection without LLM calls

#### Part 7: Hierarchical Planning (Lab 8)
- `HierarchicalPlanner` for complex task decomposition
- Task dependency mapping (CAMPAIGN_TASKS, TASK_DEPENDENCIES)
- Agent assignment strategy (AGENT_ASSIGNMENTS)
- Enables parallel execution where dependencies allow

#### Part 8: Error Recovery (Lab 12)
- `@with_retry` decorator with exponential backoff
- `CircuitBreaker` pattern for fault tolerance
- `ResilientAgent` class wrapping agents with recovery logic
- Automatic retry on transient failures
- Graceful degradation on permanent failures

#### Part 9: Complete End-to-End System (Lab 11)
- `CampaignProcessingSystem` integrating all components
- Orchestrates entire workflow from input to output
- Combines all 12 techniques in unified system
- Production-ready error handling and logging

### Lab Technique Mappings

| Lab | Technique | Implementation | Use Case Application |
|-----|-----------|-----------------|----------------------|
| Lab 1 | Simple Python Agent | Base `Agent` class with action selection | Foundation for all agents |
| Lab 2 | Round Robin Communication | AutoGen `RoundRobinGroupChat` | Multi-agent campaign workflow coordination |
| Lab 3 | Reactive Agent | *(Applied in monitoring)* | Real-time anomaly detection |
| Lab 4 | Deliberative Agent | LangGraph `StateGraph` | Complex workflow decision-making |
| Lab 5 | Long-Term Memory | *(Applied in state persistence)* | Campaign execution history tracking |
| Lab 6 | Observation Tools | BigQuery, Looker, Calendar APIs | Data retrieval for analysis |
| Lab 7 | Action Tools | PowerPoint, Email, SharePoint APIs | Execution and communication |
| Lab 8 | Hierarchical Planning | `HierarchicalPlanner` with dependencies | Task decomposition and sequencing |
| Lab 9 | Rule-Based Reasoning | `RuleBasedValidator` with 6 rules | Data quality validation |
| Lab 10 | Robustness Evaluation | *(Applied in testing)* | Agent behavior validation |
| Lab 11 | Personal Assistant | `CampaignProcessingSystem` | Unified end-to-end orchestration |
| Lab 12 | Error Recovery | `@with_retry`, `CircuitBreaker` | Resilient workflow execution |

---

## üìä Key Metrics & ROI

### Current vs. Future State

**Per Campaign Timeline:**

| Metric | Current | Future | Improvement |
|--------|---------|--------|-------------|
| Processing Time | 12 hours | 4.5 hours | -62.5% |
| Wait/Queue Time | 28 hours | 12 hours | -57% |
| Total Lead Time | 40 hours | 16.5 hours | -59% |
| Manual Effort | 12 hours | 4.5 hours | 7.5 hours saved |

**Annual Impact (20 campaigns/month):**

| Metric | Value |
|--------|-------|
| Monthly Hours Saved | 150 hours |
| Monthly Cost Savings | $9,000 |
| Annual Cost Savings | $108,000 |
| Implementation Cost (Year 1) | $120,000 |
| Year 1 Net Benefit | -$12,000 (breakeven) |
| Year 2+ Annual Benefit | $68,000/year |

**5-Year ROI:** $68,000 √ó 4 years + $108,000 Year 1 savings - $120,000 Year 1 cost = $340,000 cumulative

---

## üöÄ Getting Started

### Prerequisites

- Python 3.9+
- Jupyter Notebook or JupyterLab
- OpenAI API key
- Google Cloud credentials (for BigQuery, Looker, etc.)
- Optional: AutoGen, LangGraph, LangChain packages

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/Digital-Ethos-Academy/GAI-3101-Custom-Agentic-AI-Solutions.git
   cd "use-cases/Campaign Execution & Committee Presentation"
   ```

2. **Install dependencies:**
   ```bash
   pip install -r ../../requirements.txt
   ```
   Or install packages individually:
   ```bash
   pip install openai autogen langchain langgraph google-cloud-bigquery python-pptx
   ```

3. **Set up credentials:**
   ```bash
   export OPENAI_API_KEY="your-api-key-here"
   export GOOGLE_APPLICATION_CREDENTIALS="path-to-gcp-credentials.json"
   ```

4. **Open the notebook:**
   ```bash
   jupyter notebook campaign-agents-implementation.ipynb
   ```

### Running the Notebook

Follow the notebook cells sequentially:

1. **Part 1** ‚Äì Environment setup and imports
2. **Part 2** ‚Äì Initialize specialized agents
3. **Part 3** ‚Äì Test multi-agent communication
4. **Part 4** ‚Äì Run LangGraph workflow
5. **Part 5** ‚Äì Observe tool integration examples
6. **Part 6** ‚Äì Test rule-based validation
7. **Part 7** ‚Äì Execute hierarchical planning
8. **Part 8** ‚Äì Demonstrate error recovery
9. **Part 9** ‚Äì Run complete end-to-end system

Each section includes:
- Explanation of technique and use case application
- Implementation code with comments
- Example outputs and results
- Key takeaways for production deployment

---

## üìö Technical Architecture

### Agent Types & Responsibilities

| Agent | Responsible For | Tools Used |
|-------|-----------------|-----------|
| **ValidationAgent** | Input validation, data quality | Rule-based validator |
| **DataPreparationAgent** | ETL, metrics computation | BigQuery SQL orchestration |
| **MonitoringAgent** | Dashboard setup, tracking | Looker API, Cloud Storage |
| **AnalysisAgent** | KPI review, insights | Looker dashboards, BigQuery |
| **SchedulingAgent** | Calendar coordination | Google Calendar API |
| **PresentationAgent** | Deck generation | PowerPoint automation |

### Workflow Orchestration

```
Input Campaign Data
        ‚Üì
   ValidationAgent (Rule-based checks)
        ‚Üì
   DataPreparationAgent (ETL pipeline)
        ‚Üì
   MonitoringAgent (Setup tracking)
        ‚Üì
   AnalysisAgent (KPI validation)
        ‚Üì
   SchedulingAgent (Committee availability)
        ‚Üì
   PresentationAgent (Deck generation)
        ‚Üì
   Output: PowerPoint + Email
```

### Error Handling & Resilience

- **Retry Logic:** Exponential backoff for transient failures
- **Circuit Breaker:** Prevent cascading failures
- **Graceful Degradation:** Continue with available data
- **Logging:** Comprehensive audit trail for debugging

---

## üîß Customization & Extension

### Adding New Agents

1. Create a new class inheriting from `Agent`
2. Implement `_select_action()` and `act()` methods
3. Define custom tools for the agent
4. Add to `CampaignProcessingSystem` orchestration

### Adding New Tools

1. Define observation or action tool function
2. Add docstring with input/output schema
3. Wrap with error handling and logging
4. Register with agent classes that need it

### Modifying Validation Rules

Edit the `RuleBasedValidator` class in Part 6:
- Add new rule methods for custom validation
- Adjust thresholds based on business requirements
- Integrate domain-specific constraints

### Configuring for Production

- Replace mock tools with real API integrations
- Configure authentication for Google Cloud, SharePoint
- Set up logging and monitoring
- Implement cost tracking for agent operations
- Schedule recurring execution via Cloud Scheduler

---

## üìñ Additional Resources

### Within This Repository

- **[value-stream-overview.md](./value-stream-overview.md)** ‚Äì Detailed VSM with current/future timelines and ROI
- **[../../support-materials/course-materials/GAI-3101-LabGuide.pdf](../../support-materials/course-materials/GAI-3101-LabGuide.pdf)** ‚Äì Complete lab guide covering all 12 techniques
- **[../../support-materials/labfiles/](../../support-materials/labfiles/)** ‚Äì Individual lab solution notebooks

### External References

- [LangGraph Documentation](https://python.langchain.com/docs/langgraph/)
- [AutoGen Documentation](https://microsoft.github.io/autogen/)
- [Google BigQuery Documentation](https://cloud.google.com/bigquery/docs)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)

---

## üéì Learning Outcomes

After working through this implementation, you will understand:

1. ‚úÖ How to design and build simple, deliberative, and reactive agents
2. ‚úÖ Multi-agent communication patterns and orchestration strategies
3. ‚úÖ Tool integration for observation (data retrieval) and action (execution)
4. ‚úÖ Rule-based reasoning for deterministic validation
5. ‚úÖ Hierarchical planning for complex workflow decomposition
6. ‚úÖ Error recovery and resilience patterns
7. ‚úÖ End-to-end system design for business automation
8. ‚úÖ Practical business ROI quantification and impact measurement

---

## üìù Implementation Checklist

For production deployment, ensure:

- [ ] All API credentials are securely configured
- [ ] Error handling and logging are in place
- [ ] Agents are tested with production-like data volumes
- [ ] Monitoring and alerting are configured
- [ ] Backup and recovery procedures are documented
- [ ] User acceptance testing (UAT) is completed
- [ ] Stakeholder communication plan is prepared
- [ ] Training materials for analysts are created
- [ ] Performance metrics are tracked monthly
- [ ] Cost monitoring is set up for cloud resources

---

## ü§ù Support & Feedback

For questions, issues, or improvements:

1. Review the [GAI-3101 Course Materials](../../support-materials/course-materials/)
2. Check the individual [Lab Solution Notebooks](../../support-materials/labfiles/)
3. Refer to the [VSM Guide](../../support-materials/guides/vsm-guide.md)
4. Consult framework documentation (LangGraph, AutoGen)

---

## üìÑ Document Information

- **Version:** 1.0
- **Last Updated:** November 2025
- **Owner:** Campaign Analytics & AI Engineering
- **Status:** Production Ready
- **Notebook Commit:** 746319f

---

## License

This implementation is part of the GAI-3101 Custom Agentic AI Solutions curriculum. Use and modify according to your organization's needs.
