{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Introducing Single Agents with LangGraph - SOLUTIONS\n",
        "\n",
        "This notebook contains the complete solution for the Challenge: Add User Preferences."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "In this lab, you'll build your first single-agent system using LangGraph. This agent will:\n",
        "\n",
        "- **Remember conversations** across multiple interactions\n",
        "- **Maintain context** using LangGraph's state management\n",
        "- **Persist history** with checkpointers\n",
        "- **Handle multiple users** through thread IDs\n",
        "\n",
        "### What is LangGraph?\n",
        "\n",
        "LangGraph is a framework for building stateful, multi-actor applications with LLMs. It extends LangChain with:\n",
        "\n",
        "1. **StateGraph**: Directed graph of nodes (functions) and edges (control flow)\n",
        "2. **Checkpointing**: Automatic state persistence\n",
        "3. **Streaming**: Real-time output as the graph executes\n",
        "4. **Thread-based sessions**: Isolated conversation histories\n",
        "\n",
        "### The Scenario\n",
        "\n",
        "You'll build a customer support chatbot that:\n",
        "- Answers questions about a fictional product (\"SuperWidget\")\n",
        "- Remembers what the user asked before\n",
        "- Can be reset to start fresh conversations\n",
        "- Supports multiple concurrent users via thread IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-2",
      "metadata": {},
      "source": [
        "## Setup and Installation\n",
        "\n",
        "Install LangGraph 1.0+ and LangChain 1.0+:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cell-3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langgraph langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cell-4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Environment configured\n"
          ]
        }
      ],
      "source": [
        "from typing import Annotated, TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# API key setup\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "print(\"✓ Environment configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-5",
      "metadata": {},
      "source": [
        "## Step 1: Define the Agent's State\n",
        "\n",
        "In LangGraph, **state** is the data that flows through your graph. We use a `TypedDict` to define what data the agent tracks.\n",
        "\n",
        "For a conversational agent, we need:\n",
        "- **messages**: The conversation history\n",
        "\n",
        "The `Annotated[list, add_messages]` tells LangGraph to **append** new messages rather than replacing the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cell-6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ State defined\n",
            "  - messages: list (appends new messages)\n"
          ]
        }
      ],
      "source": [
        "class State(TypedDict):\n",
        "    \"\"\"State for customer support chatbot.\"\"\"\n",
        "    messages: Annotated[list, add_messages]  # Conversation history\n",
        "\n",
        "print(\"✓ State defined\")\n",
        "print(\"  - messages: list (appends new messages)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {},
      "source": [
        "## Step 2: Create the Agent Node\n",
        "\n",
        "A **node** in LangGraph is a Python function that:\n",
        "1. Takes the current state as input\n",
        "2. Does some work (like calling an LLM)\n",
        "3. Returns a dictionary with state updates\n",
        "\n",
        "Our `chatbot` node:\n",
        "- Gets the conversation history from `state[\"messages\"]`\n",
        "- Adds a system prompt about SuperWidget\n",
        "- Calls the LLM\n",
        "- Returns the LLM's response to be added to messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cell-8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Chatbot node created\n",
            "  Model: gpt-4o-mini\n",
            "  System prompt: 633 characters\n"
          ]
        }
      ],
      "source": [
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "\n",
        "# System prompt with product knowledge\n",
        "SYSTEM_PROMPT = \"\"\"You are a helpful customer support agent for SuperWidget, \n",
        "a revolutionary smart home device that controls all your appliances with voice commands.\n",
        "\n",
        "SuperWidget features:\n",
        "- Voice control for lights, thermostats, locks, and appliances\n",
        "- Works with Alexa, Google Assistant, and Siri\n",
        "- Easy 5-minute setup via mobile app\n",
        "- 24/7 customer support\n",
        "- Price: $199\n",
        "\n",
        "Common issues:\n",
        "- \"Can't connect to WiFi\" → Check 2.4GHz network, restart device\n",
        "- \"Voice not recognized\" → Retrain voice profile in app settings\n",
        "- \"Device offline\" → Check power cable and WiFi connection\n",
        "\n",
        "Be friendly, concise, and helpful. Ask clarifying questions if needed.\n",
        "\"\"\"\n",
        "\n",
        "def chatbot(state: State) -> dict:\n",
        "    \"\"\"Customer support chatbot node.\"\"\"\n",
        "    # Build messages with system prompt\n",
        "    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"]\n",
        "    \n",
        "    # Call LLM\n",
        "    response = llm.invoke(messages)\n",
        "    \n",
        "    # Return state update (new message to append)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "print(\"✓ Chatbot node created\")\n",
        "print(f\"  Model: gpt-4o-mini\")\n",
        "print(f\"  System prompt: {len(SYSTEM_PROMPT)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-9",
      "metadata": {},
      "source": [
        "## Step 3: Build the StateGraph\n",
        "\n",
        "Now we create a graph with:\n",
        "1. **One node**: `chatbot` (the function we defined)\n",
        "2. **Two edges**:\n",
        "   - START → chatbot (entry point)\n",
        "   - chatbot → END (exit point)\n",
        "\n",
        "This creates a simple linear flow:\n",
        "```\n",
        "START → chatbot → END\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cell-10",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Graph structure defined\n",
            "  Nodes: chatbot\n",
            "  Flow: START → chatbot → END\n"
          ]
        }
      ],
      "source": [
        "# Create graph\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Add node\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# Add edges\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "print(\"✓ Graph structure defined\")\n",
        "print(\"  Nodes: chatbot\")\n",
        "print(\"  Flow: START → chatbot → END\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-11",
      "metadata": {},
      "source": [
        "## Step 4: Enable Persistence with Checkpointing\n",
        "\n",
        "**Persistence** means the agent remembers previous conversations.\n",
        "\n",
        "We use a **checkpointer** to automatically save state after each execution:\n",
        "- `MemorySaver()`: In-memory storage (for development/testing)\n",
        "- **Production alternatives**: SqliteSaver, PostgresSaver\n",
        "\n",
        "When you compile the graph with a checkpointer, it:\n",
        "1. Saves state after each execution\n",
        "2. Loads previous state when you provide the same `thread_id`\n",
        "3. Enables conversation history across multiple `invoke()` calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cell-12",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Agent compiled with persistence\n",
            "  Checkpointer: MemorySaver (in-memory)\n",
            "  Ready to remember conversations!\n"
          ]
        }
      ],
      "source": [
        "# Create checkpointer\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Compile graph with persistence\n",
        "agent = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "print(\"✓ Agent compiled with persistence\")\n",
        "print(\"  Checkpointer: MemorySaver (in-memory)\")\n",
        "print(\"  Ready to remember conversations!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-13",
      "metadata": {},
      "source": [
        "## Step 5: Test the Agent\n",
        "\n",
        "Let's have a multi-turn conversation to see persistence in action.\n",
        "\n",
        "**Key concept**: `thread_id` identifies the conversation session.\n",
        "- Same `thread_id` = continue existing conversation\n",
        "- Different `thread_id` = start new conversation\n",
        "\n",
        "### Helper Function\n",
        "\n",
        "We'll create a helper to make chatting easier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cell-14",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper function ready\n",
            "  Usage: chat('your message', thread_id='session1')\n"
          ]
        }
      ],
      "source": [
        "def chat(user_message: str, thread_id: str = \"default\") -> str:\n",
        "    \"\"\"\n",
        "    Send a message and get the agent's response.\n",
        "    \n",
        "    Args:\n",
        "        user_message: What the user says\n",
        "        thread_id: Conversation session ID (default: \"default\")\n",
        "    \n",
        "    Returns:\n",
        "        The agent's response text\n",
        "    \"\"\"\n",
        "    # Create config with thread ID\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "    \n",
        "    # Invoke agent with user message\n",
        "    result = agent.invoke(\n",
        "        {\"messages\": [HumanMessage(content=user_message)]},\n",
        "        config\n",
        "    )\n",
        "    \n",
        "    # Return last message (agent's response)\n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "print(\"✓ Helper function ready\")\n",
        "print(\"  Usage: chat('your message', thread_id='session1')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-15",
      "metadata": {},
      "source": [
        "### Test 1: Basic Conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cell-16",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: Hi! What is SuperWidget?\n",
            "Agent: Hi there! SuperWidget is a revolutionary smart home device that allows you to control all your appliances using voice commands. It works seamlessly with Alexa, Google Assistant, and Siri, making it easy to manage your lights, thermostats, locks, and other appliances with just your voice. The setup is simple and only takes about 5 minutes via our mobile app. If you have any specific questions or need more information, feel free to ask!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Start conversation\n",
        "response1 = chat(\"Hi! What is SuperWidget?\", thread_id=\"user1\")\n",
        "print(f\"User: Hi! What is SuperWidget?\")\n",
        "print(f\"Agent: {response1}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-17",
      "metadata": {},
      "source": [
        "### Test 2: Follow-up Question (Tests Persistence)\n",
        "\n",
        "The agent should remember what \"it\" refers to (SuperWidget):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cell-18",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: How much does it cost?\n",
            "Agent: SuperWidget is priced at $199. If you have any more questions or need assistance with anything else, just let me know!\n",
            "\n",
            "✓ Agent remembered the conversation context!\n"
          ]
        }
      ],
      "source": [
        "# Follow-up (same thread)\n",
        "response2 = chat(\"How much does it cost?\", thread_id=\"user1\")\n",
        "print(f\"User: How much does it cost?\")\n",
        "print(f\"Agent: {response2}\")\n",
        "print()\n",
        "print(\"✓ Agent remembered the conversation context!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-19",
      "metadata": {},
      "source": [
        "### Test 3: New User (Different Thread)\n",
        "\n",
        "A different `thread_id` starts a fresh conversation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cell-20",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: I can't connect to WiFi. Help!\n",
            "Agent: I'm here to help! Please check the following:\n",
            "\n",
            "1. **Network Type**: Ensure you’re trying to connect to a 2.4GHz network, as SuperWidget doesn’t support 5GHz networks.\n",
            "2. **Restart Device**: Try unplugging SuperWidget, waiting for about 10 seconds, and then plugging it back in.\n",
            "\n",
            "Can you confirm if you're on a 2.4GHz network? If you're still having trouble, let me know!\n",
            "\n",
            "✓ New thread = isolated conversation\n"
          ]
        }
      ],
      "source": [
        "# Different user (new thread)\n",
        "response3 = chat(\"I can't connect to WiFi. Help!\", thread_id=\"user2\")\n",
        "print(f\"User: I can't connect to WiFi. Help!\")\n",
        "print(f\"Agent: {response3}\")\n",
        "print()\n",
        "print(\"✓ New thread = isolated conversation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-21",
      "metadata": {},
      "source": [
        "## Step 6: Inspect Conversation State\n",
        "\n",
        "You can view the saved state for any thread:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cell-22",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State for user1:\n",
            "  Total messages: 4\n",
            "\n",
            "Conversation history:\n",
            "  1. User: Hi! What is SuperWidget?\n",
            "  2. Agent: Hi there! SuperWidget is a revolutionary smart home device that allows you to co...\n",
            "  3. User: How much does it cost?\n",
            "  4. Agent: SuperWidget is priced at $199. If you have any more questions or need assistance...\n"
          ]
        }
      ],
      "source": [
        "# Get state for user1's conversation\n",
        "state_user1 = agent.get_state({\"configurable\": {\"thread_id\": \"user1\"}})\n",
        "\n",
        "print(\"State for user1:\")\n",
        "print(f\"  Total messages: {len(state_user1.values['messages'])}\")\n",
        "print(f\"\\nConversation history:\")\n",
        "for i, msg in enumerate(state_user1.values['messages']):\n",
        "    role = \"User\" if isinstance(msg, HumanMessage) else \"Agent\"\n",
        "    content = msg.content[:80] + \"...\" if len(msg.content) > 80 else msg.content\n",
        "    print(f\"  {i+1}. {role}: {content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-23",
      "metadata": {},
      "source": [
        "## Challenge: Add User Preferences\n",
        "\n",
        "**Goal**: Extend the agent to remember user preferences beyond just messages.\n",
        "\n",
        "**Requirements**:\n",
        "1. Add a `user_name` field to the `State` TypedDict\n",
        "2. Create a new node `extract_name` that checks if the user introduced themselves\n",
        "3. If they did, extract and save their name to `state[\"user_name\"]`\n",
        "4. Modify the `chatbot` node to greet users by name if known\n",
        "5. Update the graph flow:\n",
        "   ```\n",
        "   START → extract_name → chatbot → END\n",
        "   ```\n",
        "\n",
        "**Hints**:\n",
        "- Use the LLM to extract names: \"Did the user introduce themselves? If so, what's their name?\"\n",
        "- Check `if state.get(\"user_name\")` to see if name is set\n",
        "- Update system prompt to include: `f\"The user's name is {user_name}\" if user_name else \"\"`\n",
        "\n",
        "**Test**:\n",
        "```python\n",
        "chat(\"Hi, I'm Alice!\", thread_id=\"alice\")\n",
        "chat(\"What's my name?\", thread_id=\"alice\")  # Should remember \"Alice\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "challenge-solution",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Extended state defined\n",
            "  - messages: list (conversation history)\n",
            "  - user_name: Optional[str] (extracted from conversation)\n"
          ]
        }
      ],
      "source": [
        "# Challenge Solution: Add User Preferences\n",
        "\n",
        "from typing import Annotated, TypedDict, Optional\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "# Step 1: Extend State with user_name field\n",
        "class StateWithName(TypedDict):\n",
        "    \"\"\"Extended state with user name tracking.\"\"\"\n",
        "    messages: Annotated[list, add_messages]\n",
        "    user_name: Optional[str]  # User's name if introduced\n",
        "\n",
        "print(\"✓ Extended state defined\")\n",
        "print(\"  - messages: list (conversation history)\")\n",
        "print(\"  - user_name: Optional[str] (extracted from conversation)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "extract-name-node",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Name extraction node created\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Create extract_name node\n",
        "\n",
        "NAME_EXTRACTION_PROMPT = \"\"\"Look at the user's last message: \"{message}\"\n",
        "\n",
        "Did the user introduce themselves or provide their name?\n",
        "\n",
        "If YES: Respond with ONLY the name (e.g., \"Alice\" or \"Bob\")\n",
        "If NO: Respond with ONLY the word \"NONE\"\n",
        "\n",
        "Examples:\n",
        "- \"Hi, I'm Alice!\" → Alice\n",
        "- \"My name is Bob\" → Bob\n",
        "- \"Hello\" → NONE\n",
        "- \"What is SuperWidget?\" → NONE\n",
        "\"\"\"\n",
        "\n",
        "llm_name_extractor = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "def extract_name(state: StateWithName) -> dict:\n",
        "    \"\"\"Extract user name from conversation if present.\"\"\"\n",
        "    # If name already extracted, skip\n",
        "    if state.get(\"user_name\"):\n",
        "        print(f\"  Name already known: {state['user_name']}\")\n",
        "        return {}  # No state update\n",
        "    \n",
        "    # Get last user message\n",
        "    user_messages = [msg for msg in state[\"messages\"] if isinstance(msg, HumanMessage)]\n",
        "    if not user_messages:\n",
        "        return {}  # No user messages yet\n",
        "    \n",
        "    last_message = user_messages[-1].content\n",
        "    \n",
        "    # Ask LLM to extract name\n",
        "    prompt = NAME_EXTRACTION_PROMPT.format(message=last_message)\n",
        "    response = llm_name_extractor.invoke([SystemMessage(content=prompt)])\n",
        "    \n",
        "    extracted = response.content.strip()\n",
        "    \n",
        "    # Check if name was found\n",
        "    if extracted != \"NONE\" and extracted:\n",
        "        print(f\"  ✓ Extracted name: {extracted}\")\n",
        "        return {\"user_name\": extracted}\n",
        "    else:\n",
        "        print(f\"  No name found in message\")\n",
        "        return {}  # No name found\n",
        "\n",
        "print(\"✓ Name extraction node created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "updated-chatbot-node",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Updated chatbot node created\n",
            "  Now greets users by name when known\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Update chatbot node to use name\n",
        "\n",
        "SYSTEM_PROMPT_WITH_NAME = \"\"\"You are a helpful customer support agent for SuperWidget, \n",
        "a revolutionary smart home device that controls all your appliances with voice commands.\n",
        "\n",
        "{name_section}\n",
        "\n",
        "SuperWidget features:\n",
        "- Voice control for lights, thermostats, locks, and appliances\n",
        "- Works with Alexa, Google Assistant, and Siri\n",
        "- Easy 5-minute setup via mobile app\n",
        "- 24/7 customer support\n",
        "- Price: $199\n",
        "\n",
        "Common issues:\n",
        "- \"Can't connect to WiFi\" → Check 2.4GHz network, restart device\n",
        "- \"Voice not recognized\" → Retrain voice profile in app settings\n",
        "- \"Device offline\" → Check power cable and WiFi connection\n",
        "\n",
        "Be friendly, concise, and helpful. Ask clarifying questions if needed.\n",
        "{greeting_instruction}\n",
        "\"\"\"\n",
        "\n",
        "llm_chatbot = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "\n",
        "def chatbot_with_name(state: StateWithName) -> dict:\n",
        "    \"\"\"Customer support chatbot that greets by name.\"\"\"\n",
        "    # Build personalized system prompt\n",
        "    user_name = state.get(\"user_name\")\n",
        "    \n",
        "    if user_name:\n",
        "        name_section = f\"The user's name is {user_name}.\"\n",
        "        greeting_instruction = f\"Greet {user_name} by name when appropriate.\"\n",
        "    else:\n",
        "        name_section = \"The user has not introduced themselves yet.\"\n",
        "        greeting_instruction = \"\"\n",
        "    \n",
        "    system_prompt = SYSTEM_PROMPT_WITH_NAME.format(\n",
        "        name_section=name_section,\n",
        "        greeting_instruction=greeting_instruction\n",
        "    )\n",
        "    \n",
        "    # Build messages with system prompt\n",
        "    messages = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n",
        "    \n",
        "    # Call LLM\n",
        "    response = llm_chatbot.invoke(messages)\n",
        "    \n",
        "    # Return state update\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "print(\"✓ Updated chatbot node created\")\n",
        "print(\"  Now greets users by name when known\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "updated-graph",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Updated graph compiled with persistence\n",
            "  Flow: START → extract_name → chatbot → END\n",
            "  Nodes: extract_name, chatbot\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Build updated graph with name extraction\n",
        "\n",
        "# Create graph\n",
        "graph_builder_with_name = StateGraph(StateWithName)\n",
        "\n",
        "# Add nodes\n",
        "graph_builder_with_name.add_node(\"extract_name\", extract_name)\n",
        "graph_builder_with_name.add_node(\"chatbot\", chatbot_with_name)\n",
        "\n",
        "# Add edges: START → extract_name → chatbot → END\n",
        "graph_builder_with_name.add_edge(START, \"extract_name\")\n",
        "graph_builder_with_name.add_edge(\"extract_name\", \"chatbot\")\n",
        "graph_builder_with_name.add_edge(\"chatbot\", END)\n",
        "\n",
        "# Compile with persistence\n",
        "memory_with_name = MemorySaver()\n",
        "agent_with_name = graph_builder_with_name.compile(checkpointer=memory_with_name)\n",
        "\n",
        "print(\"✓ Updated graph compiled with persistence\")\n",
        "print(\"  Flow: START → extract_name → chatbot → END\")\n",
        "print(\"  Nodes: extract_name, chatbot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "updated-helper",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Updated helper function ready\n",
            "  Usage: chat_with_name('Hi, I\\'m Alice!', thread_id='alice')\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Updated helper function\n",
        "\n",
        "def chat_with_name(user_message: str, thread_id: str = \"default\") -> str:\n",
        "    \"\"\"\n",
        "    Send a message and get the agent's response.\n",
        "    Now extracts and remembers user names!\n",
        "    \n",
        "    Args:\n",
        "        user_message: What the user says\n",
        "        thread_id: Conversation session ID\n",
        "    \n",
        "    Returns:\n",
        "        The agent's response text\n",
        "    \"\"\"\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "    \n",
        "    result = agent_with_name.invoke(\n",
        "        {\"messages\": [HumanMessage(content=user_message)]},\n",
        "        config\n",
        "    )\n",
        "    \n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "print(\"✓ Updated helper function ready\")\n",
        "print(\"  Usage: chat_with_name('Hi, I\\\\'m Alice!', thread_id='alice')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "test-name-1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 1: Name Introduction\n",
            "==================================================\n",
            "  ✓ Extracted name: Alice\n",
            "User: Hi, I'm Alice!\n",
            "Agent: Hi Alice! How can I assist you today with your SuperWidget?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test 1: User introduces themselves\n",
        "\n",
        "print(\"Test 1: Name Introduction\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "response = chat_with_name(\"Hi, I'm Alice!\", thread_id=\"alice\")\n",
        "print(f\"User: Hi, I'm Alice!\")\n",
        "print(f\"Agent: {response}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "test-name-2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 2: Name Recall\n",
            "==================================================\n",
            "  Name already known: Alice\n",
            "User: What's my name?\n",
            "Agent: Your name is Alice! How can I help you today?\n",
            "\n",
            "✓ Agent remembered the name from previous turn!\n"
          ]
        }
      ],
      "source": [
        "# Test 2: Agent remembers the name\n",
        "\n",
        "print(\"Test 2: Name Recall\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "response = chat_with_name(\"What's my name?\", thread_id=\"alice\")\n",
        "print(f\"User: What's my name?\")\n",
        "print(f\"Agent: {response}\")\n",
        "print()\n",
        "print(\"✓ Agent remembered the name from previous turn!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "test-name-3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 3: Different User\n",
            "==================================================\n",
            "  ✓ Extracted name: Bob\n",
            "User: Hello, my name is Bob\n",
            "Agent: Hi Bob! It's great to meet you. How can I assist you today with your SuperWidget?\n",
            "\n",
            "✓ Different thread = different conversation\n"
          ]
        }
      ],
      "source": [
        "# Test 3: Different user, different name\n",
        "\n",
        "print(\"Test 3: Different User\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "response = chat_with_name(\"Hello, my name is Bob\", thread_id=\"bob\")\n",
        "print(f\"User: Hello, my name is Bob\")\n",
        "print(f\"Agent: {response}\")\n",
        "print()\n",
        "print(\"✓ Different thread = different conversation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "test-state",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test 4: State Inspection\n",
            "==================================================\n",
            "\n",
            "State for Alice:\n",
            "  user_name: Alice\n",
            "  Total messages: 4\n",
            "\n",
            "State for Bob:\n",
            "  user_name: Bob\n",
            "  Total messages: 2\n",
            "\n",
            "✓ Each thread maintains separate state!\n"
          ]
        }
      ],
      "source": [
        "# Test 4: Inspect state to see saved name\n",
        "\n",
        "print(\"Test 4: State Inspection\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "state_alice = agent_with_name.get_state({\"configurable\": {\"thread_id\": \"alice\"}})\n",
        "\n",
        "print(f\"\\nState for Alice:\")\n",
        "print(f\"  user_name: {state_alice.values.get('user_name')}\")\n",
        "print(f\"  Total messages: {len(state_alice.values['messages'])}\")\n",
        "\n",
        "state_bob = agent_with_name.get_state({\"configurable\": {\"thread_id\": \"bob\"}})\n",
        "\n",
        "print(f\"\\nState for Bob:\")\n",
        "print(f\"  user_name: {state_bob.values.get('user_name')}\")\n",
        "print(f\"  Total messages: {len(state_bob.values['messages'])}\")\n",
        "\n",
        "print(\"\\n✓ Each thread maintains separate state!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### What We Implemented\n",
        "\n",
        "1. **Extended State** - Added `user_name: Optional[str]` field to track user identity\n",
        "\n",
        "2. **Name Extraction Node** - Created `extract_name()` that:\n",
        "   - Checks if name already known (skip if yes)\n",
        "   - Analyzes last user message with LLM\n",
        "   - Extracts name if user introduced themselves\n",
        "   - Updates state with extracted name\n",
        "\n",
        "3. **Personalized Chatbot** - Updated `chatbot_with_name()` to:\n",
        "   - Include user's name in system prompt\n",
        "   - Greet user by name when appropriate\n",
        "   - Maintain context of user identity\n",
        "\n",
        "4. **Updated Graph Flow**:\n",
        "   ```\n",
        "   START → extract_name → chatbot → END\n",
        "   ```\n",
        "\n",
        "### Key Features Demonstrated\n",
        "\n",
        "✅ **State Extension** - Added fields to TypedDict for richer context\n",
        "\n",
        "✅ **Multi-Node Workflow** - Chained processing (extraction → response)\n",
        "\n",
        "✅ **Conditional State Updates** - Only update name if found\n",
        "\n",
        "✅ **LLM as Tool** - Used LLM for name extraction task\n",
        "\n",
        "✅ **Thread Isolation** - Each user's name persists separately\n",
        "\n",
        "### Design Patterns\n",
        "\n",
        "**State Management**:\n",
        "```python\n",
        "# Check if field exists\n",
        "if state.get(\"user_name\"):\n",
        "    # Use existing value\n",
        "    \n",
        "# Conditional update\n",
        "return {\"user_name\": extracted} if extracted else {}\n",
        "```\n",
        "\n",
        "**LLM Prompting**:\n",
        "```python\n",
        "# Clear, specific instructions\n",
        "# Examples for few-shot learning\n",
        "# Simple output format (name or \"NONE\")\n",
        "```\n",
        "\n",
        "**Graph Sequencing**:\n",
        "```python\n",
        "# Preprocessing → Main logic\n",
        "extract_name → chatbot\n",
        "```\n",
        "\n",
        "### Production Considerations\n",
        "\n",
        "**Current Implementation**:\n",
        "- ✅ Name extraction works for simple introductions\n",
        "- ✅ Thread isolation prevents name leaks\n",
        "- ⚠️ Only checks last message (misses earlier introductions)\n",
        "- ⚠️ No name validation (could extract nonsense)\n",
        "\n",
        "**Production Enhancements**:\n",
        "- Check all messages, not just last one\n",
        "- Validate extracted names (reasonable length, characters)\n",
        "- Handle name changes (\"Actually, call me Bob\")\n",
        "- Add confirmation (\"Nice to meet you, Alice! Is that correct?\")\n",
        "- Support nicknames and multiple name formats\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "Try extending this pattern to track:\n",
        "- **User preferences**: Product interests, notification settings\n",
        "- **Session metadata**: First message time, message count\n",
        "- **Context flags**: Is user frustrated, needs escalation?\n",
        "- **Multi-turn tasks**: Shopping cart, booking process\n",
        "\n",
        "**Great work!** You've built a personalized conversational agent with LangGraph."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-25",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this lab, you learned how to build a stateful single agent with LangGraph:\n",
        "\n",
        "✅ **State Management** - Used TypedDict with `add_messages` to track conversation history\n",
        "\n",
        "✅ **Nodes** - Created functions that process state and return updates\n",
        "\n",
        "✅ **Edges** - Defined control flow with START → node → END\n",
        "\n",
        "✅ **Persistence** - Enabled checkpointing to remember conversations across sessions\n",
        "\n",
        "✅ **Thread IDs** - Used thread IDs to isolate conversations for different users\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "**StateGraph Workflow**:\n",
        "1. Define state schema (TypedDict)\n",
        "2. Create nodes (functions)\n",
        "3. Build graph (add nodes + edges)\n",
        "4. Compile with checkpointer\n",
        "5. Invoke with config (thread_id)\n",
        "\n",
        "**When to Use Single Agents**:\n",
        "- Simple conversational bots\n",
        "- Customer support with FAQ\n",
        "- Task-specific assistants (scheduling, summarization)\n",
        "- Any scenario where one LLM call per turn is sufficient\n",
        "\n",
        "**Next Steps**:\n",
        "- **Multi-agent systems**: Coordinate multiple specialized agents\n",
        "- **Tool use**: Give agents access to external APIs\n",
        "- **Conditional routing**: Dynamic paths based on state\n",
        "- **Streaming**: Real-time output during execution"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gai-3101",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
