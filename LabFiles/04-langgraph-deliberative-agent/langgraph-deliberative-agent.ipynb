{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Deliberative Agent in LangGraph\n",
    "\n",
    "> **Learning Outcomes:**\n",
    "> - Understand the concept of a Deliberative Agent\n",
    "> - Implement a Deliberative Agent in LangGraph\n",
    "> - Test the Deliberative Agent in a simulated environment\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we will implement a Deliberative Agent in LangGraph. A Deliberative Agent is an agent that can reason about its actions and make decisions based on its goals and beliefs. The agent first plans its actions before executing them. This is in contrast to a Reactive Agent that reacts to its environment without planning.\n",
    "\n",
    "\n",
    "### LangGraph Framework\n",
    "\n",
    "[LangGraph](https://www.google.com/url?sa=E&source=gmail&q=https://python.langchain.com/docs/langgraph) is a framework from Langchain designed for building conversational AI agents with state management. It allows you to create agent workflows as graphs, making complex interactions easier to define and manage.\n",
    "\n",
    "\n",
    "### The Scenario\n",
    "\n",
    "We will be creating an LangGraph graph which first plans the actions to complete a task and then executes the actions. The task is finalized by an agent before begin returned to the user. It can be visualized like this:\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    User --> Planner\n",
    "    Planner --> Executor\n",
    "    Executor -- Still Working --> Executor\n",
    "    Executor -- Tasks Complete --> Finalizer\n",
    "    Finalizer --> User\n",
    "```\n",
    "\n",
    "\n",
    "## Getting Started\n",
    "Let's start by installing the required libraries and setting the OpenAI API key. The OpenAI API key is required to access the OpenAI models.\n",
    "\n",
    "Run the following cells to install the required libraries and set the OpenAI API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip setuptools wheel\n",
    "%pip install tiktoken --only-binary=:all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU \\\n",
    "    langchain==0.3.* \\\n",
    "    langchain_openai==0.3.* \\\n",
    "        langgraph==0.5.*\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core\n",
    "\n",
    "### Step 1 - Define the Agent's State\n",
    "\n",
    "In this step, we will define the state of our Deliberative Agent. The state will include the task, the plan, the current task, the total number of tasks, the results of each task, and the final result.\n",
    "\n",
    "We will use the `TypedDict` class from the `typing_extensions` module to define the state. This will allow us to specify the types of the state variables.\n",
    "\n",
    "Here is a simple example of how to define the state of the agent:\n",
    "\n",
    "```python\n",
    "class State(TypedDict):\n",
    "    messages: list[str]\n",
    "```\n",
    "\n",
    "In the follow cell, define a `State` class with the following fields:\n",
    "- `task`: The task that the agent needs to complete.\n",
    "- `plan`: The plan of action for the task.\n",
    "- `current_task`: The current task number that the agent is working on.\n",
    "- `task_count`: The total number of tasks in the plan.\n",
    "- `results`: A list of results from the completed tasks.\n",
    "- `final_result`: The final result after all tasks are completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how LangGraph will pass data between nodes in the graph. As the data moves through the graph, it will be stored in a typed dictionary. Fields can be added or updated as the data moves through the graph.\n",
    "\n",
    "### Step 2 - Create a Planning Chain\n",
    "\n",
    "In this step, we will create a planning chain that will generate a plan of action for the agent. The planning chain will use a prompt template to instruct the language model to break down the task into smaller, manageable subtasks.\n",
    "\n",
    "Here is an example of how to create a chain in LangChain:\n",
    "\n",
    "```python\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"Create a plan for: {task}\"),\n",
    "])\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke({\"task\": \"Build a house!\"})\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <b>Note:</b> The <code>ChatPromptTemplate</code> class is used to create a prompt template that can be used to interpolate variables into the prompt. Any field from the state can be used in the prompt template.\n",
    "</div>\n",
    "\n",
    "In the cell below create a planning chain that generates a plan of action for the agent. Write whatever prompts you think are necessary to instruct the language model to generate a plan of action for the task. Test the chain by invoking it with a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a planning chain that generates a plan of action for the agent, we need a bit more information in the output. Our Agent will execute each task iteratively and then finalize the result. It would be nice to know the number of tasks in the plan so that we can track the progress of the agent.\n",
    "\n",
    "We could parse the output of the planning chain to extract the number of tasks. Or we could use an LLM to extract the number of tasks from the plan. But it is more efficient to modify the planning chain to include the number of tasks in the output.\n",
    "\n",
    "We can do this using structured output. LangChain allows us to define a schema with Pydantic models to enforce structured output from the planning chain. This ensures that the output from the language model adheres to the structure defined in the schema.\n",
    "\n",
    "Here is an example of how to define a structured output schema in LangChain:\n",
    "\n",
    "```python\n",
    "class SandwhichSchema(BaseModel):\n",
    "    bread_type: str\n",
    "    veggies: List[str]\n",
    "    protiens: List[str]\n",
    "    sauces: List[str]\n",
    "\n",
    "llm = llm.with_structured_output(SandwhichSchema)\n",
    "```\n",
    "\n",
    "In the following cell, define a Schema to enforce structured output from the planning chain. The schema should have two fields:\n",
    "- **plan**: A string containing the detailed plan.  \n",
    "- **task_count**: An integer indicating the number of subtasks generated in the plan.\n",
    "\n",
    "Update the planning chain to include the structured output schema. Test the chain by invoking it with a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Create an Execution Chain\n",
    "\n",
    "Now that we have the planning stage complete, we need to create an execution chain that will execute the plan, step by step. Each call to the execution chain should complete only one task from the plan.\n",
    "\n",
    "The prompt template should include:\n",
    "\n",
    "- The original task.\n",
    "- The plan made by the planner.\n",
    "- Any previous results.\n",
    "- The current task number.\n",
    "\n",
    "Remember that these keys can be accessed from the state dictionary!\n",
    "\n",
    "In the cell below, create an execution chain that executes one step in the plan. Write whatever prompts you think are necessary to instruct the language model to execute the plan. Test the chain by invoking it with the a state dictionary containing the task, plan, current task number, and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Create a Finalization Chain\n",
    "\n",
    "One last step before we can hook everything up! We need to create a finalization chain that will finalize the result of the agent after all tasks are completed. The finalization chain should take the results of all the tasks and combine them into a single final result.\n",
    "\n",
    "The prompt will look similar to the execution chain, but it should be tasked with combining the results to complete the initial task.\n",
    "\n",
    "In the cell below, create a finalization chain that finalizes the result of the agent. Write whatever prompts you think are necessary to instruct the language model to finalize the result. Test the chain by invoking it with a state dictionary containing the task and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Create the Graph\n",
    "\n",
    "Now it's time to create the graph. The graph will consist of the following nodes:\n",
    "\n",
    "- **Planner**: The node that generates a plan of action for the agent.\n",
    "- **Executor**: The node that executes the plan, step by step.\n",
    "- **Finalizer**: The node that finalizes the result of the agent.\n",
    "\n",
    "#### Finalizer Node\n",
    "\n",
    "Each node in the graph needs a function that will be called when the node is invoked. The function should take the state dictionary as input and returns the updated state dictionary. For example:\n",
    "\n",
    "```python\n",
    "def house_builder(state: State):\n",
    "    return { \"foundation\": foundation_chain.invoke(state).content }\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <b>Note:</b> The chains return a Python class. You will likely want to return the <code>content</code> attribute of the chain output.\n",
    "</div>\n",
    "\n",
    "The finalizer node should be the easiest to implement. It should take the results of all the tasks and combine them into a single final result. To store the final result it should return a dictionary with the key `final_result`.\n",
    "\n",
    "\n",
    "\n",
    "In the cell below, define the function for the finalizer node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Planner Node\n",
    "Next, we'll define the function for the planner node. The planner node should generate a plan of action for the agent. \n",
    "\n",
    "Remember that our planning chain outputs a structured response with the plan and the number of tasks. We can use this information to update the state dictionary. We can also use this node to set the initial values for the `current_task` and `results` fields in the state dictionary.\n",
    "\n",
    "In the cell below, define the function for the planner node. It should return a state with all of the keys defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executor Node\n",
    "\n",
    "Our last node is the executor node. This node should increment the `current_task` field--you don't need an LLM to do this! It should also execute the current task in the plan--you do need an LLM for this!\n",
    "\n",
    "In addition to incrementing the `current_task`, the node should return an updated list of results. This means you will need to append the result of the current task to the list of results.\n",
    "\n",
    "In the cell below, define the function for the executor node. Make sure that all of the other fields in the state dictionary are preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Conditional Edge\n",
    "\n",
    "The executor node will have two outgoing edges: one for when the agent is still working and one for when the agent has completed all the tasks. The edge for when the agent is still working should loop back to the executor node. The edge for when the agent has completed all the tasks should go to the finalizer node.\n",
    "\n",
    "Conditional edges in LangGraph are defined using... functions! Just like a node, the conditional edge function takes the state dictionary as input. However, the function returns only a string indicating the name of the next node to go to. For example:\n",
    "\n",
    "```python\n",
    "def is_house_done(state: State):\n",
    "    # Check if the agent has completed all the tasks\n",
    "    for key, value in state.items():\n",
    "        if value != \"done\":\n",
    "            return \"build_house\"\n",
    "    return \"house_done\"\n",
    "```\n",
    "\n",
    "In the cell below, define the function for the conditional edge between the executor and finalizer nodes. The function should return `done` if the agent has completed all the tasks, and `next_agent` otherwise. You can use the `current_task` and `task_count` fields in the state dictionary to determine if the agent has completed all the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Graph\n",
    "With all our functions specified, we can now create the graph.\n",
    "\n",
    "In the cell below, is an example of how to create a graph in LangGraph. Run the cell to create the graph and visualize it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Fake state\n",
    "class HomeState(TypedDict):\n",
    "    pass\n",
    "\n",
    "# Fake nodes\n",
    "house_designer = lambda state: None\n",
    "house_builder = lambda state: None\n",
    "realtor = lambda state: None\n",
    "is_house_done = lambda state: None\n",
    "\n",
    "builder = StateGraph(HomeState)\n",
    "builder.add_node(\"house_designer\", house_designer)\n",
    "builder.add_node(\"house_builder\", house_builder)\n",
    "builder.add_node(\"realtor\", realtor)\n",
    "builder.add_edge(START, \"house_designer\")\n",
    "builder.add_edge(\"house_designer\", \"house_builder\")\n",
    "builder.add_conditional_edges(\"house_builder\", is_house_done, {\"house_done\": \"realtor\", \"next_agent\": \"house_builder\"})\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "\n",
    "# Display the graph\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, create the graph for our agent. Display the graph to ensure it is correct.\n",
    "\n",
    "It should look something like this:\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "\n",
    "    start([\"\\_\\_start\\_\\_\"]) --> planner(planner)\n",
    "    planner --> executor(executor)\n",
    "    executor -- next_task --> executor\n",
    "    executor -- done --> finalizer(finalizer)\n",
    "    finalizer --> result([\"\\_\\_end\\_\\_\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Test the Agent\n",
    "\n",
    "Now that we have created the graph, it's time to test our work! In the cell below, is code that will run the agent and output the results.\n",
    "\n",
    "If your graph is named `graph`, this will work out of the box. If you named your graph something else, you will need to update the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "total_tasks = 0\n",
    "\n",
    "TASK = \"Write a corporate policy on Generative AI usage.\"\n",
    "\n",
    "for chunk in graph.stream({\"task\": TASK }, stream_mode=\"updates\"):\n",
    "    node = next(iter(chunk)) \n",
    "    if node == \"finalizer\":\n",
    "        display(Markdown(f\"**Final Result**\\n {chunk[node]['final_result']}\\n\\n\"))\n",
    "    elif node == \"planner\":\n",
    "        display(Markdown(f\"**{node}**\\n{chunk[node]['plan']}\\n\\n\"))\n",
    "        total_tasks = chunk[node].get('task_count', 0)\n",
    "    elif node == \"executor\":\n",
    "        current_task_num = chunk[node].get('current_task', 'N/A')\n",
    "        display(Markdown(f\"**{node}**\\n```{current_task_num} / {total_tasks}```\\n\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully implemented a Deliberative Agent in LangGraph. Feel free to experiment with different tasks and prompts to see how the agent performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge 1 - Iterative Tasks\n",
    "\n",
    "Right now, our graph expects the agent to complete each task in a single step. This is not very realistic. In reality, each task may require multiple steps to complete. For example, laying the foundation of a house may require multiple steps, such as digging the foundation, pouring the concrete, and letting it set.\n",
    "\n",
    "Update the graph to allow for multiple steps in each task. You will need to update the executor node to handle multiple steps. You may want an extra node that reviews the results of each task before moving on to the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge 2 - Error Handling\n",
    "\n",
    "Our agent is very optimistic. It assumes that everything will go according to plan. In reality, things can go wrong. For example, the agent may encounter an unexpected problem while executing a task. Update the graph to handle errors. You may want to add a node that retries the task if it fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
