{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36db6533",
   "metadata": {},
   "source": [
    "# Implementing Long-Term Memory in LangGraph - SOLUTION\n",
    "\n",
    "> **Learning Outcomes:**\n",
    "> - Understand the concept and mechanisms of Long-Term Memory\n",
    "> - Implement Long-Term Memory in LangGraph\n",
    "> - Extend the implementation to support consolidation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we will implement long-term memory in LangGraph. Long-Term memory is a mechanism that allows the model to remember information from the past. This is particularly useful in tasks that require the model to remember information from the past interactions to tailor their responses to the user.\n",
    "\n",
    "### Memory in Humans\n",
    "\n",
    "In humans, memory has many different components and processes. These include:\n",
    "\n",
    "1. *Encoding:* Converting information into a form that can be stored in memory.\n",
    "2. *Storage:* Storing information in memory.\n",
    "3. *Recall:* Passively remembering information.\n",
    "4. *Retrieval:* Actively trying to remember information.\n",
    "5. *Forgetting:* The loss of information over time.\n",
    "6. *Consolidation:* Stabilizing and organizing memories over time.\n",
    "\n",
    "### The Scenario\n",
    "\n",
    "We will be creating a chatbot that can remember information from past interactions. The chatbot will be able to selectively remember information that is important and forget information that is not. The chatbot will also be able to consolidate memories to make them more stable and organized.\n",
    "\n",
    "The graph will look like this:\n",
    "\n",
    "```mermaid\n",
    "stateDiagram\n",
    "    [*] --> Recall\n",
    "    Recall --> ChatBot\n",
    "    ChatBot --> Encode\n",
    "    Encode --> Consolidate\n",
    "    Consolidate --> Chat\n",
    "```\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Let's start by installing the required libraries and setting the OpenAI API key. The OpenAI API key is required to access the OpenAI models.\n",
    "\n",
    "Run the following cells to install the required libraries and set the OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc84f1dd-7183-4a50-a452-2c3f2e65d20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (25.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (80.9.0)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.45.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tiktoken in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip setuptools wheel\n",
    "%pip install tiktoken --only-binary=:all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d13ffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ········\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain==0.3.* langchain_openai==0.3.* langgraph==0.5.*\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "import uuid\n",
    "import textwrap\n",
    "from typing import Annotated\n",
    "\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    os.environ['OPENAI_API_KEY'] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9992a4f5",
   "metadata": {},
   "source": [
    "## Core\n",
    "\n",
    "### Step 1 - Building the State\n",
    "\n",
    "We will start by building the state of our graph. The state will contain the messages from the user and the chatbot. The state will also contain retrieved memories from the long-term memory.\n",
    "\n",
    "We will use the `TypedDict` class from the `typing_extensions` module to define the state. This will allow us to specify the types of the state variables. We will also use the `Annotated` class to add metadata to the state variables. This includes the \"add_messages\" metadata for the `messages` field, which specifies that new messages should be added to the existing messages.\n",
    "\n",
    "```python\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "```\n",
    "\n",
    "In the follow cell, define a `ChatbotState` class with the following fields:\n",
    "\n",
    "- `messages`: A list of messages from the user and the chatbot. \n",
    "- `memories`: A list of strings representing the memories stored in the long-term memory.\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a561c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# [SOLUTION]\n",
    "class ChatbotState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    memory: list[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483a248",
   "metadata": {},
   "source": [
    "This is how LangGraph will pass data between nodes in the graph. As the data moves through the graph, it will be stored in a typed dictionary. Fields can be added or updated as the data moves through the graph.\n",
    "\n",
    "### Step 2 - Setting Up the Memory Store\n",
    "\n",
    "Next, we will set up the memory store for the long-term memory. The memory store will use LangGraph's `InMemoryStore`. This memory doesn't refer to \"memory\", but to RAM. So, it will reset and lose all data when the program is restarted.\n",
    "\n",
    "We will also create a `Memories` class that will allow us to structure the outputs returned from a model and make it easier to work with the memories.\n",
    "\n",
    "Run the following cell to define both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06291986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pydantic import BaseModel\n",
    "\n",
    "in_memory_store = InMemoryStore(\n",
    "    index={\n",
    "        \"embed\": OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "        \"dims\": 1536,\n",
    "    }\n",
    ")\n",
    "\n",
    "class Memories(BaseModel):\n",
    "    list: list[str]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e936b",
   "metadata": {},
   "source": [
    "### Step 3 - Implementing the Nodes\n",
    "\n",
    "Now, we will implement the nodes for our graph. To make working with our memory store easier, we will first define a helper function named `get_namespace` that will return a namespace for the memory store.\n",
    "\n",
    "Run the following cell to define the `get_namespace` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aeba41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "def get_namespace(config: RunnableConfig):\n",
    "    return (\"memories\", config[\"configurable\"][\"user_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed62ce7",
   "metadata": {},
   "source": [
    "#### Recall Node\n",
    "\n",
    "Our first node will be the `Recall` node. This node will retrieve memories from the long-term memory store.\n",
    "\n",
    "You can retrieve memories from the memory store using the `search` method of the memory store. The `get` method takes the namespace and a query as arguments. The query can be a string or a dictionary.\n",
    "\n",
    "```python\n",
    "results = store.search(namespace, query)\n",
    "results[0].value[\"data\"] # <-- This will give you the memory\n",
    "```\n",
    "\n",
    "To simulate passive recall of memories, we will use the user's last message as the query to retrieve memories related to the user's last message.\n",
    "\n",
    "```python\n",
    "last_message = state[\"messages\"][-1].content\n",
    "```\n",
    "\n",
    "In the following cell, implement the `Recall` node. The node should retrieve memories related to the user's last message and update the memroies in the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1721b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "def recall(state: ChatbotState, config: RunnableConfig, *, store: BaseStore):\n",
    "    # YOUR CODE HERE\n",
    "    # [SOLUTION]\n",
    "    memories = store.search(get_namespace(config), query=str(state[\"messages\"][-1].content))\n",
    "    for memory in memories:\n",
    "        print(\"recalled:\", memory.value[\"data\"])\n",
    "    return { \"memory\": list([d.value[\"data\"] for d in memories]) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4389d15",
   "metadata": {},
   "source": [
    "#### Chatbot Node\n",
    "\n",
    "Our next node will be the `ChatBot` node. This node will generate a response from the chatbot.\n",
    "\n",
    "In the following cell, write a system message that describes the purpose of the chatbot and add the memories to it. Then invoke the model with the system message and the state messages.\n",
    "\n",
    "Here is a brief example that does not include the memories:\n",
    "\n",
    "```python\n",
    "model.invoke(\n",
    "    [{\"role\": \"system\", \"content\": \"I am a chatbot that can remember information from past interactions.\"}]\n",
    "    + state[\"messages\"]\n",
    ")\n",
    "```\n",
    "\n",
    "Make sure to return the response to add it to the messages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2796d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4.1\")\n",
    "\n",
    "def chatbot(state: ChatbotState, config: RunnableConfig, *, store: BaseStore):\n",
    "    # YOUR CODE HERE\n",
    "    # [SOLUTION]\n",
    "    memories = \"\\n\".join(state[\"memory\"])\n",
    "    system_msg = f\"You are a helpful assistant talking to the user. User info: {memories}\"\n",
    "    response = model.invoke(\n",
    "        [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "    )\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7cd5c",
   "metadata": {},
   "source": [
    "#### Encode Node\n",
    "Next, we will implement the `Encode` node. This node will encode the chatbot's response and store it in the long-term memory.\n",
    "\n",
    "This node will function similarly to the chatbot mode. However, it should have an additional user message that asks the model to make a list of things to remember. It should return the `Memories` object with the memories to store. To store the memories, you can use the the following code:\n",
    "\n",
    "```python\n",
    "store.put(namespace, str(uuid.uuid4()), {\"data\": memory})\n",
    "```\n",
    "\n",
    "In the following cell, implement the `Encode` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6512328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(state: ChatbotState, config: RunnableConfig, *, store: BaseStore):\n",
    "    # Pre-format the memories string to avoid f-string backslash error\n",
    "    existing_memories_str = \"\\n\".join(state[\"memory\"])\n",
    "\n",
    "    memories = model.with_structured_output(Memories).invoke([\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": textwrap.dedent(\"\"\"\n",
    "                You are a bag person for the assistant.\n",
    "                Help the assistant remember important information.\n",
    "                Format memories as declarative sentence fragments.\n",
    "                Do not include already known info.\n",
    "            \"\"\").strip()\n",
    "        }\n",
    "    ] + state[\"messages\"][-2:] + [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": textwrap.dedent(f\"\"\"\n",
    "                # Memories\n",
    "                {existing_memories_str}\n",
    "\n",
    "                Make a list of things to remember.\n",
    "            \"\"\")\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    namespace = get_namespace(config)\n",
    "\n",
    "    for memory in memories.list:\n",
    "        print(\"memory:\", memory)\n",
    "        store.put(namespace, str(uuid.uuid4()), {\"data\": memory})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8263e8",
   "metadata": {},
   "source": [
    "#### Consolidate Node\n",
    "\n",
    "Our final node will be the `Consolidate` node. This node will consolidate the memories in the long-term memory store. We are going to use the internals of the memory store to make it easier to retrieve and delete all the memories.\n",
    "\n",
    "```python\n",
    "store._data[namespace] # <-- This will give you all the memories\n",
    "del store._data[namespace] # <-- This will delete all the memories\n",
    "```\n",
    "\n",
    "In the cell below, implement the `Consolidate` node. The node should consolidate the memories in the long-term memory store and store the consolidated memories in the state.\n",
    "\n",
    "In order to prevent this node from running every time, add a condition to run this node only if there are more than 10 memories in the memory store. Limit the number of memories to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b41e0623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate(state: ChatbotState, config: RunnableConfig, *, store: BaseStore):\n",
    "    namespace = get_namespace(config)\n",
    "    all_memories = store._data[namespace]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # [SOLUTION]\n",
    "    if len(all_memories) < 10:\n",
    "        print(f'There are {len(all_memories)} memories, not enough to consolidate.')\n",
    "        return\n",
    "\n",
    "    all_memories = \"\\n\".join([d.value[\"data\"] for d in all_memories.values()])\n",
    "\n",
    "    memories = model.with_structured_output(Memories).invoke([{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": textwrap.dedent(\"\"\"\n",
    "            You are a memory consolidator.\n",
    "            Reduce the number of memories to 10.\n",
    "            Do not invent memories.\n",
    "            Keep them formatted as declarative sentence fragments.\n",
    "            Combine similar memories.\n",
    "        \"\"\").strip()\n",
    "    }] + state[\"messages\"][-2:] + [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": textwrap.dedent(f\"\"\"\n",
    "                # Memories\n",
    "                {all_memories}\n",
    "\n",
    "                Consolidate the memories.\n",
    "            \"\"\")\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    del store._data[namespace]\n",
    "\n",
    "    for memory in memories.list:\n",
    "        print(\"consolidated memory:\", memory)\n",
    "        store.put(namespace, str(uuid.uuid4()), {\"data\": memory})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc5c65",
   "metadata": {},
   "source": [
    "### Step 4 - Building the Graph\n",
    "\n",
    "Now we can build the graph using the nodes we implemented. The graph is fairly straightforward and links the nodes in the following order: Recall -> ChatBot -> Encode -> Consolidate. As a reminder, this is how you can build the graph:\n",
    "\n",
    "```python\n",
    "builder = StateGraph()\n",
    "builder.add_node(\"node\", function)\n",
    "builder.add_edge(START, \"node\")\n",
    "builder.add_edge(\"node\", END)\n",
    "```\n",
    "\n",
    "In the cell below, build the graph using the nodes we implemented. At the end, compile it using the following code:\n",
    "\n",
    "```python\n",
    "builder.compile(checkpointer=MemorySaver(), store=in_memory_store)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc4c7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "builder = StateGraph(ChatbotState)\n",
    "# YOUR CODE HERE\n",
    "# [SOLUTION]\n",
    "builder.add_node(\"recall\", recall)\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "builder.add_node(\"encode\", encode)\n",
    "builder.add_node(\"consolidate\", consolidate)\n",
    "\n",
    "builder.add_edge(START, \"recall\")\n",
    "builder.add_edge(\"recall\", \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", \"encode\")\n",
    "builder.add_edge(\"encode\", \"consolidate\")\n",
    "builder.add_edge(\"consolidate\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=MemorySaver(), store=in_memory_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e69d0",
   "metadata": {},
   "source": [
    "### Step 5 - Running the Graph\n",
    "\n",
    "Finally, we can run the graph. Run the following cell to run the graph and see the chatbot in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "646951a7-a46a-42a8-ad25-543ca2499fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I'm Bob. \n",
      " -----------------------------------\n",
      "Hi! I'm Bob. \n",
      " -----------------------------------\n",
      "Hi! I'm Bob. \n",
      " -----------------------------------\n",
      "memory: Bob introduced himself as 'Bob'\n",
      "There are 1 memories, not enough to consolidate.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Bob! Nice to meet you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set a user ID and thread ID for the conversation. (Thread is the conversation, not the code thread.)\n",
    "thread_1 = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "thread_2 = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# Start the conversation with a message from the user.\n",
    "input_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Hi! I'm Bob.\"\n",
    "}\n",
    "\n",
    "def run_graph(input_message, config):\n",
    "    for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "        final_state = chunk\n",
    "        #print(chunk) # uncomment this message if you'd like to see the message detail. \n",
    "        print(chunk['messages'][0].content, \"\\n\", \"-\"*35)\n",
    "\n",
    "    chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "run_graph(input_message, thread_1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d8a31-8ddd-4c1a-816c-2eae8157dfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7ce352c",
   "metadata": {},
   "source": [
    "Now let's give the model a lot to remember!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38681ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I'm Bob. \n",
      " -----------------------------------\n",
      "recalled: Bob introduced himself as 'Bob'\n",
      "Hi! I'm Bob. \n",
      " -----------------------------------\n",
      "Hi! I'm Bob. \n",
      " -----------------------------------\n",
      "memory: Bob prefers tea over coffee.\n",
      "memory: Bob has a small scar on his left elbow.\n",
      "memory: Bob enjoys solving crossword puzzles.\n",
      "memory: Bob is afraid of heights.\n",
      "memory: Bob can play the first few bars of 'Für Elise' on piano.\n",
      "memory: Bob owns a collection of vintage postcards.\n",
      "memory: Bob has traveled to three different continents.\n",
      "memory: Bob is a night owl.\n",
      "memory: Bob loves the smell of old books.\n",
      "memory: Bob once won a local pie-baking contest.\n",
      "consolidated memory: Name is Bob.\n",
      "consolidated memory: Prefers tea over coffee.\n",
      "consolidated memory: Has a small scar on left elbow.\n",
      "consolidated memory: Enjoys solving crossword puzzles.\n",
      "consolidated memory: Is afraid of heights.\n",
      "consolidated memory: Can play the first few bars of 'Für Elise' on piano.\n",
      "consolidated memory: Owns a collection of vintage postcards.\n",
      "consolidated memory: Has traveled to three continents.\n",
      "consolidated memory: Is a night owl.\n",
      "consolidated memory: Loves the smell of old books and once won a local pie-baking contest.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Bob! Thanks for sharing those fun facts about yourself. Since you’ve already won a local pie-baking contest, clearly you have some baking chops! Here are a few ideas that play into your interests and might inspire you for this weekend:\n",
      "\n",
      "1. **Vintage-Inspired Bake:** Since you collect vintage postcards and love old books, why not try baking something classic and nostalgic? A Victorian sponge cake, a classic pound cake, or an old-fashioned coffee cake (perhaps with tea instead of coffee, since you prefer tea).\n",
      "\n",
      "2. **Travel-Inspired Bake:** You’ve traveled to three continents—think about baking something from one of those places! Perhaps a French tarte tatin, an Australian lamington, or a South American alfajor.\n",
      "\n",
      "3. **Tea Lover’s Choice:** Bake something that pairs beautifully with tea. Some suggestions: Earl Grey shortbread cookies, lemon drizzle cake, or scones with jam and clotted cream.\n",
      "\n",
      "4. **Crossword-Themed Bake:** Get creative and bake cookies or cupcakes decorated with crossword puzzle designs (you can pipe icing letters or squares on top!).\n",
      "\n",
      "5. **Für Elise Inspiration:** Try a German dessert like a Black Forest cake or apple strudel—a playful nod to Beethoven’s heritage and your piano skills.\n",
      "\n",
      "Considering your love for nostalgia and tea, how about some homemade scones or a classic Victoria sponge cake? Both are perfect for a cozy evening with a crossword puzzle and a cup of tea.\n",
      "\n",
      "Would you like a specific recipe for any of these ideas?\n"
     ]
    }
   ],
   "source": [
    "run_graph({\"role\": \"user\", \"content\": \"\"\"\n",
    "I prefer tea over coffee.\n",
    "I have a small scar on my left elbow.\n",
    "I enjoy solving crossword puzzles.\n",
    "I am afraid of heights.\n",
    "I can play the first few bars of \"Für Elise\" on piano.\n",
    "I own a collection of vintage postcards.\n",
    "I have traveled to three different continents.\n",
    "I am a night owl.\n",
    "I love the smell of old books.\n",
    "I once won a local pie-baking contest.\n",
    "\n",
    "What should I bake this weekend?\n",
    "\"\"\"}, thread_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef17fd",
   "metadata": {},
   "source": [
    "Run the cell below to see if the chatbot can remember the information across conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "561bfbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What do you remember about me?\n",
      " \n",
      " -----------------------------------\n",
      "recalled: Loves the smell of old books and once won a local pie-baking contest.\n",
      "recalled: Name is Bob.\n",
      "recalled: Is a night owl.\n",
      "recalled: Has a small scar on left elbow.\n",
      "recalled: Is afraid of heights.\n",
      "recalled: Owns a collection of vintage postcards.\n",
      "recalled: Prefers tea over coffee.\n",
      "recalled: Enjoys solving crossword puzzles.\n",
      "recalled: Can play the first few bars of 'Für Elise' on piano.\n",
      "recalled: Has traveled to three continents.\n",
      "\n",
      "What do you remember about me?\n",
      " \n",
      " -----------------------------------\n",
      "\n",
      "What do you remember about me?\n",
      " \n",
      " -----------------------------------\n",
      "memory: Name is Bob.\n",
      "memory: Loves the smell of old books.\n",
      "memory: Once won a local pie-baking contest.\n",
      "memory: Is a night owl.\n",
      "memory: Has a small scar on left elbow.\n",
      "memory: Is afraid of heights.\n",
      "memory: Owns a collection of vintage postcards.\n",
      "memory: Prefers tea over coffee.\n",
      "memory: Enjoys solving crossword puzzles.\n",
      "memory: Can play the first few bars of 'Für Elise' on piano.\n",
      "memory: Has traveled to three continents.\n",
      "consolidated memory: Name is Bob.\n",
      "consolidated memory: Prefers tea over coffee.\n",
      "consolidated memory: Has a small scar on left elbow.\n",
      "consolidated memory: Enjoys solving crossword puzzles.\n",
      "consolidated memory: Is afraid of heights.\n",
      "consolidated memory: Can play the first few bars of 'Für Elise' on piano.\n",
      "consolidated memory: Owns a collection of vintage postcards.\n",
      "consolidated memory: Has traveled to three continents.\n",
      "consolidated memory: Is a night owl.\n",
      "consolidated memory: Loves the smell of old books and once won a local pie-baking contest.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here’s what I remember about you, Bob:\n",
      "\n",
      "- You love the smell of old books.\n",
      "- You once won a local pie-baking contest.\n",
      "- You’re a night owl.\n",
      "- You have a small scar on your left elbow.\n",
      "- You’re afraid of heights.\n",
      "- You own a collection of vintage postcards.\n",
      "- You prefer tea over coffee.\n",
      "- You enjoy solving crossword puzzles.\n",
      "- You can play the first few bars of \"Für Elise\" on piano.\n",
      "- You’ve traveled to three continents.\n",
      "\n",
      "Did I miss anything important?\n"
     ]
    }
   ],
   "source": [
    "run_graph({\"role\": \"user\", \"content\": \"\"\"\n",
    "What do you remember about me?\n",
    "\"\"\"}, thread_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ccb71",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "\n",
    "Feel free to experiment with the chatbot by sending different messages. You can also modify the code to add more features or improve the existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d7cdbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e91a2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this lab, we implemented long-term memory in LangGraph. We created a chatbot that can remember information from past interactions and consolidate memories to make them more stable and organized. We also learned how to use the memory store to store and retrieve memories."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
