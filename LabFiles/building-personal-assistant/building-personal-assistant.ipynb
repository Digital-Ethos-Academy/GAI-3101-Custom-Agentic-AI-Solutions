{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Building a Personal Assistant Agent\n",
    "\n",
    "**Production-Ready Implementation with Logging, Error Handling, and Structured Outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "learning-outcomes",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- **Design single-agent architectures** for multi-capability applications\n",
    "- **Implement production-grade logging** with Python's `logging` module\n",
    "- **Add comprehensive error handling** with try/except patterns\n",
    "- **Build structured outputs** using Pydantic models\n",
    "- **Visualize agent workflows** with LangGraph's built-in diagram tools\n",
    "- **Manage persistent state** with thread-based memory\n",
    "- **Test and validate** complex agent workflows\n",
    "- **Learn from user corrections** to adapt agent behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### The Scenario\n",
    "\n",
    "You're a PhD student juggling multiple research projects. You need an agent that can:\n",
    "\n",
    "- Find and organize academic papers\n",
    "- Schedule reading time on your calendar\n",
    "- Maintain your bibliography database\n",
    "- Remember your preferences (morning meetings, favorite journals)\n",
    "- Learn from your corrections\n",
    "\n",
    "### Single-Agent Architecture\n",
    "\n",
    "Unlike multi-agent systems where specialists collaborate, a **single agent** coordinates all capabilities through:\n",
    "\n",
    "1. **Unified state management**: One state tracks all context\n",
    "2. **Tool orchestration**: Agent decides which tools to use when\n",
    "3. **Integrated memory**: Preferences and context persist across sessions\n",
    "4. **Adaptive behavior**: Learns from user feedback\n",
    "\n",
    "**When to use this pattern**:\n",
    "- Tasks are related and share context\n",
    "- Coordination overhead of multiple agents isn't justified\n",
    "- User expects seamless, conversational interaction\n",
    "\n",
    "### Production Patterns You'll Learn\n",
    "\n",
    "This lab teaches **real-world engineering practices**:\n",
    "\n",
    "- **Logging**: Replace `print()` with proper logging for debugging\n",
    "- **Error handling**: Gracefully handle tool failures\n",
    "- **Structured outputs**: Use Pydantic for type-safe tool responses\n",
    "- **Graph visualization**: Understand agent flow with diagrams\n",
    "- **Thread management**: Understand LangGraph's session isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "### Install Required Packages\n",
    "\n",
    "We'll install the **latest stable versions** of:\n",
    "- **LangGraph 1.0+**: Agent workflow framework (currently 1.0.3)\n",
    "- **LangChain 1.0+**: Core LLM abstractions\n",
    "- **LangChain OpenAI**: OpenAI model integration\n",
    "- **Requests**: HTTP client for API calls\n",
    "\n",
    "**Version 1.0 Upgrade Notes**:\n",
    "- LangGraph 1.0 has ZERO breaking changes from 0.6.6 - all APIs remain backward compatible\n",
    "- LangChain 1.0 requires Python 3.10+ and has minor package structure changes\n",
    "- All existing code patterns work without modification in 1.0\n",
    "\n",
    "**Note on version specs**: We use quotes to prevent shell glob expansion issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU \\\n",
    "    langgraph > 1.0.0\\\n",
    "    langchain > 1.0.0 \\\n",
    "    langchain-openai > 1.0.0 \\\n",
    "    requests > 2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b52c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show langgraph langchain langchain-openai requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "### Import Dependencies and Configure Logging\n",
    "\n",
    "**Production Pattern**: Always set up logging at the start of your application.\n",
    "\n",
    "**Why logging over print()**:\n",
    "- **Levels**: DEBUG, INFO, WARNING, ERROR, CRITICAL for filtering\n",
    "- **Timestamps**: Automatic timestamps for debugging\n",
    "- **Configurability**: Easy to redirect to files, disable in production\n",
    "- **Context**: Logger names help identify source of messages\n",
    "\n",
    "**Log levels we'll use**:\n",
    "- `logger.debug()`: Detailed diagnostic information\n",
    "- `logger.info()`: Confirmation that things are working\n",
    "- `logger.warning()`: Something unexpected but recoverable\n",
    "- `logger.error()`: Serious problem, function failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import getpass\n",
    "import logging\n",
    "from typing import TypedDict, Annotated, List, Dict, Any, Optional\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# LangChain/LangGraph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Create logger for this module\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-key-header",
   "metadata": {},
   "source": [
    "### Configure API Keys and LLM\n",
    "\n",
    "**Security best practice**: Never hardcode API keys. Always use environment variables or secret management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "api-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key setup\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "    logger.info(\"OpenAI API key configured from user input\")\n",
    "else:\n",
    "    logger.info(\"OpenAI API key found in environment\")\n",
    "\n",
    "# Initialize LLM\n",
    "try:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    logger.info(\"LLM initialized: gpt-4o-mini with temperature=0\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to initialize LLM: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "state-header",
   "metadata": {},
   "source": [
    "## Step 1: Design the State Structure\n",
    "\n",
    "### What is State?\n",
    "\n",
    "State is the **memory** of your agent. It persists across multiple turns of conversation and tool executions.\n",
    "\n",
    "### Our State Design\n",
    "\n",
    "For a research assistant, we need to track:\n",
    "\n",
    "1. **`messages`**: All user-agent interactions (conversation history)\n",
    "2. **`research_context`**: Current research topic, active papers, tasks\n",
    "3. **`tool_results`**: Structured outputs from calendar, search, files\n",
    "4. **`preferences`**: Learned behaviors (morning meetings, reading duration)\n",
    "5. **`current_task`**: What the agent is currently working on\n",
    "\n",
    "### Design Decision: Single State vs. Multiple Agents\n",
    "\n",
    "We use a **single state dictionary** instead of multiple agents because:\n",
    "- All tools share the research context\n",
    "- Preferences affect all capabilities (scheduling, file organization)\n",
    "- Conversational flow is unified (one conversation thread)\n",
    "\n",
    "### The `add_messages` Reducer\n",
    "\n",
    "`Annotated[list, add_messages]` is a special LangGraph pattern that:\n",
    "- Automatically appends new messages to the conversation\n",
    "- Handles message deduplication\n",
    "- Maintains chronological order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "state-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchAssistantState(TypedDict):\n",
    "    \"\"\"State for academic research assistant agent.\n",
    "    \n",
    "    Attributes:\n",
    "        messages: Conversation history with automatic message appending\n",
    "        research_context: Current research topic, active papers, ongoing tasks\n",
    "        tool_results: Structured results from tool executions\n",
    "        preferences: User preferences learned over time\n",
    "        current_task: Description of what the agent is currently working on\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "    research_context: Dict[str, Any]\n",
    "    tool_results: List[Dict[str, Any]]\n",
    "    preferences: Dict[str, str]\n",
    "    current_task: str\n",
    "\n",
    "\n",
    "def create_initial_state() -> ResearchAssistantState:\n",
    "    \"\"\"Create initial state with default preferences.\n",
    "    \n",
    "    Returns:\n",
    "        ResearchAssistantState with empty messages and default preferences\n",
    "    \"\"\"\n",
    "    logger.debug(\"Creating initial state with default preferences\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [],\n",
    "        \"research_context\": {},\n",
    "        \"tool_results\": [],\n",
    "        \"preferences\": {\n",
    "            \"meeting_time\": \"morning\",\n",
    "            \"reading_duration\": \"30min\"\n",
    "        },\n",
    "        \"current_task\": \"\"\n",
    "    }\n",
    "\n",
    "logger.info(\"State structure defined: ResearchAssistantState\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-outputs-header",
   "metadata": {},
   "source": [
    "## Step 2: Define Structured Outputs with Pydantic\n",
    "\n",
    "### Why Pydantic Models?\n",
    "\n",
    "**Production pattern**: Use Pydantic models for tool outputs to ensure:\n",
    "- **Type safety**: Catch errors at definition time, not runtime\n",
    "- **Validation**: Automatic data validation\n",
    "- **Documentation**: Self-documenting code\n",
    "- **IDE support**: Autocomplete and type hints\n",
    "\n",
    "### Our Models\n",
    "\n",
    "We'll define Pydantic models for:\n",
    "1. **Paper**: Represents an academic paper\n",
    "2. **PaperSearchResult**: Structured response from paper search\n",
    "3. **CalendarEvent**: Represents a scheduled event\n",
    "4. **BibliographyEntry**: Citation database entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pydantic-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paper(BaseModel):\n",
    "    \"\"\"Represents an academic paper.\"\"\"\n",
    "    title: str = Field(description=\"Paper title\")\n",
    "    authors: str = Field(description=\"Comma-separated list of authors\")\n",
    "    year: int = Field(description=\"Publication year\")\n",
    "    abstract: str = Field(description=\"Paper abstract or summary\")\n",
    "    \n",
    "\n",
    "class PaperSearchResult(BaseModel):\n",
    "    \"\"\"Structured result from paper search.\"\"\"\n",
    "    query: str = Field(description=\"Search query used\")\n",
    "    papers: List[Paper] = Field(description=\"List of papers found\")\n",
    "    total_found: int = Field(description=\"Total number of papers found\")\n",
    "    \n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    \"\"\"Represents a calendar event.\"\"\"\n",
    "    title: str = Field(description=\"Event title\")\n",
    "    date: str = Field(description=\"Event date (YYYY-MM-DD)\")\n",
    "    time: str = Field(description=\"Event time (HH:MM AM/PM)\")\n",
    "    duration_min: int = Field(description=\"Duration in minutes\")\n",
    "    \n",
    "\n",
    "class BibliographyEntry(BaseModel):\n",
    "    \"\"\"Represents a bibliography entry.\"\"\"\n",
    "    citation_key: str = Field(description=\"BibTeX citation key\")\n",
    "    title: str = Field(description=\"Paper title\")\n",
    "    authors: str = Field(description=\"Authors\")\n",
    "    year: str = Field(description=\"Publication year\")\n",
    "\n",
    "logger.info(\"Pydantic models defined: Paper, PaperSearchResult, CalendarEvent, BibliographyEntry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-header",
   "metadata": {},
   "source": [
    "## Step 3: Build the Tool Suite\n",
    "\n",
    "### Production Tool Pattern\n",
    "\n",
    "Each tool follows this pattern:\n",
    "1. **Structured inputs**: Type hints for all parameters\n",
    "2. **Error handling**: Try/except blocks for all operations\n",
    "3. **Logging**: Log entry, success, and failures\n",
    "4. **Structured outputs**: Return Pydantic models (converted to strings for LLM)\n",
    "5. **Documentation**: Clear docstrings\n",
    "\n",
    "### Our Tool Suite\n",
    "\n",
    "1. **Paper Search**: Find academic papers by query\n",
    "2. **File Organizer**: Create folders, organize files\n",
    "3. **Calendar Manager**: Schedule events, check availability\n",
    "4. **Bibliography Tracker**: Maintain citation database\n",
    "\n",
    "**Note**: These are simulated tools. In production, you'd integrate with:\n",
    "- ArXiv/Semantic Scholar APIs\n",
    "- Google Calendar API\n",
    "- File system operations\n",
    "- SQLite or BibTeX databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool-paper-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_papers_tool(query: str, limit: int = 5) -> str:\n",
    "    \"\"\"Search for academic papers on a given topic.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query (e.g., 'transformers', 'neural networks')\n",
    "        limit: Maximum number of papers to return (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        JSON string of PaperSearchResult with found papers\n",
    "    \"\"\"\n",
    "    logger.info(f\"Searching for papers: query='{query}', limit={limit}\")\n",
    "    \n",
    "    try:\n",
    "        # Simulated paper search (in production: call ArXiv/Semantic Scholar API)\n",
    "        papers = [\n",
    "            Paper(\n",
    "                title=f\"Advances in {query}: A Comprehensive Survey #{i+1}\",\n",
    "                authors=\"Smith, J., Jones, A., Lee, K.\",\n",
    "                year=2024 - i,\n",
    "                abstract=f\"This paper explores {query} using novel methods and provides comprehensive analysis of state-of-the-art approaches.\"\n",
    "            )\n",
    "            for i in range(min(limit, 5))\n",
    "        ]\n",
    "        \n",
    "        result = PaperSearchResult(\n",
    "            query=query,\n",
    "            papers=papers,\n",
    "            total_found=len(papers)\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Found {len(papers)} papers for query '{query}'\")\n",
    "        return result.model_dump_json(indent=2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Paper search failed: {e}\")\n",
    "        return f\"Error searching for papers: {str(e)}\"\n",
    "\n",
    "logger.info(\"Tool registered: search_papers_tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool-file-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def organize_files_tool(papers: List[str], category: str) -> str:\n",
    "    \"\"\"Organize paper files into categorized folders.\n",
    "    \n",
    "    Args:\n",
    "        papers: List of paper titles to organize\n",
    "        category: Category/folder name (e.g., 'Machine Learning')\n",
    "        \n",
    "    Returns:\n",
    "        Status message with organization details\n",
    "    \"\"\"\n",
    "    logger.info(f\"Organizing {len(papers)} papers into category '{category}'\")\n",
    "    \n",
    "    try:\n",
    "        # Simulated file organization (in production: use pathlib/os)\n",
    "        folder_name = f\"research_{category.lower().replace(' ', '_')}\"\n",
    "        \n",
    "        result = f\"✓ Organized {len(papers)} papers into folder '{folder_name}/':\\n\\n\"\n",
    "        for i, paper in enumerate(papers, 1):\n",
    "            result += f\"  {i}. {paper}\\n\"\n",
    "        \n",
    "        result += f\"\\n✓ Files organized successfully in {folder_name}/\"\n",
    "        \n",
    "        logger.info(f\"Successfully organized {len(papers)} papers\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"File organization failed: {e}\")\n",
    "        return f\"Error organizing files: {str(e)}\"\n",
    "\n",
    "logger.info(\"Tool registered: organize_files_tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def schedule_event_tool(title: str, duration_min: int, preferred_time: str = \"morning\") -> str:\n",
    "    \"\"\"Schedule an event on the calendar.\n",
    "    \n",
    "    Args:\n",
    "        title: Event title\n",
    "        duration_min: Duration in minutes\n",
    "        preferred_time: 'morning', 'afternoon', or 'evening' (default: 'morning')\n",
    "        \n",
    "    Returns:\n",
    "        JSON string of CalendarEvent with scheduled details\n",
    "    \"\"\"\n",
    "    logger.info(f\"Scheduling event: '{title}' for {duration_min} min ({preferred_time})\")\n",
    "    \n",
    "    try:\n",
    "        # Simulated calendar scheduling (in production: call Google Calendar API)\n",
    "        time_map = {\n",
    "            \"morning\": \"10:00 AM\",\n",
    "            \"afternoon\": \"2:00 PM\",\n",
    "            \"evening\": \"5:00 PM\"\n",
    "        }\n",
    "        \n",
    "        time_slot = time_map.get(preferred_time.lower(), \"10:00 AM\")\n",
    "        tomorrow = (datetime.now() + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        event = CalendarEvent(\n",
    "            title=title,\n",
    "            date=tomorrow,\n",
    "            time=time_slot,\n",
    "            duration_min=duration_min\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Event scheduled: {title} on {tomorrow} at {time_slot}\")\n",
    "        return event.model_dump_json(indent=2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Calendar scheduling failed: {e}\")\n",
    "        return f\"Error scheduling event: {str(e)}\"\n",
    "\n",
    "logger.info(\"Tool registered: schedule_event_tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def update_bibliography_tool(paper_title: str, authors: str, year: str) -> str:\n",
    "    \"\"\"Add a paper to the bibliography database.\n",
    "    \n",
    "    Args:\n",
    "        paper_title: Full title of the paper\n",
    "        authors: Comma-separated list of authors\n",
    "        year: Publication year\n",
    "        \n",
    "    Returns:\n",
    "        JSON string of BibliographyEntry with citation key\n",
    "    \"\"\"\n",
    "    logger.info(f\"Adding to bibliography: '{paper_title}' ({year})\")\n",
    "    \n",
    "    try:\n",
    "        # Simulated bibliography update (in production: use SQLite/BibTeX)\n",
    "        first_author_last = authors.split(',')[0].split()[-1]\n",
    "        citation_key = f\"{first_author_last}{year}\"\n",
    "        \n",
    "        entry = BibliographyEntry(\n",
    "            citation_key=citation_key,\n",
    "            title=paper_title,\n",
    "            authors=authors,\n",
    "            year=year\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Bibliography entry created: {citation_key}\")\n",
    "        return entry.model_dump_json(indent=2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Bibliography update failed: {e}\")\n",
    "        return f\"Error updating bibliography: {str(e)}\"\n",
    "\n",
    "logger.info(\"Tool registered: update_bibliography_tool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-binding-header",
   "metadata": {},
   "source": [
    "### Bind Tools to LLM\n",
    "\n",
    "Now we bind all tools to the LLM, enabling it to call them during conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tools-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tools\n",
    "tools = [\n",
    "    search_papers_tool,\n",
    "    organize_files_tool,\n",
    "    schedule_event_tool,\n",
    "    update_bibliography_tool\n",
    "]\n",
    "\n",
    "# Bind tools to LLM\n",
    "try:\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    logger.info(f\"Successfully bound {len(tools)} tools to LLM\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to bind tools: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graph-nodes-header",
   "metadata": {},
   "source": [
    "## Step 4: Build the Agent Graph\n",
    "\n",
    "### LangGraph Architecture\n",
    "\n",
    "Our agent follows this workflow:\n",
    "\n",
    "```\n",
    "START → agent → [has tool calls?] → tools → agent → END\n",
    "                      ↓ (no)\n",
    "                     END\n",
    "```\n",
    "\n",
    "**Nodes**:\n",
    "1. **agent**: Reasons about user input and decides which tools to call\n",
    "2. **tools**: Executes tool calls and returns results\n",
    "\n",
    "**Conditional edges**:\n",
    "- If agent produces tool calls → go to **tools** node\n",
    "- If no tool calls → conversation is complete, go to **END**\n",
    "\n",
    "### Error Handling in Nodes\n",
    "\n",
    "Each node wraps operations in try/except blocks to:\n",
    "- Catch and log errors\n",
    "- Return helpful error messages to the LLM\n",
    "- Prevent the agent from crashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent-node",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state: ResearchAssistantState) -> ResearchAssistantState:\n",
    "    \"\"\"Main agent reasoning node.\n",
    "    \n",
    "    Receives current state, invokes LLM with tools, and returns updated state.\n",
    "    \n",
    "    Args:\n",
    "        state: Current agent state\n",
    "        \n",
    "    Returns:\n",
    "        Updated state with agent's response\n",
    "    \"\"\"\n",
    "    logger.debug(\"Agent node: Processing request\")\n",
    "    \n",
    "    try:\n",
    "        messages = state[\"messages\"]\n",
    "        logger.debug(f\"Agent node: {len(messages)} messages in history\")\n",
    "        \n",
    "        # Invoke LLM with bound tools\n",
    "        response = llm_with_tools.invoke(messages)\n",
    "        \n",
    "        # Check if tool calls were made\n",
    "        if hasattr(response, \"tool_calls\") and response.tool_calls:\n",
    "            logger.info(f\"Agent requested {len(response.tool_calls)} tool call(s)\")\n",
    "        else:\n",
    "            logger.info(\"Agent completed without tool calls\")\n",
    "        \n",
    "        return {\"messages\": [response]}\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Agent node failed: {e}\")\n",
    "        error_msg = AIMessage(content=f\"I encountered an error: {str(e)}. Please try again.\")\n",
    "        return {\"messages\": [error_msg]}\n",
    "\n",
    "logger.info(\"Agent node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tools-node",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_node(state: ResearchAssistantState) -> ResearchAssistantState:\n",
    "    \"\"\"Execute tool calls from agent.\n",
    "    \n",
    "    Extracts tool calls from last message, executes each tool,\n",
    "    and returns results as ToolMessages.\n",
    "    \n",
    "    Args:\n",
    "        state: Current agent state\n",
    "        \n",
    "    Returns:\n",
    "        Updated state with tool results\n",
    "    \"\"\"\n",
    "    logger.debug(\"Tools node: Executing tool calls\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    tool_results = []\n",
    "    new_messages = []\n",
    "    \n",
    "    # Execute each tool call\n",
    "    for tool_call in last_message.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        tool_call_id = tool_call[\"id\"]\n",
    "        \n",
    "        logger.info(f\"Executing tool: {tool_name} with args: {tool_args}\")\n",
    "        \n",
    "        try:\n",
    "            # Find and execute the tool\n",
    "            tool_map = {tool.name: tool for tool in tools}\n",
    "            \n",
    "            if tool_name not in tool_map:\n",
    "                error_msg = f\"Unknown tool: {tool_name}\"\n",
    "                logger.error(error_msg)\n",
    "                result = error_msg\n",
    "            else:\n",
    "                result = tool_map[tool_name].invoke(tool_args)\n",
    "                logger.info(f\"Tool {tool_name} executed successfully\")\n",
    "            \n",
    "            # Store result\n",
    "            tool_results.append({\n",
    "                \"tool\": tool_name,\n",
    "                \"result\": result,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            # Create tool message\n",
    "            new_messages.append(\n",
    "                ToolMessage(content=str(result), tool_call_id=tool_call_id)\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Tool {tool_name} failed: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            \n",
    "            # Return error as tool message\n",
    "            new_messages.append(\n",
    "                ToolMessage(content=error_msg, tool_call_id=tool_call_id)\n",
    "            )\n",
    "    \n",
    "    logger.info(f\"Tools node: Executed {len(tool_results)} tool(s)\")\n",
    "    return {\"messages\": new_messages, \"tool_results\": tool_results}\n",
    "\n",
    "logger.info(\"Tools node defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graph-construction-header",
   "metadata": {},
   "source": [
    "### Construct the Graph\n",
    "\n",
    "Now we'll build the complete workflow graph:\n",
    "\n",
    "1. Define the conditional edge logic\n",
    "2. Create the StateGraph\n",
    "3. Add nodes and edges\n",
    "4. Compile with memory checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graph-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: ResearchAssistantState) -> str:\n",
    "    \"\"\"Determine if we should continue to tools or end.\n",
    "    \n",
    "    Args:\n",
    "        state: Current agent state\n",
    "        \n",
    "    Returns:\n",
    "        'tools' if tool calls present, END otherwise\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If there are tool calls, continue to tools node\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        logger.debug(\"Conditional edge: Routing to tools node\")\n",
    "        return \"tools\"\n",
    "    \n",
    "    # Otherwise, end\n",
    "    logger.debug(\"Conditional edge: Routing to END\")\n",
    "    return END\n",
    "\n",
    "\n",
    "# Create the graph\n",
    "logger.info(\"Building agent graph...\")\n",
    "\n",
    "try:\n",
    "    builder = StateGraph(ResearchAssistantState)\n",
    "    \n",
    "    # Add nodes\n",
    "    builder.add_node(\"agent\", agent_node)\n",
    "    builder.add_node(\"tools\", tool_node)\n",
    "    logger.debug(\"Nodes added: agent, tools\")\n",
    "    \n",
    "    # Define flow\n",
    "    builder.add_edge(START, \"agent\")\n",
    "    builder.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\"tools\": \"tools\", END: END}\n",
    "    )\n",
    "    builder.add_edge(\"tools\", \"agent\")\n",
    "    logger.debug(\"Edges added: START->agent, agent->tools/END, tools->agent\")\n",
    "    \n",
    "    # Compile with memory\n",
    "    memory = MemorySaver()\n",
    "    agent = builder.compile(checkpointer=memory)\n",
    "    \n",
    "    logger.info(\"✓ Agent graph compiled successfully with memory checkpointer\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to build agent graph: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graph-visualization-header",
   "metadata": {},
   "source": [
    "## Step 5: Visualize the Agent Workflow\n",
    "\n",
    "### Understanding the Graph\n",
    "\n",
    "LangGraph provides built-in visualization to help you understand the agent's workflow.\n",
    "\n",
    "**What you'll see**:\n",
    "- **Nodes**: Circles representing computation steps (agent, tools)\n",
    "- **Edges**: Arrows showing flow between steps\n",
    "- **Conditional edges**: Diamond shapes showing decision points\n",
    "\n",
    "This visualization is crucial for:\n",
    "- Debugging complex workflows\n",
    "- Understanding agent behavior\n",
    "- Communicating architecture to teammates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graph-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    # Generate graph visualization\n",
    "    graph_image = agent.get_graph().draw_mermaid_png()\n",
    "    \n",
    "    # Display in notebook\n",
    "    display(Image(graph_image))\n",
    "    \n",
    "    logger.info(\"Graph visualization displayed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.warning(f\"Could not display graph visualization: {e}\")\n",
    "    logger.info(\"Graph structure: START -> agent -> [conditional] -> tools -> agent -> END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thread-id-header",
   "metadata": {},
   "source": [
    "## Understanding thread_id: Session Isolation\n",
    "\n",
    "### What is thread_id?\n",
    "\n",
    "In LangGraph, `thread_id` is a **session identifier** that isolates conversation state.\n",
    "\n",
    "### How it Works\n",
    "\n",
    "```python\n",
    "    config = {\"configurable\": {\"thread_id\": \"user-123\"}}\n",
    "```\n",
    "\n",
    "- **Same thread_id**: Messages and state are shared (multi-turn conversation)\n",
    "- **Different thread_id**: Completely isolated sessions\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "**Scenario 1: Same user, same conversation** (example code)\n",
    "```python\n",
    "    config = {\"configurable\": {\"thread_id\": \"user-123\"}}\n",
    "\n",
    "    # Turn 1\n",
    "    chat(\"Find papers on transformers\", config)\n",
    "    # Agent remembers: query=\"transformers\", found 5 papers\n",
    "\n",
    "    # Turn 2 (same thread)\n",
    "    chat(\"Schedule time to read the first one\", config)\n",
    "    # Agent knows which paper: \"Advances in transformers: Survey #1\"\n",
    "```\n",
    "\n",
    "**Scenario 2: Different users** (example code)\n",
    "```python\n",
    "    config_alice = {\"configurable\": {\"thread_id\": \"alice-session\"}}\n",
    "    config_bob = {\"configurable\": {\"thread_id\": \"bob-session\"}}\n",
    "\n",
    "    # Alice's session\n",
    "    chat(\"Find papers on NLP\", config_alice)\n",
    "\n",
    "    # Bob's session (isolated from Alice)\n",
    "    chat(\"Find papers on computer vision\", config_bob)\n",
    "```\n",
    "\n",
    "### Production Use Cases\n",
    "\n",
    "- **Web applications**: `thread_id = user_id` or `session_id`\n",
    "- **Slack bots**: `thread_id = channel_id + thread_ts`\n",
    "- **Multi-tenant systems**: `thread_id = tenant_id + conversation_id`\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Use meaningful IDs**: `user-123-session-456`, not `thread-1`\n",
    "2. **Document your schema**: What does each thread_id represent?\n",
    "3. **Handle cleanup**: Old threads consume memory (implement expiration)\n",
    "4. **Test isolation**: Verify different threads don't leak state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chat-interface-header",
   "metadata": {},
   "source": [
    "## Step 6: Build the Chat Interface\n",
    "\n",
    "### Chat Function Design\n",
    "\n",
    "Our chat function:\n",
    "1. Retrieves or creates state for the given thread\n",
    "2. Adds user message to state\n",
    "3. Invokes agent graph\n",
    "4. Returns agent's response\n",
    "5. Automatically persists state for future turns\n",
    "\n",
    "**Error handling**: We wrap the entire conversation in try/except to gracefully handle failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chat-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, config: dict) -> str:\n",
    "    \"\"\"Send a message and get response.\n",
    "    \n",
    "    Args:\n",
    "        user_input: User's message\n",
    "        config: Configuration dict with thread_id\n",
    "        \n",
    "    Returns:\n",
    "        Agent's response text\n",
    "    \"\"\"\n",
    "    thread_id = config.get(\"configurable\", {}).get(\"thread_id\", \"unknown\")\n",
    "    logger.info(f\"Chat request [thread={thread_id}]: {user_input[:50]}...\")\n",
    "    \n",
    "    try:\n",
    "        # Get current state or create new\n",
    "        state = agent.get_state(config)\n",
    "        \n",
    "        if state.values:\n",
    "            current_state = state.values\n",
    "            logger.debug(f\"Retrieved existing state for thread {thread_id}\")\n",
    "        else:\n",
    "            current_state = create_initial_state()\n",
    "            logger.debug(f\"Created new state for thread {thread_id}\")\n",
    "        \n",
    "        # Add user message\n",
    "        current_state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        \n",
    "        # Run agent\n",
    "        result = agent.invoke(current_state, config)\n",
    "        \n",
    "        # Extract last AI message\n",
    "        response = result[\"messages\"][-1].content\n",
    "        \n",
    "        logger.info(f\"Chat response [thread={thread_id}]: {response[:50]}...\")\n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Chat failed [thread={thread_id}]: {e}\")\n",
    "        return f\"I encountered an error: {str(e)}. Please try again.\"\n",
    "\n",
    "logger.info(\"Chat interface ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "learning-header",
   "metadata": {},
   "source": [
    "## Step 7: Learn from User Corrections\n",
    "\n",
    "### Adaptive Learning Pattern\n",
    "\n",
    "When users correct the agent, we update preferences:\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "User: \"Schedule a review meeting\"\n",
    "Agent: [schedules for 2pm]\n",
    "User: \"No, I prefer mornings\"\n",
    "Agent: [updates preferences] \"Changed to 10am. I'll remember.\"\n",
    "```\n",
    "\n",
    "### Detection Logic\n",
    "\n",
    "We detect corrections by looking for:\n",
    "1. **Negation words**: \"no\", \"actually\", \"instead\"\n",
    "2. **Preference indicators**: \"prefer\", \"like\", \"better\"\n",
    "3. **Specific values**: \"morning\", \"afternoon\", \"30 minutes\"\n",
    "\n",
    "### Implementation\n",
    "\n",
    "The `detect_correction()` function extracts structured corrections from natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learning-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_correction(message: str) -> Dict[str, str]:\n",
    "    \"\"\"Detect if user is correcting agent behavior.\n",
    "    \n",
    "    Args:\n",
    "        message: User's message\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of detected corrections (e.g., {'meeting_time': 'morning'})\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Checking for corrections in: {message}\")\n",
    "    \n",
    "    message_lower = message.lower()\n",
    "    corrections = {}\n",
    "    \n",
    "    try:\n",
    "        # Check for time preference corrections\n",
    "        if any(word in message_lower for word in [\"no\", \"actually\", \"prefer\", \"instead\"]):\n",
    "            if \"morning\" in message_lower:\n",
    "                corrections[\"meeting_time\"] = \"morning\"\n",
    "                logger.info(\"Detected preference: morning meetings\")\n",
    "            elif \"afternoon\" in message_lower:\n",
    "                corrections[\"meeting_time\"] = \"afternoon\"\n",
    "                logger.info(\"Detected preference: afternoon meetings\")\n",
    "            elif \"evening\" in message_lower:\n",
    "                corrections[\"meeting_time\"] = \"evening\"\n",
    "                logger.info(\"Detected preference: evening meetings\")\n",
    "        \n",
    "        # Check for duration preferences\n",
    "        if \"30\" in message_lower and \"min\" in message_lower:\n",
    "            corrections[\"reading_duration\"] = \"30min\"\n",
    "            logger.info(\"Detected preference: 30min duration\")\n",
    "        elif \"60\" in message_lower and \"min\" in message_lower:\n",
    "            corrections[\"reading_duration\"] = \"60min\"\n",
    "            logger.info(\"Detected preference: 60min duration\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Correction detection failed: {e}\")\n",
    "    \n",
    "    return corrections\n",
    "\n",
    "logger.info(\"Correction detection function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learning-chat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_learning(user_input: str, config: dict) -> str:\n",
    "    \"\"\"Chat with preference learning.\n",
    "    \n",
    "    Extends basic chat to detect and learn from user corrections.\n",
    "    \n",
    "    Args:\n",
    "        user_input: User's message\n",
    "        config: Configuration dict with thread_id\n",
    "        \n",
    "    Returns:\n",
    "        Agent's response text\n",
    "    \"\"\"\n",
    "    thread_id = config.get(\"configurable\", {}).get(\"thread_id\", \"unknown\")\n",
    "    logger.info(f\"Chat with learning [thread={thread_id}]: {user_input[:50]}...\")\n",
    "    \n",
    "    try:\n",
    "        # Get current state or create new\n",
    "        state = agent.get_state(config)\n",
    "        \n",
    "        if state.values:\n",
    "            current_state = state.values\n",
    "        else:\n",
    "            current_state = create_initial_state()\n",
    "        \n",
    "        # Check for corrections and update preferences\n",
    "        corrections = detect_correction(user_input)\n",
    "        if corrections:\n",
    "            current_state[\"preferences\"].update(corrections)\n",
    "            logger.info(f\"Updated preferences [thread={thread_id}]: {corrections}\")\n",
    "        \n",
    "        # Add user message\n",
    "        current_state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        \n",
    "        # Run agent\n",
    "        result = agent.invoke(current_state, config)\n",
    "        \n",
    "        # Extract response\n",
    "        response = result[\"messages\"][-1].content\n",
    "        \n",
    "        logger.info(f\"Response [thread={thread_id}]: {response[:50]}...\")\n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Chat with learning failed [thread={thread_id}]: {e}\")\n",
    "        return f\"I encountered an error: {str(e)}. Please try again.\"\n",
    "\n",
    "logger.info(\"Learning-enabled chat interface ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "testing-header",
   "metadata": {},
   "source": [
    "## Step 8: Test the Agent\n",
    "\n",
    "### Test Scenarios\n",
    "\n",
    "We'll validate:\n",
    "\n",
    "1. **Basic workflow**: Search papers + organize + add to bibliography\n",
    "2. **Multi-turn context**: Agent remembers previous results\n",
    "3. **Learning from corrections**: Preferences persist across turns\n",
    "4. **Error handling**: Graceful failure recovery\n",
    "\n",
    "### Expected Behavior\n",
    "\n",
    "Each test should:\n",
    "- Execute without exceptions\n",
    "- Log all operations\n",
    "- Return coherent responses\n",
    "- Maintain context across turns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test1-header",
   "metadata": {},
   "source": [
    "### Test 1: Basic Workflow\n",
    "\n",
    "**Goal**: Verify agent can search papers, organize them, and update bibliography in a single request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=\"*60)\n",
    "logger.info(\"TEST 1: Basic Workflow\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-basic-workflow\"}}\n",
    "\n",
    "response = chat_with_learning(\n",
    "    \"Find 3 papers on transformers and add the first one to my bibliography\",\n",
    "    config\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"USER: Find 3 papers on transformers and add the first one to my bibliography\")\n",
    "print(\"=\"*60)\n",
    "print(f\"AGENT: {response}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test2-header",
   "metadata": {},
   "source": [
    "### Test 2: Multi-Turn Context\n",
    "\n",
    "**Goal**: Verify agent maintains context across multiple conversation turns.\n",
    "\n",
    "**Turn 1**: Search for papers  \n",
    "**Turn 2**: Schedule time to read (agent must remember papers from Turn 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=\"*60)\n",
    "logger.info(\"TEST 2: Multi-Turn Context\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "config2 = {\"configurable\": {\"thread_id\": \"test-multi-turn\"}}\n",
    "\n",
    "# Turn 1\n",
    "response1 = chat_with_learning(\n",
    "    \"Find papers on attention mechanisms\",\n",
    "    config2\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TURN 1\")\n",
    "print(\"=\"*60)\n",
    "print(\"USER: Find papers on attention mechanisms\")\n",
    "print(\"=\"*60)\n",
    "print(f\"AGENT: {response1}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Turn 2\n",
    "response2 = chat_with_learning(\n",
    "    \"Schedule 30 minutes to read the top paper tomorrow morning\",\n",
    "    config2\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TURN 2\")\n",
    "print(\"=\"*60)\n",
    "print(\"USER: Schedule 30 minutes to read the top paper tomorrow morning\")\n",
    "print(\"=\"*60)\n",
    "print(f\"AGENT: {response2}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test3-header",
   "metadata": {},
   "source": [
    "### Test 3: Learning from Corrections\n",
    "\n",
    "**Goal**: Verify agent learns and applies user preferences.\n",
    "\n",
    "**Turn 1**: Schedule meeting (default: morning)  \n",
    "**Turn 2**: User corrects: \"No, I prefer afternoons\"  \n",
    "**Turn 3**: Schedule another meeting (should use afternoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=\"*60)\n",
    "logger.info(\"TEST 3: Learning from Corrections\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "config3 = {\"configurable\": {\"thread_id\": \"test-learning\"}}\n",
    "\n",
    "# Turn 1: Schedule with defaults\n",
    "response1 = chat_with_learning(\n",
    "    \"Schedule a paper review meeting for 60 minutes\",\n",
    "    config3\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TURN 1\")\n",
    "print(\"=\"*60)\n",
    "print(\"USER: Schedule a paper review meeting for 60 minutes\")\n",
    "print(\"=\"*60)\n",
    "print(f\"AGENT: {response1}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Turn 2: Correct preference\n",
    "response2 = chat_with_learning(\n",
    "    \"No, I prefer afternoon meetings\",\n",
    "    config3\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TURN 2\")\n",
    "print(\"=\"*60)\n",
    "print(\"USER: No, I prefer afternoon meetings\")\n",
    "print(\"=\"*60)\n",
    "print(f\"AGENT: {response2}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Turn 3: Apply learned preference\n",
    "response3 = chat_with_learning(\n",
    "    \"Schedule another review meeting for next week\",\n",
    "    config3\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TURN 3\")\n",
    "print(\"=\"*60)\n",
    "print(\"USER: Schedule another review meeting for next week\")\n",
    "print(\"=\"*60)\n",
    "print(f\"AGENT: {response3}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenges-header",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "Now that you've built a production-ready research assistant, try these extensions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenge1-header",
   "metadata": {},
   "source": [
    "## Challenge 1: Implement Priority-Based Task Queue\n",
    "\n",
    "### Goal\n",
    "Extend the agent to manage multiple research tasks with priorities.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "1. Add `task_queue: List[Dict]` to `ResearchAssistantState`\n",
    "2. Each task should have:\n",
    "   - `title`: Task description\n",
    "   - `priority`: Integer (1=highest, 5=lowest)\n",
    "   - `status`: \"pending\", \"in_progress\", or \"completed\"\n",
    "3. Create a new tool: `add_task_tool(title, priority)`\n",
    "4. Create a new tool: `show_queue_tool()` that returns sorted queue\n",
    "5. Agent should process high-priority tasks first\n",
    "\n",
    "### Example Usage\n",
    "```\n",
    "User: \"Add reading paper X to my queue (high priority)\"\n",
    "Agent: \"Added to queue with priority 1\"\n",
    "\n",
    "User: \"What's in my queue?\"\n",
    "Agent: \"You have 3 tasks:\n",
    "  1. [Priority 1] Read paper X\n",
    "  2. [Priority 2] Review notes\n",
    "  3. [Priority 3] Update bibliography\"\n",
    "```\n",
    "\n",
    "### Hints\n",
    "\n",
    "- Sort queue by priority: `sorted(tasks, key=lambda t: t['priority'])`\n",
    "- Use Pydantic model for task structure\n",
    "- Add logging for all queue operations\n",
    "- Include error handling for invalid priorities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenge1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# 1. Define Task Pydantic model\n",
    "# class Task(BaseModel):\n",
    "#     ...\n",
    "\n",
    "# 2. Create add_task_tool\n",
    "# @tool\n",
    "# def add_task_tool(...):\n",
    "#     ...\n",
    "\n",
    "# 3. Create show_queue_tool\n",
    "# @tool\n",
    "# def show_queue_tool(...):\n",
    "#     ...\n",
    "\n",
    "# 4. Test your implementation\n",
    "# config = {\"configurable\": {\"thread_id\": \"test-queue\"}}\n",
    "# response = chat_with_learning(\"Add task...\", config)\n",
    "\n",
    "logger.info(\"Challenge 1: Implement your solution above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenge2-header",
   "metadata": {},
   "source": [
    "## Challenge 2: Smart Scheduling with Conflict Detection\n",
    "\n",
    "### Goal\n",
    "Make the calendar manager detect conflicts and suggest alternatives.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "1. Maintain a list of scheduled events in state: `scheduled_events: List[CalendarEvent]`\n",
    "2. Enhance `schedule_event_tool` to:\n",
    "   - Check for time conflicts with existing events\n",
    "   - If conflict detected, find next available slot\n",
    "   - Respect user's preferred time-of-day\n",
    "   - Return suggestion: \"Conflict at 2pm. Next available: 3pm. Shall I book it?\"\n",
    "3. Add conflict resolution logic:\n",
    "   - Check ±30 minutes around requested time\n",
    "   - Suggest same day if possible, next day otherwise\n",
    "\n",
    "### Example Usage\n",
    "```\n",
    "User: \"Schedule meeting for 2pm\"\n",
    "Agent: \"Conflict detected at 2pm (already have 'Paper review'). \n",
    "        Next available afternoon slot: 3:30pm. Would you like to book it?\"\n",
    "\n",
    "User: \"Yes\"\n",
    "Agent: \"Scheduled for 3:30pm\"\n",
    "```\n",
    "\n",
    "### Hints\n",
    "\n",
    "- Convert times to `datetime` for comparison\n",
    "- Check overlaps: `new_start < existing_end and new_end > existing_start`\n",
    "- Increment time in 30-minute intervals to find next slot\n",
    "- Use logging to track conflict detection\n",
    "- Add error handling for invalid times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenge2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# 1. Add scheduled_events to state\n",
    "# (You'll need to modify ResearchAssistantState)\n",
    "\n",
    "# 2. Create conflict detection helper\n",
    "# def has_conflict(new_event, existing_events):\n",
    "#     ...\n",
    "\n",
    "# 3. Create next_available_slot helper\n",
    "# def find_next_slot(preferred_time, existing_events):\n",
    "#     ...\n",
    "\n",
    "# 4. Enhance schedule_event_tool\n",
    "# @tool\n",
    "# def schedule_event_tool_enhanced(...):\n",
    "#     # Check conflicts\n",
    "#     # Find alternatives if needed\n",
    "#     # Return suggestion\n",
    "#     ...\n",
    "\n",
    "# 5. Test your implementation\n",
    "# config = {\"configurable\": {\"thread_id\": \"test-conflicts\"}}\n",
    "# response1 = chat_with_learning(\"Schedule meeting at 2pm\", config)\n",
    "# response2 = chat_with_learning(\"Schedule another meeting at 2pm\", config)\n",
    "\n",
    "logger.info(\"Challenge 2: Implement your solution above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What You Built\n",
    "\n",
    "You've created a **production-ready single-agent system** using **LangGraph 1.0 + LangChain 1.0** that:\n",
    "\n",
    "✅ **Integrates multiple tools** in a unified architecture  \n",
    "✅ **Maintains conversational context** across multiple turns  \n",
    "✅ **Learns from user feedback** to improve over time  \n",
    "✅ **Handles errors gracefully** with comprehensive logging  \n",
    "✅ **Persists state** across sessions with thread-based memory  \n",
    "✅ **Uses structured outputs** with Pydantic for type safety  \n",
    "✅ **Visualizes workflows** with graph diagrams  \n",
    "\n",
    "### Version 1.0 Compatibility\n",
    "\n",
    "This lab is fully compatible with **LangGraph 1.0.3+ and LangChain 1.0+**:\n",
    "- ✅ Zero breaking changes from LangGraph 0.6.6\n",
    "- ✅ All APIs backward compatible\n",
    "- ✅ Works with latest OpenAI models (gpt-4o-mini)\n",
    "- ✅ Python 3.10+ required (LangChain 1.0 requirement)\n",
    "\n",
    "### Production Patterns You Learned\n",
    "\n",
    "1. **Logging**: Replace `print()` with proper logging levels\n",
    "2. **Error handling**: Try/except blocks in all tool operations\n",
    "3. **Structured outputs**: Pydantic models for type safety\n",
    "4. **Graph visualization**: Understanding agent flow\n",
    "5. **Thread isolation**: Session management with thread_id\n",
    "6. **Adaptive learning**: Detecting and applying user corrections\n",
    "\n",
    "### When to Use Single-Agent Architecture\n",
    "\n",
    "✅ **Good for**:\n",
    "- Related capabilities sharing context\n",
    "- Conversational user interaction\n",
    "- Centralized state management\n",
    "- Learning from user behavior\n",
    "\n",
    "❌ **Not ideal for**:\n",
    "- Highly specialized, independent tasks\n",
    "- Parallel execution required\n",
    "- Different reasoning strategies per task\n",
    "- Clear separation of concerns (use multi-agent instead)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Lab 2**: Build a Data Analysis Agent with code generation\n",
    "- **Lab 3**: Add production-grade error recovery and retries\n",
    "- **Lab 4**: Implement multi-agent collaboration\n",
    "- **Capstone**: Integrate all patterns into a complete system\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Always log, never print**: Logging is essential for debugging production systems\n",
    "2. **Handle all errors**: Every tool call should be wrapped in try/except\n",
    "3. **Use structured outputs**: Pydantic ensures type safety and validation\n",
    "4. **Visualize your graphs**: Understanding flow is crucial for debugging\n",
    "5. **Test thoroughly**: Multi-turn conversations reveal edge cases\n",
    "6. **Document thread_id usage**: Session isolation prevents data leaks\n",
    "\n",
    "**Great work!** You've built a real-world agent with production engineering practices using the latest stable versions of LangGraph and LangChain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
