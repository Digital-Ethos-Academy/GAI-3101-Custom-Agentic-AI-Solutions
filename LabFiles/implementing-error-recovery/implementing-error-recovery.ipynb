{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Error Recovery and Resilience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Difficulty**: Advanced - This lab introduces production patterns used in distributed systems.\n",
    "> If you're new to error recovery, focus on understanding the patterns conceptually first.\n",
    "> The code demonstrates industry-standard techniques but may feel complex initially - that's expected!\n",
    "\n",
    "> **Learning Outcomes:**\n",
    "> - Classify error types and recovery strategies\n",
    "> - Implement retry with exponential backoff\n",
    "> - Build circuit breaker patterns\n",
    "> - Handle partial failures gracefully\n",
    "> - Add production-grade logging and monitoring\n",
    "> - Design fallback mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, we will build a Multi-Source News Aggregator that demonstrates production-grade error handling and resilience patterns. This agent fetches news from multiple APIs and must handle:\n",
    "- Network failures and timeouts\n",
    "- Rate limiting (HTTP 429)\n",
    "- Partial failures (some sources work, others don't)\n",
    "- Service degradation without total failure\n",
    "\n",
    "### The Scenario\n",
    "\n",
    "You're building a news aggregator that pulls from 5 different APIs. In production:\n",
    "- APIs go down randomly\n",
    "- Rate limits are exceeded\n",
    "- Network is unreliable\n",
    "- Users expect results even if some sources fail\n",
    "\n",
    "Your agent must:\n",
    "- Retry failed requests intelligently\n",
    "- Use circuit breakers to prevent cascade failures\n",
    "- Aggregate partial results\n",
    "- Log errors for monitoring\n",
    "- Degrade gracefully\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**Error Recovery Patterns**:\n",
    "\n",
    "1. **Retry with Exponential Backoff**:\n",
    "```python\n",
    "attempt 1: wait 1s → retry\n",
    "attempt 2: wait 2s → retry\n",
    "attempt 3: wait 4s → retry\n",
    "attempt 4: fail permanently\n",
    "```\n",
    "\n",
    "2. **Circuit Breaker**:\n",
    "```\n",
    "Closed (normal) → failures exceed threshold → Open (fail fast)\n",
    "                                                    ↓\n",
    "                                          wait timeout period\n",
    "                                                    ↓\n",
    "                                          Half-Open (test)\n",
    "                                                    ↓\n",
    "                    success → Closed    OR    failure → Open\n",
    "```\n",
    "\n",
    "3. **Partial Failure Handling**:\n",
    "- 5 sources queried\n",
    "- 3 succeed, 2 fail\n",
    "- Return 3 results (not total failure)\n",
    "\n",
    "4. **Fallback Mechanisms**:\n",
    "- Primary API fails → Use cached results\n",
    "- Multiple APIs down → Use default content\n",
    "\n",
    "This pattern is essential when:\n",
    "- Dealing with external APIs\n",
    "- Building production systems\n",
    "- Reliability is critical\n",
    "- Failures are expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "### Install Required Packages\n",
    "\n",
    "We'll install the **latest stable versions** of:\n",
    "- **LangGraph 1.0+**: Agent workflow framework\n",
    "- **LangChain 1.0+**: Core LLM abstractions\n",
    "- **LangChain OpenAI**: OpenAI model integration\n",
    "- **Requests**: HTTP client for API simulation\n",
    "\n",
    "**Version 1.0 Upgrade Notes**:\n",
    "- LangGraph 1.0 has ZERO breaking changes from 0.6.6\n",
    "- LangChain 1.0 requires Python 3.10+\n",
    "- All resilience patterns work identically in version 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU \\\n",
    "    langgraph \\\n",
    "    langchain \\\n",
    "    langchain-openai \\\n",
    "    requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import getpass\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "from enum import Enum\n",
    "from datetime import datetime, timedelta\n",
    "from typing import TypedDict, Annotated, List, Dict, Any, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "# External libraries\n",
    "import requests\n",
    "\n",
    "# LangChain/LangGraph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# API key setup\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(\"✓ Environment configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Design Error Classification System\n",
    "\n",
    "Not all errors are equal. We need to classify errors to determine recovery strategy:\n",
    "\n",
    "**Error Categories**:\n",
    "\n",
    "1. **Transient** (temporary, worth retrying):\n",
    "   - Network timeouts\n",
    "   - HTTP 503 (Service Unavailable)\n",
    "   - HTTP 429 (Rate Limit)\n",
    "\n",
    "2. **Permanent** (won't fix with retry):\n",
    "   - HTTP 404 (Not Found)\n",
    "   - HTTP 401 (Unauthorized)\n",
    "   - Invalid API response format\n",
    "\n",
    "3. **Partial** (some components failed):\n",
    "   - 2 of 5 APIs failed\n",
    "   - Incomplete data\n",
    "\n",
    "**Recovery Actions**:\n",
    "- Transient → Retry with backoff\n",
    "- Permanent → Fail fast, don't retry\n",
    "- Partial → Return available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorType(Enum):\n",
    "    \"\"\"Error classification for recovery strategy.\"\"\"\n",
    "    TRANSIENT = \"transient\"  # Temporary, retry\n",
    "    PERMANENT = \"permanent\"  # Won't fix, fail fast\n",
    "    PARTIAL = \"partial\"  # Some success, some failure\n",
    "\n",
    "class ErrorInfo(BaseModel):\n",
    "    \"\"\"Information about an error.\"\"\"\n",
    "    error_type: ErrorType\n",
    "    message: str\n",
    "    source: str\n",
    "    timestamp: datetime = Field(default_factory=datetime.now)\n",
    "    retry_count: int = 0\n",
    "\n",
    "def classify_error(exception: Exception, source: str) -> ErrorInfo:\n",
    "    \"\"\"Classify error to determine recovery strategy.\"\"\"\n",
    "    \n",
    "    # Network/timeout errors - transient\n",
    "    if isinstance(exception, (requests.Timeout, requests.ConnectionError)):\n",
    "        return ErrorInfo(\n",
    "            error_type=ErrorType.TRANSIENT,\n",
    "            message=f\"Network error: {str(exception)}\",\n",
    "            source=source\n",
    "        )\n",
    "    \n",
    "    # HTTP errors\n",
    "    if isinstance(exception, requests.HTTPError):\n",
    "        status_code = exception.response.status_code\n",
    "        \n",
    "        # Transient HTTP errors\n",
    "        if status_code in [429, 503, 504]:\n",
    "            return ErrorInfo(\n",
    "                error_type=ErrorType.TRANSIENT,\n",
    "                message=f\"HTTP {status_code}: {exception}\",\n",
    "                source=source\n",
    "            )\n",
    "        \n",
    "        # Permanent HTTP errors\n",
    "        else:\n",
    "            return ErrorInfo(\n",
    "                error_type=ErrorType.PERMANENT,\n",
    "                message=f\"HTTP {status_code}: {exception}\",\n",
    "                source=source\n",
    "            )\n",
    "    \n",
    "    # Default: treat as permanent\n",
    "    return ErrorInfo(\n",
    "        error_type=ErrorType.PERMANENT,\n",
    "        message=f\"Unknown error: {str(exception)}\",\n",
    "        source=source\n",
    "    )\n",
    "\n",
    "print(\"✓ Error classification system defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Retry with Exponential Backoff\n",
    "\n",
    "Exponential backoff prevents overwhelming failing services:\n",
    "\n",
    "**Algorithm**:\n",
    "```python\n",
    "max_retries = 3\n",
    "base_delay = 1  # second\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        return call_api()\n",
    "    except TransientError:\n",
    "        delay = base_delay * (2 ** attempt)  # 1s, 2s, 4s\n",
    "        wait(delay)\n",
    "        continue\n",
    "    except PermanentError:\n",
    "        raise  # Don't retry\n",
    "```\n",
    "\n",
    "**Benefits**:\n",
    "- Gives service time to recover\n",
    "- Reduces server load\n",
    "- Prevents thundering herd problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetryConfig(BaseModel):\n",
    "    \"\"\"Configuration for retry logic.\"\"\"\n",
    "    max_retries: int = 3\n",
    "    base_delay: float = 1.0  # seconds\n",
    "    max_delay: float = 10.0  # seconds\n",
    "    jitter: bool = True  # Add randomness to prevent thundering herd\n",
    "\n",
    "def retry_with_backoff(\n",
    "    func,\n",
    "    *args,\n",
    "    config: RetryConfig = RetryConfig(),\n",
    "    source: str = \"unknown\",\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Execute function with exponential backoff retry.\"\"\"\n",
    "    \n",
    "    for attempt in range(config.max_retries + 1):\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            \n",
    "            if attempt > 0:\n",
    "                logger.info(f\"✓ {source}: Succeeded on attempt {attempt + 1}\")\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        except Exception as e:\n",
    "            error_info = classify_error(e, source)\n",
    "            error_info.retry_count = attempt\n",
    "            \n",
    "            # Don't retry permanent errors\n",
    "            if error_info.error_type == ErrorType.PERMANENT:\n",
    "                logger.error(f\"✗ {source}: Permanent error - {error_info.message}\")\n",
    "                raise\n",
    "            \n",
    "            # Last attempt - raise\n",
    "            if attempt == config.max_retries:\n",
    "                logger.error(f\"✗ {source}: Max retries exceeded - {error_info.message}\")\n",
    "                raise\n",
    "            \n",
    "            # Calculate backoff delay\n",
    "            delay = min(\n",
    "                config.base_delay * (2 ** attempt),\n",
    "                config.max_delay\n",
    "            )\n",
    "            \n",
    "            # Add jitter (randomness)\n",
    "            if config.jitter:\n",
    "                delay = delay * (0.5 + random.random())  # 50-150% of delay\n",
    "            \n",
    "            logger.warning(\n",
    "                f\"⚠ {source}: Attempt {attempt + 1} failed - {error_info.message}. \"\n",
    "                f\"Retrying in {delay:.2f}s...\"\n",
    "            )\n",
    "            \n",
    "            time.sleep(delay)\n",
    "\n",
    "print(\"✓ Retry with backoff implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Circuit Breaker Pattern\n",
    "\n",
    "Circuit breakers prevent cascading failures by failing fast when a service is down:\n",
    "\n",
    "**States**:\n",
    "1. **Closed** (normal): Requests pass through\n",
    "2. **Open** (failing): Requests fail immediately\n",
    "3. **Half-Open** (testing): Allow one request to test recovery\n",
    "\n",
    "**State Transitions**:\n",
    "```\n",
    "Closed:\n",
    "  - On success: stay Closed\n",
    "  - On failure: increment failure count\n",
    "  - If failures >= threshold: transition to Open\n",
    "\n",
    "Open:\n",
    "  - Fail all requests immediately\n",
    "  - After timeout: transition to Half-Open\n",
    "\n",
    "Half-Open:\n",
    "  - Allow one test request\n",
    "  - On success: transition to Closed, reset counts\n",
    "  - On failure: transition back to Open\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircuitState(Enum):\n",
    "    \"\"\"Circuit breaker states.\"\"\"\n",
    "    CLOSED = \"closed\"  # Normal operation\n",
    "    OPEN = \"open\"  # Failing fast\n",
    "    HALF_OPEN = \"half_open\"  # Testing recovery\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"Circuit breaker for preventing cascade failures.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        failure_threshold: int = 3,\n",
    "        timeout: float = 30.0,  # seconds\n",
    "        name: str = \"circuit\"\n",
    "    ):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.timeout = timeout\n",
    "        self.name = name\n",
    "        \n",
    "        self.state = CircuitState.CLOSED\n",
    "        self.failure_count = 0\n",
    "        self.last_failure_time = None\n",
    "        self.success_count = 0\n",
    "    \n",
    "    def call(self, func, *args, **kwargs):\n",
    "        \"\"\"Execute function through circuit breaker.\"\"\"\n",
    "        \n",
    "        # Check if we should transition from OPEN to HALF_OPEN\n",
    "        if self.state == CircuitState.OPEN:\n",
    "            if self.last_failure_time and \\\n",
    "               (datetime.now() - self.last_failure_time).total_seconds() >= self.timeout:\n",
    "                logger.info(f\"Circuit {self.name}: OPEN → HALF_OPEN (testing recovery)\")\n",
    "                self.state = CircuitState.HALF_OPEN\n",
    "            else:\n",
    "                raise Exception(f\"Circuit {self.name} is OPEN - failing fast\")\n",
    "        \n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            self._on_success()\n",
    "            return result\n",
    "        \n",
    "        except Exception as e:\n",
    "            self._on_failure()\n",
    "            raise\n",
    "    \n",
    "    def _on_success(self):\n",
    "        \"\"\"Handle successful call.\"\"\"\n",
    "        self.success_count += 1\n",
    "        \n",
    "        if self.state == CircuitState.HALF_OPEN:\n",
    "            logger.info(f\"Circuit {self.name}: HALF_OPEN → CLOSED (recovery confirmed)\")\n",
    "            self.state = CircuitState.CLOSED\n",
    "            self.failure_count = 0\n",
    "            self.last_failure_time = None\n",
    "    \n",
    "    def _on_failure(self):\n",
    "        \"\"\"Handle failed call.\"\"\"\n",
    "        self.failure_count += 1\n",
    "        self.last_failure_time = datetime.now()\n",
    "        \n",
    "        if self.state == CircuitState.HALF_OPEN:\n",
    "            logger.warning(f\"Circuit {self.name}: HALF_OPEN → OPEN (recovery failed)\")\n",
    "            self.state = CircuitState.OPEN\n",
    "        \n",
    "        elif self.state == CircuitState.CLOSED:\n",
    "            if self.failure_count >= self.failure_threshold:\n",
    "                logger.warning(\n",
    "                    f\"Circuit {self.name}: CLOSED → OPEN \"\n",
    "                    f\"({self.failure_count} failures >= {self.failure_threshold} threshold)\"\n",
    "                )\n",
    "                self.state = CircuitState.OPEN\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Manually reset circuit breaker.\"\"\"\n",
    "        self.state = CircuitState.CLOSED\n",
    "        self.failure_count = 0\n",
    "        self.last_failure_time = None\n",
    "        logger.info(f\"Circuit {self.name}: Manually reset to CLOSED\")\n",
    "\n",
    "print(\"✓ Circuit breaker implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build Simulated News Sources\n",
    "\n",
    "We'll simulate 5 news APIs with different failure modes:\n",
    "\n",
    "1. **Reliable API**: 95% success\n",
    "2. **Slow API**: Often times out\n",
    "3. **Rate-Limited API**: Returns 429 frequently\n",
    "4. **Flaky API**: Random failures\n",
    "5. **Down API**: Always fails\n",
    "\n",
    "This lets us test all recovery patterns.\n",
    "\n",
    "**Note**: We use realistic delays (1-3 seconds) so you can observe the exponential backoff in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsSource:\n",
    "    \"\"\"Simulated news API source with configurable failure modes.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        failure_rate: float = 0.0,\n",
    "        timeout_rate: float = 0.0,\n",
    "        rate_limit_rate: float = 0.0\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.failure_rate = failure_rate\n",
    "        self.timeout_rate = timeout_rate\n",
    "        self.rate_limit_rate = rate_limit_rate\n",
    "        self.call_count = 0\n",
    "    \n",
    "    def fetch_news(self, topic: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Fetch news articles (simulated).\"\"\"\n",
    "        self.call_count += 1\n",
    "        \n",
    "        # Simulate timeout with realistic delay (1-3 seconds)\n",
    "        # This makes retry backoff visible in logs\n",
    "        if random.random() < self.timeout_rate:\n",
    "            delay = random.uniform(1.0, 3.0)\n",
    "            logger.debug(f\"{self.name}: Simulating timeout after {delay:.1f}s delay\")\n",
    "            time.sleep(delay)\n",
    "            raise requests.Timeout(f\"{self.name}: Request timed out after {delay:.1f}s\")\n",
    "        \n",
    "        # Simulate rate limiting\n",
    "        if random.random() < self.rate_limit_rate:\n",
    "            response = requests.Response()\n",
    "            response.status_code = 429\n",
    "            raise requests.HTTPError(f\"{self.name}: Rate limit exceeded\", response=response)\n",
    "        \n",
    "        # Simulate general failure\n",
    "        if random.random() < self.failure_rate:\n",
    "            response = requests.Response()\n",
    "            response.status_code = 503\n",
    "            raise requests.HTTPError(f\"{self.name}: Service unavailable\", response=response)\n",
    "        \n",
    "        # Success - return mock articles\n",
    "        return [\n",
    "            {\n",
    "                \"title\": f\"{topic} article {i+1} from {self.name}\",\n",
    "                \"source\": self.name,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            for i in range(3)\n",
    "        ]\n",
    "\n",
    "# Create sources with different reliability profiles\n",
    "sources = {\n",
    "    \"ReliableNews\": NewsSource(\"ReliableNews\", failure_rate=0.05),\n",
    "    \"SlowNews\": NewsSource(\"SlowNews\", timeout_rate=0.4),\n",
    "    \"RateLimitedNews\": NewsSource(\"RateLimitedNews\", rate_limit_rate=0.3),\n",
    "    \"FlakyNews\": NewsSource(\"FlakyNews\", failure_rate=0.3, timeout_rate=0.2),\n",
    "    \"DownNews\": NewsSource(\"DownNews\", failure_rate=1.0)\n",
    "}\n",
    "\n",
    "print(\"✓ News sources created\")\n",
    "for name, source in sources.items():\n",
    "    print(f\"  - {name}: failure={source.failure_rate}, timeout={source.timeout_rate}, rate_limit={source.rate_limit_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Visualize the Workflow\n",
    "\n",
    "Before we implement the aggregator, let's visualize how error recovery flows through the system.\n",
    "\n",
    "This diagram shows the complete path from initial request to final result, including all recovery patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow visualization\n",
    "print(\"\"\"\\n\n",
    "╔═══════════════════════════════════════════════════════════════════════════════╗\n",
    "║                    RESILIENT AGGREGATOR WORKFLOW                              ║\n",
    "╚═══════════════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│  START: aggregate(topic)                                                    │\n",
    "└────────────────────────────────┬────────────────────────────────────────────┘\n",
    "                                 │\n",
    "                                 ▼\n",
    "                    ┌────────────────────────┐\n",
    "                    │  For each source       │\n",
    "                    │  (parallel processing) │\n",
    "                    └────────────┬───────────┘\n",
    "                                 │\n",
    "        ┌────────────────────────┼────────────────────────┐\n",
    "        ▼                        ▼                        ▼\n",
    "  ┌──────────┐            ┌──────────┐            ┌──────────┐\n",
    "  │ Source 1 │            │ Source 2 │    ...     │ Source N │\n",
    "  └─────┬────┘            └─────┬────┘            └─────┬────┘\n",
    "        │                       │                       │\n",
    "        ▼                       ▼                       ▼\n",
    "  ┌─────────────────────────────────────────────────────────┐\n",
    "  │ STEP 1: Circuit Breaker Check                          │\n",
    "  ├─────────────────────────────────────────────────────────┤\n",
    "  │  State: CLOSED    → Proceed to retry                   │\n",
    "  │  State: OPEN      → Fail fast (skip retries)           │\n",
    "  │  State: HALF_OPEN → Test recovery (one attempt)        │\n",
    "  └────────────────────────┬────────────────────────────────┘\n",
    "                           │\n",
    "                           ▼\n",
    "  ┌─────────────────────────────────────────────────────────┐\n",
    "  │ STEP 2: Retry Loop (max 3 attempts)                    │\n",
    "  ├─────────────────────────────────────────────────────────┤\n",
    "  │  Attempt 1: immediate                                  │\n",
    "  │      ↓ (fail)                                          │\n",
    "  │  Wait: base_delay * 2^0 * jitter ≈ 0.5-1.5s           │\n",
    "  │      ↓                                                 │\n",
    "  │  Attempt 2: after backoff                             │\n",
    "  │      ↓ (fail)                                          │\n",
    "  │  Wait: base_delay * 2^1 * jitter ≈ 1.0-3.0s           │\n",
    "  │      ↓                                                 │\n",
    "  │  Attempt 3: after longer backoff                      │\n",
    "  │      ↓ (success OR fail permanently)                  │\n",
    "  └────────────────────────┬────────────────────────────────┘\n",
    "                           │\n",
    "                           ▼\n",
    "  ┌─────────────────────────────────────────────────────────┐\n",
    "  │ STEP 3: Error Classification                           │\n",
    "  ├─────────────────────────────────────────────────────────┤\n",
    "  │  TRANSIENT (timeout, 429, 503) → Retry                 │\n",
    "  │  PERMANENT (404, 401)          → Fail fast             │\n",
    "  │  PARTIAL (some success)        → Continue              │\n",
    "  └────────────────────────┬────────────────────────────────┘\n",
    "                           │\n",
    "              ┌────────────┴────────────┐\n",
    "              ▼                         ▼\n",
    "        ┌──────────┐              ┌──────────┐\n",
    "        │ SUCCESS  │              │ FAILURE  │\n",
    "        └─────┬────┘              └─────┬────┘\n",
    "              │                         │\n",
    "              ▼                         ▼\n",
    "  ┌──────────────────────┐   ┌──────────────────────────┐\n",
    "  │ Update metrics       │   │ Log error                │\n",
    "  │ Return articles      │   │ Update circuit state     │\n",
    "  │ Circuit: success()   │   │ Circuit: failure()       │\n",
    "  └──────────┬───────────┘   └──────────┬───────────────┘\n",
    "             │                          │\n",
    "             └──────────┬───────────────┘\n",
    "                        │\n",
    "                        ▼\n",
    "           ┌────────────────────────────┐\n",
    "           │ Aggregate Results          │\n",
    "           ├────────────────────────────┤\n",
    "           │ 3/5 sources succeeded      │\n",
    "           │ → Partial success          │\n",
    "           │ → Return available data    │\n",
    "           └────────────┬───────────────┘\n",
    "                        │\n",
    "                        ▼\n",
    "           ┌────────────────────────────┐\n",
    "           │ END: Return aggregated     │\n",
    "           │      state with articles   │\n",
    "           │      and error info        │\n",
    "           └────────────────────────────┘\n",
    "\n",
    "╔═══════════════════════════════════════════════════════════════════════════════╗\n",
    "║  KEY PATTERNS                                                                 ║\n",
    "╠═══════════════════════════════════════════════════════════════════════════════╣\n",
    "║  • Circuit Breaker: Prevents cascade failures                                ║\n",
    "║  • Exponential Backoff: Gives services time to recover                       ║\n",
    "║  • Error Classification: Smart retry decisions                               ║\n",
    "║  • Partial Success: Degrade gracefully, don't fail completely                ║\n",
    "║  • Comprehensive Logging: Monitor production behavior                        ║\n",
    "╚═══════════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n✓ Workflow visualization complete\")\n",
    "print(\"  Watch for these patterns in the test output below:\")\n",
    "print(\"  - Retry backoff delays (1s → 2s → 4s)\")\n",
    "print(\"  - Circuit state transitions (CLOSED → OPEN → HALF_OPEN)\")\n",
    "print(\"  - Partial success (some sources work, others fail)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build Resilient Aggregator\n",
    "\n",
    "The aggregator combines all patterns:\n",
    "1. Circuit breaker per source\n",
    "2. Retry with backoff\n",
    "3. Partial failure handling\n",
    "4. Logging and monitoring\n",
    "\n",
    "**Key Design**:\n",
    "- Each source has its own circuit breaker\n",
    "- Failed sources don't block successful ones\n",
    "- Results are aggregated from available sources\n",
    "- Detailed error tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregatorState(TypedDict):\n",
    "    \"\"\"State for news aggregator.\"\"\"\n",
    "    topic: str\n",
    "    articles: List[Dict[str, Any]]\n",
    "    errors: List[ErrorInfo]\n",
    "    source_status: Dict[str, str]  # source -> status\n",
    "    start_time: datetime\n",
    "    end_time: Optional[datetime]\n",
    "\n",
    "class ResilientAggregator:\n",
    "    \"\"\"News aggregator with circuit breakers and retry logic.\"\"\"\n",
    "    \n",
    "    def __init__(self, sources: Dict[str, NewsSource]):\n",
    "        self.sources = sources\n",
    "        self.circuit_breakers = {\n",
    "            name: CircuitBreaker(failure_threshold=3, timeout=15.0, name=name)\n",
    "            for name in sources.keys()\n",
    "        }\n",
    "        self.retry_config = RetryConfig(max_retries=2, base_delay=0.5)\n",
    "    \n",
    "    def aggregate(self, topic: str) -> AggregatorState:\n",
    "        \"\"\"Aggregate news from all sources with error recovery.\"\"\"\n",
    "        logger.info(f\"\\n{'='*60}\")\n",
    "        logger.info(f\"Starting aggregation for topic: {topic}\")\n",
    "        logger.info(f\"{'='*60}\")\n",
    "        \n",
    "        state = {\n",
    "            \"topic\": topic,\n",
    "            \"articles\": [],\n",
    "            \"errors\": [],\n",
    "            \"source_status\": {},\n",
    "            \"start_time\": datetime.now(),\n",
    "            \"end_time\": None\n",
    "        }\n",
    "        \n",
    "        # Try each source\n",
    "        for source_name, source in self.sources.items():\n",
    "            try:\n",
    "                logger.info(f\"\\n--- Fetching from {source_name} ---\")\n",
    "                \n",
    "                # Wrap in circuit breaker and retry\n",
    "                circuit = self.circuit_breakers[source_name]\n",
    "                \n",
    "                articles = circuit.call(\n",
    "                    retry_with_backoff,\n",
    "                    source.fetch_news,\n",
    "                    topic,\n",
    "                    config=self.retry_config,\n",
    "                    source=source_name\n",
    "                )\n",
    "                \n",
    "                state[\"articles\"].extend(articles)\n",
    "                state[\"source_status\"][source_name] = \"success\"\n",
    "                logger.info(f\"✓ {source_name}: Retrieved {len(articles)} articles\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                error_info = classify_error(e, source_name)\n",
    "                state[\"errors\"].append(error_info)\n",
    "                state[\"source_status\"][source_name] = \"failed\"\n",
    "                logger.error(f\"✗ {source_name}: {error_info.message}\")\n",
    "        \n",
    "        state[\"end_time\"] = datetime.now()\n",
    "        \n",
    "        # Summary\n",
    "        duration = (state[\"end_time\"] - state[\"start_time\"]).total_seconds()\n",
    "        success_count = sum(1 for status in state[\"source_status\"].values() if status == \"success\")\n",
    "        total_sources = len(self.sources)\n",
    "        \n",
    "        logger.info(f\"\\n{'='*60}\")\n",
    "        logger.info(f\"Aggregation complete in {duration:.2f}s\")\n",
    "        logger.info(f\"Success: {success_count}/{total_sources} sources\")\n",
    "        logger.info(f\"Total articles: {len(state['articles'])}\")\n",
    "        logger.info(f\"Errors: {len(state['errors'])}\")\n",
    "        logger.info(f\"{'='*60}\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def get_circuit_status(self) -> Dict[str, str]:\n",
    "        \"\"\"Get status of all circuit breakers.\"\"\"\n",
    "        return {\n",
    "            name: circuit.state.value\n",
    "            for name, circuit in self.circuit_breakers.items()\n",
    "        }\n",
    "    \n",
    "    def reset_circuits(self):\n",
    "        \"\"\"Reset all circuit breakers.\"\"\"\n",
    "        for circuit in self.circuit_breakers.values():\n",
    "            circuit.reset()\n",
    "\n",
    "print(\"✓ Resilient aggregator created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Add Health Monitoring\n",
    "\n",
    "Production systems need visibility into error patterns and performance metrics.\n",
    "\n",
    "**Metrics to Track**:\n",
    "- Success rate per source\n",
    "- Average response time\n",
    "- Circuit breaker state\n",
    "- Retry attempts\n",
    "- Partial failure rate\n",
    "\n",
    "This helps answer:\n",
    "- Which sources are most reliable?\n",
    "- When should we remove a failing source?\n",
    "- Is our retry strategy working?\n",
    "- What's our overall system health?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceMetrics(BaseModel):\n",
    "    \"\"\"Metrics for a single source.\"\"\"\n",
    "    total_requests: int = 0\n",
    "    successful_requests: int = 0\n",
    "    failed_requests: int = 0\n",
    "    total_response_time: float = 0.0\n",
    "    retry_count: int = 0\n",
    "    \n",
    "    @property\n",
    "    def success_rate(self) -> float:\n",
    "        if self.total_requests == 0:\n",
    "            return 0.0\n",
    "        return (self.successful_requests / self.total_requests) * 100\n",
    "    \n",
    "    @property\n",
    "    def avg_response_time(self) -> float:\n",
    "        if self.successful_requests == 0:\n",
    "            return 0.0\n",
    "        return self.total_response_time / self.successful_requests\n",
    "\n",
    "class MetricsCollector:\n",
    "    \"\"\"Collects and reports health metrics.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics: Dict[str, SourceMetrics] = defaultdict(SourceMetrics)\n",
    "    \n",
    "    def record_request(self, source: str, success: bool, response_time: float = 0.0, retries: int = 0):\n",
    "        \"\"\"Record a request attempt.\"\"\"\n",
    "        metrics = self.metrics[source]\n",
    "        metrics.total_requests += 1\n",
    "        \n",
    "        if success:\n",
    "            metrics.successful_requests += 1\n",
    "            metrics.total_response_time += response_time\n",
    "        else:\n",
    "            metrics.failed_requests += 1\n",
    "        \n",
    "        metrics.retry_count += retries\n",
    "    \n",
    "    def get_health_report(self, circuit_states: Dict[str, str]) -> str:\n",
    "        \"\"\"Generate health dashboard.\"\"\"\n",
    "        lines = []\n",
    "        lines.append(\"\\n\" + \"=\"*85)\n",
    "        lines.append(\"HEALTH DASHBOARD\")\n",
    "        lines.append(\"=\"*85)\n",
    "        lines.append(f\"{'Source':<20} | {'Requests':>8} | {'Success':>7} | {'Avg Time':>8} | {'Retries':>7} | {'Circuit':<10}\")\n",
    "        lines.append(\"-\"*85)\n",
    "        \n",
    "        for source, metrics in sorted(self.metrics.items()):\n",
    "            circuit_state = circuit_states.get(source, \"unknown\")\n",
    "            \n",
    "            lines.append(\n",
    "                f\"{source:<20} | \"\n",
    "                f\"{metrics.total_requests:>8} | \"\n",
    "                f\"{metrics.success_rate:>6.1f}% | \"\n",
    "                f\"{metrics.avg_response_time:>7.3f}s | \"\n",
    "                f\"{metrics.retry_count:>7} | \"\n",
    "                f\"{circuit_state:<10}\"\n",
    "            )\n",
    "        \n",
    "        lines.append(\"=\"*85)\n",
    "        \n",
    "        # Overall stats\n",
    "        total_requests = sum(m.total_requests for m in self.metrics.values())\n",
    "        total_successes = sum(m.successful_requests for m in self.metrics.values())\n",
    "        overall_success = (total_successes / total_requests * 100) if total_requests > 0 else 0\n",
    "        \n",
    "        lines.append(f\"Overall Success Rate: {overall_success:.1f}% ({total_successes}/{total_requests} requests)\")\n",
    "        lines.append(\"=\"*85)\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "# Add metrics to aggregator\n",
    "class ResilientAggregatorWithMetrics(ResilientAggregator):\n",
    "    \"\"\"Aggregator with health monitoring.\"\"\"\n",
    "    \n",
    "    def __init__(self, sources: Dict[str, NewsSource]):\n",
    "        super().__init__(sources)\n",
    "        self.metrics = MetricsCollector()\n",
    "    \n",
    "    def aggregate(self, topic: str) -> AggregatorState:\n",
    "        \"\"\"Aggregate with metrics collection.\"\"\"\n",
    "        logger.info(f\"\\n{'='*60}\")\n",
    "        logger.info(f\"Starting aggregation for topic: {topic}\")\n",
    "        logger.info(f\"{'='*60}\")\n",
    "        \n",
    "        state = {\n",
    "            \"topic\": topic,\n",
    "            \"articles\": [],\n",
    "            \"errors\": [],\n",
    "            \"source_status\": {},\n",
    "            \"start_time\": datetime.now(),\n",
    "            \"end_time\": None\n",
    "        }\n",
    "        \n",
    "        for source_name, source in self.sources.items():\n",
    "            start_time = time.time()\n",
    "            retry_attempts = 0\n",
    "            \n",
    "            try:\n",
    "                logger.info(f\"\\n--- Fetching from {source_name} ---\")\n",
    "                circuit = self.circuit_breakers[source_name]\n",
    "                \n",
    "                articles = circuit.call(\n",
    "                    retry_with_backoff,\n",
    "                    source.fetch_news,\n",
    "                    topic,\n",
    "                    config=self.retry_config,\n",
    "                    source=source_name\n",
    "                )\n",
    "                \n",
    "                response_time = time.time() - start_time\n",
    "                state[\"articles\"].extend(articles)\n",
    "                state[\"source_status\"][source_name] = \"success\"\n",
    "                \n",
    "                # Record success metrics\n",
    "                self.metrics.record_request(\n",
    "                    source_name,\n",
    "                    success=True,\n",
    "                    response_time=response_time,\n",
    "                    retries=retry_attempts\n",
    "                )\n",
    "                \n",
    "                logger.info(f\"✓ {source_name}: Retrieved {len(articles)} articles in {response_time:.2f}s\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                response_time = time.time() - start_time\n",
    "                error_info = classify_error(e, source_name)\n",
    "                state[\"errors\"].append(error_info)\n",
    "                state[\"source_status\"][source_name] = \"failed\"\n",
    "                \n",
    "                # Record failure metrics\n",
    "                self.metrics.record_request(\n",
    "                    source_name,\n",
    "                    success=False,\n",
    "                    response_time=0.0,\n",
    "                    retries=error_info.retry_count\n",
    "                )\n",
    "                \n",
    "                logger.error(f\"✗ {source_name}: {error_info.message}\")\n",
    "        \n",
    "        state[\"end_time\"] = datetime.now()\n",
    "        \n",
    "        # Summary\n",
    "        duration = (state[\"end_time\"] - state[\"start_time\"]).total_seconds()\n",
    "        success_count = sum(1 for status in state[\"source_status\"].values() if status == \"success\")\n",
    "        total_sources = len(self.sources)\n",
    "        \n",
    "        logger.info(f\"\\n{'='*60}\")\n",
    "        logger.info(f\"Aggregation complete in {duration:.2f}s\")\n",
    "        logger.info(f\"Success: {success_count}/{total_sources} sources\")\n",
    "        logger.info(f\"Total articles: {len(state['articles'])}\")\n",
    "        logger.info(f\"Errors: {len(state['errors'])}\")\n",
    "        logger.info(f\"{'='*60}\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def get_health_report(self) -> str:\n",
    "        \"\"\"Get health dashboard.\"\"\"\n",
    "        return self.metrics.get_health_report(self.get_circuit_status())\n",
    "\n",
    "print(\"✓ Health monitoring added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Test Error Recovery\n",
    "\n",
    "Run multiple aggregation cycles to see recovery patterns in action:\n",
    "\n",
    "1. **First run**: Some sources fail, retries occur\n",
    "2. **Second run**: Circuit breakers may be open\n",
    "3. **After timeout**: Circuits test recovery\n",
    "\n",
    "Watch the logs to see:\n",
    "- Retry attempts with increasing delays (1s → 2s → 4s)\n",
    "- Circuit breaker state transitions\n",
    "- Partial success (some sources work)\n",
    "- Graceful degradation\n",
    "- Health metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aggregator with metrics\n",
    "aggregator = ResilientAggregatorWithMetrics(sources)\n",
    "\n",
    "# Test 1: First aggregation\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# TEST 1: First Aggregation\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "result1 = aggregator.aggregate(\"AI advancements\")\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(f\"  Articles retrieved: {len(result1['articles'])}\")\n",
    "print(f\"  Source status: {result1['source_status']}\")\n",
    "print(f\"  Circuit states: {aggregator.get_circuit_status()}\")\n",
    "\n",
    "# Show health dashboard\n",
    "print(aggregator.get_health_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Immediate retry (circuits may be open)\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# TEST 2: Immediate Retry (may hit open circuits)\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "result2 = aggregator.aggregate(\"Climate change\")\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(f\"  Articles retrieved: {len(result2['articles'])}\")\n",
    "print(f\"  Source status: {result2['source_status']}\")\n",
    "print(f\"  Circuit states: {aggregator.get_circuit_status()}\")\n",
    "\n",
    "# Show updated health dashboard\n",
    "print(aggregator.get_health_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Manual circuit reset and retry\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# TEST 3: After Circuit Reset\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "print(\"\\nResetting all circuits...\")\n",
    "aggregator.reset_circuits()\n",
    "print(f\"Circuit states after reset: {aggregator.get_circuit_status()}\")\n",
    "\n",
    "result3 = aggregator.aggregate(\"Technology trends\")\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(f\"  Articles retrieved: {len(result3['articles'])}\")\n",
    "print(f\"  Source status: {result3['source_status']}\")\n",
    "print(f\"  Circuit states: {aggregator.get_circuit_status()}\")\n",
    "\n",
    "# Show final health dashboard\n",
    "print(aggregator.get_health_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1: Add Fallback Cache\n",
    "\n",
    "**Goal**: When all sources fail for a topic, return cached results from previous successful queries.\n",
    "\n",
    "**Requirements**:\n",
    "- Add `cache: Dict[str, List[Dict]]` to aggregator (topic → articles)\n",
    "- After successful aggregation, cache results with timestamp\n",
    "- If aggregation returns 0 articles, check cache\n",
    "- Return cached results with \"CACHED\" indicator in logs\n",
    "- Expire cache after 1 hour\n",
    "\n",
    "**Hints**:\n",
    "- Store timestamp with each cache entry: `{\"articles\": [...], \"timestamp\": datetime.now()}`\n",
    "- Check `(now - cache_time) < timedelta(hours=1)`\n",
    "- Add logging: `logger.info(f\"Using cached results from {timestamp}\")`\n",
    "- Test by temporarily setting all sources to `failure_rate=1.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you built a production-grade resilient system with:\n",
    "\n",
    "✅ **Error classification** - Distinguish transient, permanent, and partial failures  \n",
    "✅ **Retry with exponential backoff** - Handle transient errors intelligently  \n",
    "✅ **Circuit breakers** - Prevent cascade failures and enable recovery testing  \n",
    "✅ **Partial failure handling** - Degrade gracefully, return available data  \n",
    "✅ **Comprehensive logging** - Monitor errors and recovery in production  \n",
    "✅ **Health monitoring** - Track metrics and system health  \n",
    "✅ **Resilience patterns** - Apply industry-standard error recovery  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "**Error Recovery Principles**:\n",
    "1. **Classify before acting**: Not all errors deserve retry\n",
    "2. **Fail fast on permanent errors**: Don't waste time\n",
    "3. **Back off exponentially**: Give services time to recover\n",
    "4. **Isolate failures**: One bad source shouldn't block others\n",
    "5. **Monitor and log**: Visibility is critical in production\n",
    "6. **Measure everything**: Metrics drive operational decisions\n",
    "\n",
    "**When to Use These Patterns**:\n",
    "- External API dependencies\n",
    "- Distributed systems\n",
    "- Production reliability requirements\n",
    "- High-availability systems\n",
    "\n",
    "**Real-World Applications**:\n",
    "- Microservices architectures\n",
    "- Cloud-native applications\n",
    "- Data pipelines\n",
    "- Customer-facing services\n",
    "\n",
    "### Advanced Note\n",
    "\n",
    "These patterns represent **advanced production engineering**. If you're new to error recovery:\n",
    "- Focus on understanding the *why* behind each pattern\n",
    "- Experiment with the failure rates to see different behaviors\n",
    "- Review the health dashboard to understand system performance\n",
    "- Start simple (retry) before adding complexity (circuit breakers)\n",
    "\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Apply these resilience patterns to your own projects\n",
    "- Explore advanced patterns: bulkheads, rate limiting, load shedding\n",
    "- Study production incident reports to see these patterns in action"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gai-3101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
