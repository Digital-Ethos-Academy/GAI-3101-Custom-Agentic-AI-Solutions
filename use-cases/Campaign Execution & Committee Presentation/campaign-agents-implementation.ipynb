{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic AI Implementation: Campaign Execution & Committee Presentation\n",
    "\n",
    "This comprehensive notebook demonstrates how to implement agentic AI solutions for the **Campaign Execution & Committee Presentation** value stream, applying techniques learned from the GAI-3101 Custom Agentic AI Solutions course.\n",
    "\n",
    "## Business Context\n",
    "\n",
    "**Process Overview**: Transform raw BigQuery campaign data into polished PowerPoint presentations for committee review.\n",
    "\n",
    "**Current State**: 40 hours manual process\n",
    "**Target State**: 16.5 hours with AI assistance (59% reduction)\n",
    "\n",
    "### Value Stream Steps\n",
    "1. **Input Validation** - Verify campaign data completeness\n",
    "2. **Data Preparation** - Query and transform BigQuery data\n",
    "3. **Monitoring Setup** - Configure Looker dashboards\n",
    "4. **Analytical Review** - Generate insights and analysis\n",
    "5. **Availability Confirmation** - Schedule and verify stakeholder availability\n",
    "6. **PPT Assembly** - Build final presentation\n",
    "\n",
    "---\n",
    "\n",
    "## Course Techniques Applied\n",
    "\n",
    "| Lab Module | Technique | Application |\n",
    "|------------|-----------|-------------|\n",
    "| Lab 1 | Simple Python Agent | Foundation agent architecture |\n",
    "| Lab 2 | Round Robin Communication | Multi-agent coordination |\n",
    "| Lab 3 | Reactive Agent | Real-time data monitoring |\n",
    "| Lab 4 | Deliberative Agent | Planning & execution workflow |\n",
    "| Lab 5 | Long-Term Memory | Campaign history & learnings |\n",
    "| Lab 6 | Observation Tools | BigQuery/Looker integration |\n",
    "| Lab 7 | Action Tools | File creation, email, PPT generation |\n",
    "| Lab 8 | Hierarchical Planning | Task decomposition |\n",
    "| Lab 9 | Rule-Based Reasoning | Validation & quality checks |\n",
    "| Lab 10 | Robustness Evaluation | Testing & reliability |\n",
    "| Lab 11 | Personal Assistant | End-to-end workflow |\n",
    "| Lab 12 | Error Recovery | Resilient operations |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Environment Setup\n",
    "\n",
    "Install required packages and configure API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -qU \\\n",
    "    openai==1.* \\\n",
    "    langchain==0.3.* \\\n",
    "    langchain-openai==0.3.* \\\n",
    "    langgraph==0.5.* \\\n",
    "    autogen-agentchat==0.6.* \\\n",
    "    autogen-ext[openai]==0.6.* \\\n",
    "    python-pptx \\\n",
    "    pandas \\\n",
    "    google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import json\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from typing import TypedDict, Annotated, List, Dict, Any, Optional\n",
    "from abc import ABC, abstractmethod\n",
    "from enum import Enum\n",
    "\n",
    "# Configure OpenAI API Key\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "print(\"‚úÖ Environment configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Foundation - Simple Python Agent (Lab 1)\n",
    "\n",
    "Building the foundational agent architecture following the course pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "class Agent(ABC):\n",
    "    \"\"\"\n",
    "    Base Agent class following Lab 1 patterns.\n",
    "    All campaign agents inherit from this foundation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, model: str = \"gpt-4.1-mini\"):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.system_prompt = \"\"\n",
    "        self.memory = []  # Short-term memory\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Reset agent state between runs.\"\"\"\n",
    "        self.memory = []\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _select_action(self, sensors: dict) -> str:\n",
    "        \"\"\"Select an action based on sensor inputs.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def act(self, sensors: dict) -> str:\n",
    "        \"\"\"Execute the agent's action cycle.\"\"\"\n",
    "        action = self._select_action(sensors)\n",
    "        self.memory.append({\"sensors\": sensors, \"action\": action})\n",
    "        return action\n",
    "    \n",
    "    def _call_llm(self, user_message: str) -> str:\n",
    "        \"\"\"Call the LLM with the system prompt and user message.\"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "print(\"‚úÖ Base Agent class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campaign-Specific Agent Types\n",
    "\n",
    "Define specialized agents for each value stream step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationAgent(Agent):\n",
    "    \"\"\"\n",
    "    Step 1: Input Validation Agent\n",
    "    Verifies campaign data completeness and quality.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"ValidationAgent\")\n",
    "        self.system_prompt = \"\"\"\n",
    "You are a Data Validation Agent responsible for verifying campaign data quality.\n",
    "\n",
    "Your responsibilities:\n",
    "- Check data completeness (all required fields present)\n",
    "- Verify data format correctness\n",
    "- Identify anomalies or outliers\n",
    "- Report validation status with specific issues\n",
    "\n",
    "Required campaign fields:\n",
    "- campaign_id, campaign_name, start_date, end_date\n",
    "- budget, spend, impressions, clicks, conversions\n",
    "- channel, target_audience, status\n",
    "\n",
    "Output your findings in a structured format.\n",
    "\"\"\"\n",
    "    \n",
    "    def _select_action(self, sensors: dict) -> str:\n",
    "        campaign_data = sensors.get(\"campaign_data\", {})\n",
    "        prompt = f\"\"\"Validate the following campaign data:\n",
    "        \n",
    "{json.dumps(campaign_data, indent=2)}\n",
    "\n",
    "Provide a validation report with:\n",
    "1. VALID/INVALID status\n",
    "2. Missing fields (if any)\n",
    "3. Data quality issues (if any)\n",
    "4. Recommendations for fixes\n",
    "\"\"\"\n",
    "        return self._call_llm(prompt)\n",
    "\n",
    "\n",
    "class DataPreparationAgent(Agent):\n",
    "    \"\"\"\n",
    "    Step 2: Data Preparation Agent\n",
    "    Queries and transforms BigQuery data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"DataPreparationAgent\")\n",
    "        self.system_prompt = \"\"\"\n",
    "You are a Data Preparation Agent responsible for querying and transforming campaign data.\n",
    "\n",
    "Your responsibilities:\n",
    "- Generate SQL queries for BigQuery\n",
    "- Transform raw data into analysis-ready format\n",
    "- Calculate key metrics (CTR, CPA, ROAS, etc.)\n",
    "- Prepare data aggregations and summaries\n",
    "\n",
    "Output SQL queries and transformation steps.\n",
    "\"\"\"\n",
    "    \n",
    "    def _select_action(self, sensors: dict) -> str:\n",
    "        requirements = sensors.get(\"requirements\", {})\n",
    "        prompt = f\"\"\"Generate data preparation steps for the following requirements:\n",
    "\n",
    "{json.dumps(requirements, indent=2)}\n",
    "\n",
    "Provide:\n",
    "1. BigQuery SQL query\n",
    "2. Data transformation steps\n",
    "3. Calculated metrics formulas\n",
    "4. Output schema\n",
    "\"\"\"\n",
    "        return self._call_llm(prompt)\n",
    "\n",
    "\n",
    "class MonitoringAgent(Agent):\n",
    "    \"\"\"\n",
    "    Step 3: Monitoring Setup Agent\n",
    "    Configures Looker dashboards.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"MonitoringAgent\")\n",
    "        self.system_prompt = \"\"\"\n",
    "You are a Monitoring Setup Agent responsible for configuring campaign dashboards.\n",
    "\n",
    "Your responsibilities:\n",
    "- Design dashboard layouts\n",
    "- Define key performance indicators (KPIs)\n",
    "- Configure alert thresholds\n",
    "- Set up automated reporting schedules\n",
    "\n",
    "Output Looker configuration and dashboard specifications.\n",
    "\"\"\"\n",
    "    \n",
    "    def _select_action(self, sensors: dict) -> str:\n",
    "        campaign_metrics = sensors.get(\"metrics\", {})\n",
    "        prompt = f\"\"\"Configure monitoring dashboard for these metrics:\n",
    "\n",
    "{json.dumps(campaign_metrics, indent=2)}\n",
    "\n",
    "Provide:\n",
    "1. Dashboard layout recommendation\n",
    "2. KPI definitions with targets\n",
    "3. Alert threshold configurations\n",
    "4. Visualization specifications\n",
    "\"\"\"\n",
    "        return self._call_llm(prompt)\n",
    "\n",
    "\n",
    "class AnalysisAgent(Agent):\n",
    "    \"\"\"\n",
    "    Step 4: Analytical Review Agent\n",
    "    Generates insights and analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"AnalysisAgent\")\n",
    "        self.system_prompt = \"\"\"\n",
    "You are an Analysis Agent responsible for generating campaign insights.\n",
    "\n",
    "Your responsibilities:\n",
    "- Analyze campaign performance trends\n",
    "- Identify success factors and areas for improvement\n",
    "- Compare against benchmarks and historical data\n",
    "- Generate actionable recommendations\n",
    "\n",
    "Output structured insights and recommendations.\n",
    "\"\"\"\n",
    "    \n",
    "    def _select_action(self, sensors: dict) -> str:\n",
    "        performance_data = sensors.get(\"performance_data\", {})\n",
    "        prompt = f\"\"\"Analyze the following campaign performance data:\n",
    "\n",
    "{json.dumps(performance_data, indent=2)}\n",
    "\n",
    "Provide:\n",
    "1. Executive Summary (2-3 sentences)\n",
    "2. Key Performance Highlights\n",
    "3. Areas of Concern\n",
    "4. Recommendations (prioritized)\n",
    "5. Next Steps\n",
    "\"\"\"\n",
    "        return self._call_llm(prompt)\n",
    "\n",
    "\n",
    "class SchedulingAgent(Agent):\n",
    "    \"\"\"\n",
    "    Step 5: Availability Confirmation Agent\n",
    "    Schedules and verifies stakeholder availability.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"SchedulingAgent\")\n",
    "        self.system_prompt = \"\"\"\n",
    "You are a Scheduling Agent responsible for coordinating committee presentations.\n",
    "\n",
    "Your responsibilities:\n",
    "- Check stakeholder availability\n",
    "- Propose meeting times\n",
    "- Send calendar invitations\n",
    "- Handle scheduling conflicts\n",
    "\n",
    "Output scheduling recommendations and calendar actions.\n",
    "\"\"\"\n",
    "    \n",
    "    def _select_action(self, sensors: dict) -> str:\n",
    "        stakeholders = sensors.get(\"stakeholders\", [])\n",
    "        preferred_times = sensors.get(\"preferred_times\", [])\n",
    "        prompt = f\"\"\"Schedule a committee presentation meeting:\n",
    "\n",
    "Stakeholders: {json.dumps(stakeholders)}\n",
    "Preferred Times: {json.dumps(preferred_times)}\n",
    "\n",
    "Provide:\n",
    "1. Recommended meeting time(s)\n",
    "2. Required attendees\n",
    "3. Meeting agenda draft\n",
    "4. Calendar invitation content\n",
    "\"\"\"\n",
    "        return self._call_llm(prompt)\n",
    "\n",
    "\n",
    "class PresentationAgent(Agent):\n",
    "    \"\"\"\n",
    "    Step 6: PPT Assembly Agent\n",
    "    Builds final presentation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"PresentationAgent\")\n",
    "        self.system_prompt = \"\"\"\n",
    "You are a Presentation Assembly Agent responsible for creating committee presentations.\n",
    "\n",
    "Your responsibilities:\n",
    "- Structure presentation content\n",
    "- Design slide layouts\n",
    "- Incorporate data visualizations\n",
    "- Ensure brand consistency\n",
    "\n",
    "Output detailed slide-by-slide content.\n",
    "\"\"\"\n",
    "    \n",
    "    def _select_action(self, sensors: dict) -> str:\n",
    "        analysis = sensors.get(\"analysis\", \"\")\n",
    "        campaign_data = sensors.get(\"campaign_data\", {})\n",
    "        prompt = f\"\"\"Create a committee presentation based on:\n",
    "\n",
    "Campaign Data:\n",
    "{json.dumps(campaign_data, indent=2)}\n",
    "\n",
    "Analysis:\n",
    "{analysis}\n",
    "\n",
    "Provide detailed content for each slide:\n",
    "1. Title Slide\n",
    "2. Executive Summary\n",
    "3. Campaign Overview\n",
    "4. Performance Metrics\n",
    "5. Key Insights\n",
    "6. Recommendations\n",
    "7. Next Steps\n",
    "8. Appendix (if needed)\n",
    "\"\"\"\n",
    "        return self._call_llm(prompt)\n",
    "\n",
    "print(\"‚úÖ Campaign-specific agents defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Simple Agent Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample campaign data for testing\n",
    "sample_campaign = {\n",
    "    \"campaign_id\": \"CAMP-2024-001\",\n",
    "    \"campaign_name\": \"Q4 Holiday Campaign\",\n",
    "    \"start_date\": \"2024-11-01\",\n",
    "    \"end_date\": \"2024-12-31\",\n",
    "    \"budget\": 50000,\n",
    "    \"spend\": 45000,\n",
    "    \"impressions\": 2500000,\n",
    "    \"clicks\": 75000,\n",
    "    \"conversions\": 1500,\n",
    "    \"channel\": \"Digital Display\",\n",
    "    \"target_audience\": \"Adults 25-54\",\n",
    "    \"status\": \"Active\"\n",
    "}\n",
    "\n",
    "# Test Validation Agent\n",
    "validation_agent = ValidationAgent()\n",
    "validation_result = validation_agent.act({\"campaign_data\": sample_campaign})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VALIDATION AGENT RESULT\")\n",
    "print(\"=\" * 60)\n",
    "print(validation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Multi-Agent Communication (Lab 2 - AutoGen)\n",
    "\n",
    "Implementing round-robin communication between agents using AutoGen framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Initialize model client\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Define AutoGen agents for campaign workflow\n",
    "validator_autogen = AssistantAgent(\n",
    "    name=\"DataValidator\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"You are a Data Validator. Your role is to:\n",
    "    1. Check campaign data for completeness\n",
    "    2. Verify data quality and format\n",
    "    3. Report any issues found\n",
    "    \n",
    "    When data is valid, say 'DATA_VALIDATED' to pass to the next agent.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "analyst_autogen = AssistantAgent(\n",
    "    name=\"DataAnalyst\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"You are a Data Analyst. Your role is to:\n",
    "    1. Analyze campaign performance metrics\n",
    "    2. Calculate KPIs (CTR, CPA, ROAS)\n",
    "    3. Generate insights and trends\n",
    "    \n",
    "    When analysis is complete, say 'ANALYSIS_COMPLETE' to pass to the next agent.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "presenter_autogen = AssistantAgent(\n",
    "    name=\"PresentationCreator\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"You are a Presentation Creator. Your role is to:\n",
    "    1. Structure presentation content from analysis\n",
    "    2. Create slide outlines\n",
    "    3. Draft talking points\n",
    "    \n",
    "    When presentation is ready, say 'TERMINATE' to complete the workflow.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ AutoGen agents configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Round-Robin Group Chat\n",
    "termination_condition = TextMentionTermination(\"TERMINATE\")\n",
    "\n",
    "campaign_team = RoundRobinGroupChat(\n",
    "    participants=[validator_autogen, analyst_autogen, presenter_autogen],\n",
    "    termination_condition=termination_condition,\n",
    "    max_turns=10\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Round-Robin team configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the multi-agent workflow\n",
    "async def run_campaign_workflow():\n",
    "    task = f\"\"\"Process this campaign data and create a committee presentation:\n",
    "    \n",
    "    {json.dumps(sample_campaign, indent=2)}\n",
    "    \n",
    "    Workflow:\n",
    "    1. DataValidator: Validate the data\n",
    "    2. DataAnalyst: Analyze performance\n",
    "    3. PresentationCreator: Create presentation outline\n",
    "    \"\"\"\n",
    "    \n",
    "    result = await campaign_team.run(task=task)\n",
    "    return result\n",
    "\n",
    "# Execute workflow\n",
    "result = await run_campaign_workflow()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MULTI-AGENT WORKFLOW RESULT\")\n",
    "print(\"=\" * 60)\n",
    "for message in result.messages:\n",
    "    print(f\"\\n[{message.source}]:\")\n",
    "    print(message.content[:500] + \"...\" if len(message.content) > 500 else message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Deliberative Agent with LangGraph (Lab 4)\n",
    "\n",
    "Implementing a planning-based workflow using LangGraph's StateGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Initialize LangChain LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# Define State Schema\n",
    "class CampaignWorkflowState(TypedDict):\n",
    "    \"\"\"State for the campaign workflow.\"\"\"\n",
    "    campaign_data: dict           # Raw campaign data\n",
    "    plan: str                     # Execution plan\n",
    "    current_task: int             # Current task number\n",
    "    task_count: int               # Total number of tasks\n",
    "    validation_result: str        # Validation outcome\n",
    "    prepared_data: dict           # Transformed data\n",
    "    analysis: str                 # Analysis results\n",
    "    presentation: str             # Presentation content\n",
    "    final_result: str             # Final output\n",
    "\n",
    "print(\"‚úÖ LangGraph state schema defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pydantic model for structured planning output\n",
    "class CampaignPlan(BaseModel):\n",
    "    \"\"\"Structured plan for campaign workflow.\"\"\"\n",
    "    plan: str = Field(description=\"Detailed step-by-step plan\")\n",
    "    task_count: int = Field(description=\"Number of tasks in the plan\")\n",
    "\n",
    "# Planning prompt\n",
    "planning_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "You are a Campaign Workflow Planner.\n",
    "\n",
    "Purpose and Goals:\n",
    "* Break down campaign processing into smaller, manageable tasks\n",
    "* Develop a plan of action with clear steps\n",
    "* Prioritize tasks based on dependencies\n",
    "* Each task must be completable by an AI Agent\n",
    "\n",
    "Standard workflow steps:\n",
    "1. Validate input data\n",
    "2. Prepare and transform data\n",
    "3. Analyze performance metrics\n",
    "4. Generate insights\n",
    "5. Create presentation content\n",
    "6. Finalize deliverables\n",
    "\n",
    "Template:\n",
    "1. **Task Name**\n",
    "   * Purpose: [Purpose of Task]\n",
    "   * Goal: [Goal of Task]\n",
    "   * Success Criteria: [Criteria for Task]\n",
    "\n",
    "Output only the plan.\n",
    "\"\"\"),\n",
    "    (\"user\", \"Create a plan for processing this campaign: {campaign_data}\")\n",
    "])\n",
    "\n",
    "# Create planning chain with structured output\n",
    "planning_chain = planning_prompt | llm.with_structured_output(CampaignPlan)\n",
    "\n",
    "print(\"‚úÖ Planning chain configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define workflow nodes\n",
    "\n",
    "def planner_node(state: CampaignWorkflowState) -> dict:\n",
    "    \"\"\"Planning node - creates execution plan.\"\"\"\n",
    "    print(\"\\n=== PLANNER NODE ===\")\n",
    "    campaign_data = state[\"campaign_data\"]\n",
    "    \n",
    "    result = planning_chain.invoke({\"campaign_data\": json.dumps(campaign_data)})\n",
    "    \n",
    "    print(f\"Plan created with {result.task_count} tasks\")\n",
    "    \n",
    "    return {\n",
    "        \"plan\": result.plan,\n",
    "        \"task_count\": result.task_count,\n",
    "        \"current_task\": 1\n",
    "    }\n",
    "\n",
    "\n",
    "def validation_node(state: CampaignWorkflowState) -> dict:\n",
    "    \"\"\"Validation node - validates input data.\"\"\"\n",
    "    print(\"\\n=== VALIDATION NODE ===\")\n",
    "    \n",
    "    validation_agent = ValidationAgent()\n",
    "    result = validation_agent.act({\"campaign_data\": state[\"campaign_data\"]})\n",
    "    \n",
    "    print(f\"Validation complete\")\n",
    "    \n",
    "    return {\n",
    "        \"validation_result\": result,\n",
    "        \"current_task\": state[\"current_task\"] + 1\n",
    "    }\n",
    "\n",
    "\n",
    "def preparation_node(state: CampaignWorkflowState) -> dict:\n",
    "    \"\"\"Data preparation node - transforms data.\"\"\"\n",
    "    print(\"\\n=== PREPARATION NODE ===\")\n",
    "    \n",
    "    prep_agent = DataPreparationAgent()\n",
    "    result = prep_agent.act({\"requirements\": state[\"campaign_data\"]})\n",
    "    \n",
    "    # Calculate derived metrics\n",
    "    campaign = state[\"campaign_data\"]\n",
    "    prepared = {\n",
    "        **campaign,\n",
    "        \"ctr\": round((campaign[\"clicks\"] / campaign[\"impressions\"]) * 100, 2),\n",
    "        \"cpa\": round(campaign[\"spend\"] / campaign[\"conversions\"], 2),\n",
    "        \"conversion_rate\": round((campaign[\"conversions\"] / campaign[\"clicks\"]) * 100, 2),\n",
    "        \"budget_utilization\": round((campaign[\"spend\"] / campaign[\"budget\"]) * 100, 2)\n",
    "    }\n",
    "    \n",
    "    print(f\"Data prepared with calculated metrics\")\n",
    "    \n",
    "    return {\n",
    "        \"prepared_data\": prepared,\n",
    "        \"current_task\": state[\"current_task\"] + 1\n",
    "    }\n",
    "\n",
    "\n",
    "def analysis_node(state: CampaignWorkflowState) -> dict:\n",
    "    \"\"\"Analysis node - generates insights.\"\"\"\n",
    "    print(\"\\n=== ANALYSIS NODE ===\")\n",
    "    \n",
    "    analysis_agent = AnalysisAgent()\n",
    "    result = analysis_agent.act({\"performance_data\": state[\"prepared_data\"]})\n",
    "    \n",
    "    print(f\"Analysis complete\")\n",
    "    \n",
    "    return {\n",
    "        \"analysis\": result,\n",
    "        \"current_task\": state[\"current_task\"] + 1\n",
    "    }\n",
    "\n",
    "\n",
    "def presentation_node(state: CampaignWorkflowState) -> dict:\n",
    "    \"\"\"Presentation node - creates presentation content.\"\"\"\n",
    "    print(\"\\n=== PRESENTATION NODE ===\")\n",
    "    \n",
    "    pres_agent = PresentationAgent()\n",
    "    result = pres_agent.act({\n",
    "        \"analysis\": state[\"analysis\"],\n",
    "        \"campaign_data\": state[\"prepared_data\"]\n",
    "    })\n",
    "    \n",
    "    print(f\"Presentation content created\")\n",
    "    \n",
    "    return {\n",
    "        \"presentation\": result,\n",
    "        \"current_task\": state[\"current_task\"] + 1\n",
    "    }\n",
    "\n",
    "\n",
    "def finalizer_node(state: CampaignWorkflowState) -> dict:\n",
    "    \"\"\"Finalizer node - compiles final output.\"\"\"\n",
    "    print(\"\\n=== FINALIZER NODE ===\")\n",
    "    \n",
    "    final_result = f\"\"\"\n",
    "=== CAMPAIGN PROCESSING COMPLETE ===\n",
    "\n",
    "Campaign: {state['campaign_data']['campaign_name']}\n",
    "Campaign ID: {state['campaign_data']['campaign_id']}\n",
    "\n",
    "--- Validation ---\n",
    "{state['validation_result'][:500]}...\n",
    "\n",
    "--- Key Metrics ---\n",
    "CTR: {state['prepared_data'].get('ctr', 'N/A')}%\n",
    "CPA: ${state['prepared_data'].get('cpa', 'N/A')}\n",
    "Conversion Rate: {state['prepared_data'].get('conversion_rate', 'N/A')}%\n",
    "Budget Utilization: {state['prepared_data'].get('budget_utilization', 'N/A')}%\n",
    "\n",
    "--- Analysis Summary ---\n",
    "{state['analysis'][:500]}...\n",
    "\n",
    "--- Presentation Created ---\n",
    "Presentation content ready for review.\n",
    "\n",
    "Tasks Completed: {state['current_task']}/{state['task_count']}\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"Workflow finalized\")\n",
    "    \n",
    "    return {\"final_result\": final_result}\n",
    "\n",
    "print(\"‚úÖ Workflow nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the workflow graph\n",
    "workflow = StateGraph(CampaignWorkflowState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"planner\", planner_node)\n",
    "workflow.add_node(\"validator\", validation_node)\n",
    "workflow.add_node(\"preparer\", preparation_node)\n",
    "workflow.add_node(\"analyzer\", analysis_node)\n",
    "workflow.add_node(\"presenter\", presentation_node)\n",
    "workflow.add_node(\"finalizer\", finalizer_node)\n",
    "\n",
    "# Define edges\n",
    "workflow.set_entry_point(\"planner\")\n",
    "workflow.add_edge(\"planner\", \"validator\")\n",
    "workflow.add_edge(\"validator\", \"preparer\")\n",
    "workflow.add_edge(\"preparer\", \"analyzer\")\n",
    "workflow.add_edge(\"analyzer\", \"presenter\")\n",
    "workflow.add_edge(\"presenter\", \"finalizer\")\n",
    "workflow.add_edge(\"finalizer\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "campaign_app = workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Campaign workflow compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the workflow\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(campaign_app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Graph visualization not available: {e}\")\n",
    "    print(\"\\nWorkflow structure:\")\n",
    "    print(\"planner ‚Üí validator ‚Üí preparer ‚Üí analyzer ‚Üí presenter ‚Üí finalizer ‚Üí END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the deliberative workflow\n",
    "initial_state = {\n",
    "    \"campaign_data\": sample_campaign,\n",
    "    \"plan\": \"\",\n",
    "    \"current_task\": 0,\n",
    "    \"task_count\": 0,\n",
    "    \"validation_result\": \"\",\n",
    "    \"prepared_data\": {},\n",
    "    \"analysis\": \"\",\n",
    "    \"presentation\": \"\",\n",
    "    \"final_result\": \"\"\n",
    "}\n",
    "\n",
    "result = campaign_app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DELIBERATIVE WORKFLOW RESULT\")\n",
    "print(\"=\" * 60)\n",
    "print(result[\"final_result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Observation & Action Tools (Labs 6-7)\n",
    "\n",
    "Implementing tools for data observation and action execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Observation Tools\n",
    "\n",
    "def query_bigquery(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Observation Tool: Query BigQuery for campaign data.\n",
    "    \n",
    "    Args:\n",
    "        query: SQL query string\n",
    "        \n",
    "    Returns:\n",
    "        Query results as dictionary\n",
    "    \"\"\"\n",
    "    # Simulated BigQuery response\n",
    "    print(f\"üìä Executing BigQuery: {query[:50]}...\")\n",
    "    \n",
    "    # Return simulated data\n",
    "    return {\n",
    "        \"rows\": [\n",
    "            sample_campaign  # Use our sample data\n",
    "        ],\n",
    "        \"total_rows\": 1,\n",
    "        \"query_time_ms\": 234\n",
    "    }\n",
    "\n",
    "\n",
    "def check_looker_dashboard(dashboard_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Observation Tool: Check Looker dashboard status.\n",
    "    \n",
    "    Args:\n",
    "        dashboard_id: Looker dashboard identifier\n",
    "        \n",
    "    Returns:\n",
    "        Dashboard status and metrics\n",
    "    \"\"\"\n",
    "    print(f\"üìà Checking Looker dashboard: {dashboard_id}\")\n",
    "    \n",
    "    return {\n",
    "        \"dashboard_id\": dashboard_id,\n",
    "        \"status\": \"active\",\n",
    "        \"last_refresh\": datetime.now().isoformat(),\n",
    "        \"tiles\": 8,\n",
    "        \"filters_active\": [\"date_range\", \"campaign_id\"]\n",
    "    }\n",
    "\n",
    "\n",
    "def get_stakeholder_calendars(stakeholder_ids: List[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Observation Tool: Check stakeholder calendar availability.\n",
    "    \n",
    "    Args:\n",
    "        stakeholder_ids: List of stakeholder identifiers\n",
    "        \n",
    "    Returns:\n",
    "        Availability information\n",
    "    \"\"\"\n",
    "    print(f\"üìÖ Checking calendars for: {stakeholder_ids}\")\n",
    "    \n",
    "    return {\n",
    "        \"stakeholders\": stakeholder_ids,\n",
    "        \"available_slots\": [\n",
    "            {\"date\": \"2024-12-02\", \"time\": \"10:00 AM\", \"duration\": \"1 hour\"},\n",
    "            {\"date\": \"2024-12-03\", \"time\": \"2:00 PM\", \"duration\": \"1 hour\"},\n",
    "            {\"date\": \"2024-12-04\", \"time\": \"11:00 AM\", \"duration\": \"1 hour\"}\n",
    "        ],\n",
    "        \"conflicts\": []\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Observation tools defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Action Tools\n",
    "\n",
    "def create_ppt_file(content: dict, filename: str) -> dict:\n",
    "    \"\"\"\n",
    "    Action Tool: Create PowerPoint presentation file.\n",
    "    \n",
    "    Args:\n",
    "        content: Presentation content dictionary\n",
    "        filename: Output filename\n",
    "        \n",
    "    Returns:\n",
    "        Creation status\n",
    "    \"\"\"\n",
    "    print(f\"üìÑ Creating PowerPoint: {filename}\")\n",
    "    \n",
    "    # Simulated PPT creation\n",
    "    return {\n",
    "        \"status\": \"created\",\n",
    "        \"filename\": filename,\n",
    "        \"slides\": len(content.get(\"slides\", [])),\n",
    "        \"path\": f\"/output/{filename}\",\n",
    "        \"size_kb\": 1250\n",
    "    }\n",
    "\n",
    "\n",
    "def send_email(to: List[str], subject: str, body: str, attachments: List[str] = None) -> dict:\n",
    "    \"\"\"\n",
    "    Action Tool: Send email notification.\n",
    "    \n",
    "    Args:\n",
    "        to: List of recipient email addresses\n",
    "        subject: Email subject line\n",
    "        body: Email body content\n",
    "        attachments: Optional list of attachment paths\n",
    "        \n",
    "    Returns:\n",
    "        Send status\n",
    "    \"\"\"\n",
    "    print(f\"üìß Sending email to: {to}\")\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"sent\",\n",
    "        \"recipients\": to,\n",
    "        \"subject\": subject,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"message_id\": \"MSG-12345\"\n",
    "    }\n",
    "\n",
    "\n",
    "def schedule_meeting(attendees: List[str], datetime_str: str, title: str, agenda: str) -> dict:\n",
    "    \"\"\"\n",
    "    Action Tool: Schedule calendar meeting.\n",
    "    \n",
    "    Args:\n",
    "        attendees: List of attendee emails\n",
    "        datetime_str: Meeting datetime\n",
    "        title: Meeting title\n",
    "        agenda: Meeting agenda\n",
    "        \n",
    "    Returns:\n",
    "        Scheduling status\n",
    "    \"\"\"\n",
    "    print(f\"üìÜ Scheduling meeting: {title}\")\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"scheduled\",\n",
    "        \"meeting_id\": \"MTG-67890\",\n",
    "        \"title\": title,\n",
    "        \"datetime\": datetime_str,\n",
    "        \"attendees\": attendees,\n",
    "        \"calendar_link\": \"https://calendar.example.com/mtg-67890\"\n",
    "    }\n",
    "\n",
    "\n",
    "def upload_to_sharepoint(file_path: str, destination: str) -> dict:\n",
    "    \"\"\"\n",
    "    Action Tool: Upload file to SharePoint.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Local file path\n",
    "        destination: SharePoint destination folder\n",
    "        \n",
    "    Returns:\n",
    "        Upload status\n",
    "    \"\"\"\n",
    "    print(f\"‚òÅÔ∏è Uploading to SharePoint: {destination}\")\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"uploaded\",\n",
    "        \"source\": file_path,\n",
    "        \"destination\": destination,\n",
    "        \"sharepoint_url\": f\"https://sharepoint.example.com/{destination}\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Action tools defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Tools\n",
    "print(\"Testing Observation Tools:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test BigQuery\n",
    "bq_result = query_bigquery(\"SELECT * FROM campaigns WHERE campaign_id = 'CAMP-2024-001'\")\n",
    "print(f\"BigQuery Result: {bq_result['total_rows']} rows in {bq_result['query_time_ms']}ms\")\n",
    "\n",
    "# Test Looker\n",
    "looker_result = check_looker_dashboard(\"DASH-001\")\n",
    "print(f\"Looker Status: {looker_result['status']}, {looker_result['tiles']} tiles\")\n",
    "\n",
    "print(\"\\nTesting Action Tools:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test PPT Creation\n",
    "ppt_result = create_ppt_file({\"slides\": [{}, {}, {}]}, \"Q4_Campaign_Report.pptx\")\n",
    "print(f\"PPT Created: {ppt_result['filename']} ({ppt_result['slides']} slides)\")\n",
    "\n",
    "# Test Email\n",
    "email_result = send_email(\n",
    "    to=[\"stakeholder@example.com\"],\n",
    "    subject=\"Campaign Report Ready\",\n",
    "    body=\"Your Q4 campaign report is ready for review.\"\n",
    ")\n",
    "print(f\"Email Sent: {email_result['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Rule-Based Reasoning (Lab 9)\n",
    "\n",
    "Implementing validation and quality check rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleBasedValidator:\n",
    "    \"\"\"\n",
    "    Rule-based validation system for campaign data.\n",
    "    Applies deterministic rules for quality assurance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rules = []\n",
    "        self._define_rules()\n",
    "    \n",
    "    def _define_rules(self):\n",
    "        \"\"\"Define validation rules.\"\"\"\n",
    "        \n",
    "        # Rule 1: Required fields check\n",
    "        self.rules.append({\n",
    "            \"name\": \"required_fields\",\n",
    "            \"description\": \"Check all required fields are present\",\n",
    "            \"check\": lambda data: self._check_required_fields(data)\n",
    "        })\n",
    "        \n",
    "        # Rule 2: Budget validation\n",
    "        self.rules.append({\n",
    "            \"name\": \"budget_validation\",\n",
    "            \"description\": \"Spend should not exceed budget\",\n",
    "            \"check\": lambda data: data.get(\"spend\", 0) <= data.get(\"budget\", 0)\n",
    "        })\n",
    "        \n",
    "        # Rule 3: Date validation\n",
    "        self.rules.append({\n",
    "            \"name\": \"date_validation\",\n",
    "            \"description\": \"End date should be after start date\",\n",
    "            \"check\": lambda data: data.get(\"end_date\", \"\") > data.get(\"start_date\", \"\")\n",
    "        })\n",
    "        \n",
    "        # Rule 4: Conversion rate sanity check\n",
    "        self.rules.append({\n",
    "            \"name\": \"conversion_sanity\",\n",
    "            \"description\": \"Conversions should not exceed clicks\",\n",
    "            \"check\": lambda data: data.get(\"conversions\", 0) <= data.get(\"clicks\", 1)\n",
    "        })\n",
    "        \n",
    "        # Rule 5: Click-through sanity check\n",
    "        self.rules.append({\n",
    "            \"name\": \"click_sanity\",\n",
    "            \"description\": \"Clicks should not exceed impressions\",\n",
    "            \"check\": lambda data: data.get(\"clicks\", 0) <= data.get(\"impressions\", 1)\n",
    "        })\n",
    "        \n",
    "        # Rule 6: Positive values check\n",
    "        self.rules.append({\n",
    "            \"name\": \"positive_values\",\n",
    "            \"description\": \"Numeric values should be non-negative\",\n",
    "            \"check\": lambda data: all(\n",
    "                data.get(field, 0) >= 0 \n",
    "                for field in [\"budget\", \"spend\", \"impressions\", \"clicks\", \"conversions\"]\n",
    "            )\n",
    "        })\n",
    "    \n",
    "    def _check_required_fields(self, data: dict) -> bool:\n",
    "        \"\"\"Check all required fields are present.\"\"\"\n",
    "        required = [\n",
    "            \"campaign_id\", \"campaign_name\", \"start_date\", \"end_date\",\n",
    "            \"budget\", \"spend\", \"impressions\", \"clicks\", \"conversions\"\n",
    "        ]\n",
    "        return all(field in data and data[field] is not None for field in required)\n",
    "    \n",
    "    def validate(self, data: dict) -> dict:\n",
    "        \"\"\"Run all validation rules.\"\"\"\n",
    "        results = {\n",
    "            \"valid\": True,\n",
    "            \"passed\": [],\n",
    "            \"failed\": []\n",
    "        }\n",
    "        \n",
    "        for rule in self.rules:\n",
    "            try:\n",
    "                if rule[\"check\"](data):\n",
    "                    results[\"passed\"].append(rule[\"name\"])\n",
    "                else:\n",
    "                    results[\"failed\"].append({\n",
    "                        \"rule\": rule[\"name\"],\n",
    "                        \"description\": rule[\"description\"]\n",
    "                    })\n",
    "                    results[\"valid\"] = False\n",
    "            except Exception as e:\n",
    "                results[\"failed\"].append({\n",
    "                    \"rule\": rule[\"name\"],\n",
    "                    \"description\": f\"Error: {str(e)}\"\n",
    "                })\n",
    "                results[\"valid\"] = False\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"‚úÖ Rule-based validator defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Rule-Based Validation\n",
    "validator = RuleBasedValidator()\n",
    "\n",
    "# Test with valid data\n",
    "print(\"Testing with VALID campaign data:\")\n",
    "print(\"=\" * 40)\n",
    "result = validator.validate(sample_campaign)\n",
    "print(f\"Valid: {result['valid']}\")\n",
    "print(f\"Passed Rules: {result['passed']}\")\n",
    "print(f\"Failed Rules: {result['failed']}\")\n",
    "\n",
    "# Test with invalid data\n",
    "print(\"\\nTesting with INVALID campaign data:\")\n",
    "print(\"=\" * 40)\n",
    "invalid_campaign = {\n",
    "    \"campaign_id\": \"CAMP-BAD\",\n",
    "    \"campaign_name\": \"Bad Campaign\",\n",
    "    \"start_date\": \"2024-12-31\",\n",
    "    \"end_date\": \"2024-01-01\",  # End before start\n",
    "    \"budget\": 10000,\n",
    "    \"spend\": 15000,  # Over budget\n",
    "    \"impressions\": 1000,\n",
    "    \"clicks\": 2000,  # More clicks than impressions\n",
    "    \"conversions\": 50\n",
    "}\n",
    "result = validator.validate(invalid_campaign)\n",
    "print(f\"Valid: {result['valid']}\")\n",
    "print(f\"Passed Rules: {result['passed']}\")\n",
    "print(f\"Failed Rules:\")\n",
    "for failure in result['failed']:\n",
    "    print(f\"  - {failure['rule']}: {failure['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Hierarchical Planning (Lab 8)\n",
    "\n",
    "Implementing task decomposition with dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define Pydantic models for hierarchical planning\n",
    "class TaskDependencies(BaseModel):\n",
    "    \"\"\"Model for task dependencies.\"\"\"\n",
    "    task1_depends_on: str = Field(description=\"What task 1 depends on, or 'None'\")\n",
    "    task2_depends_on: str = Field(description=\"What task 2 depends on, or 'None'\")\n",
    "    task3_depends_on: str = Field(description=\"What task 3 depends on, or 'None'\")\n",
    "    task4_depends_on: str = Field(description=\"What task 4 depends on, or 'None'\")\n",
    "    task5_depends_on: str = Field(description=\"What task 5 depends on, or 'None'\")\n",
    "    task6_depends_on: str = Field(description=\"What task 6 depends on, or 'None'\")\n",
    "\n",
    "class TaskAssignments(BaseModel):\n",
    "    \"\"\"Model for task assignments to agents.\"\"\"\n",
    "    task1_assignee: str = Field(description=\"Agent assigned to task 1\")\n",
    "    task2_assignee: str = Field(description=\"Agent assigned to task 2\")\n",
    "    task3_assignee: str = Field(description=\"Agent assigned to task 3\")\n",
    "    task4_assignee: str = Field(description=\"Agent assigned to task 4\")\n",
    "    task5_assignee: str = Field(description=\"Agent assigned to task 5\")\n",
    "    task6_assignee: str = Field(description=\"Agent assigned to task 6\")\n",
    "\n",
    "# Define hierarchical state\n",
    "class HierarchicalState(TypedDict):\n",
    "    goal: str\n",
    "    tasks: List[str]\n",
    "    dependencies: dict\n",
    "    assignments: dict\n",
    "    review: str\n",
    "\n",
    "print(\"‚úÖ Hierarchical planning models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campaign Workflow Tasks\n",
    "CAMPAIGN_TASKS = [\n",
    "    \"Validate input campaign data\",\n",
    "    \"Query and prepare data from BigQuery\",\n",
    "    \"Configure Looker monitoring dashboards\",\n",
    "    \"Perform analytical review and generate insights\",\n",
    "    \"Confirm stakeholder availability and schedule\",\n",
    "    \"Assemble final PowerPoint presentation\"\n",
    "]\n",
    "\n",
    "# Task dependencies (what each task depends on)\n",
    "TASK_DEPENDENCIES = {\n",
    "    \"Validate input campaign data\": None,\n",
    "    \"Query and prepare data from BigQuery\": \"Validate input campaign data\",\n",
    "    \"Configure Looker monitoring dashboards\": \"Query and prepare data from BigQuery\",\n",
    "    \"Perform analytical review and generate insights\": \"Query and prepare data from BigQuery\",\n",
    "    \"Confirm stakeholder availability and schedule\": None,\n",
    "    \"Assemble final PowerPoint presentation\": \"Perform analytical review and generate insights\"\n",
    "}\n",
    "\n",
    "# Agent assignments\n",
    "AGENT_ASSIGNMENTS = {\n",
    "    \"Validate input campaign data\": \"ValidationAgent\",\n",
    "    \"Query and prepare data from BigQuery\": \"DataPreparationAgent\",\n",
    "    \"Configure Looker monitoring dashboards\": \"MonitoringAgent\",\n",
    "    \"Perform analytical review and generate insights\": \"AnalysisAgent\",\n",
    "    \"Confirm stakeholder availability and schedule\": \"SchedulingAgent\",\n",
    "    \"Assemble final PowerPoint presentation\": \"PresentationAgent\"\n",
    "}\n",
    "\n",
    "print(\"Campaign Workflow Hierarchy:\")\n",
    "print(\"=\" * 50)\n",
    "for i, task in enumerate(CAMPAIGN_TASKS, 1):\n",
    "    dep = TASK_DEPENDENCIES.get(task, \"None\")\n",
    "    agent = AGENT_ASSIGNMENTS.get(task, \"Unknown\")\n",
    "    print(f\"{i}. {task}\")\n",
    "    print(f\"   Depends on: {dep or 'None'}\")\n",
    "    print(f\"   Assigned to: {agent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalPlanner:\n",
    "    \"\"\"\n",
    "    Hierarchical planner that decomposes tasks and manages dependencies.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tasks: List[str], dependencies: dict, assignments: dict):\n",
    "        self.tasks = tasks\n",
    "        self.dependencies = dependencies\n",
    "        self.assignments = assignments\n",
    "        self.completed = set()\n",
    "    \n",
    "    def get_ready_tasks(self) -> List[str]:\n",
    "        \"\"\"Get tasks that are ready to execute (dependencies met).\"\"\"\n",
    "        ready = []\n",
    "        for task in self.tasks:\n",
    "            if task not in self.completed:\n",
    "                dep = self.dependencies.get(task)\n",
    "                if dep is None or dep in self.completed:\n",
    "                    ready.append(task)\n",
    "        return ready\n",
    "    \n",
    "    def complete_task(self, task: str):\n",
    "        \"\"\"Mark a task as completed.\"\"\"\n",
    "        self.completed.add(task)\n",
    "    \n",
    "    def get_execution_order(self) -> List[str]:\n",
    "        \"\"\"Get the optimal execution order respecting dependencies.\"\"\"\n",
    "        order = []\n",
    "        temp_completed = set()\n",
    "        \n",
    "        while len(order) < len(self.tasks):\n",
    "            for task in self.tasks:\n",
    "                if task not in temp_completed:\n",
    "                    dep = self.dependencies.get(task)\n",
    "                    if dep is None or dep in temp_completed:\n",
    "                        order.append(task)\n",
    "                        temp_completed.add(task)\n",
    "        \n",
    "        return order\n",
    "    \n",
    "    def get_plan_summary(self) -> str:\n",
    "        \"\"\"Generate a summary of the hierarchical plan.\"\"\"\n",
    "        order = self.get_execution_order()\n",
    "        summary = \"Hierarchical Execution Plan:\\n\"\n",
    "        summary += \"=\" * 40 + \"\\n\"\n",
    "        \n",
    "        for i, task in enumerate(order, 1):\n",
    "            agent = self.assignments.get(task, \"Unknown\")\n",
    "            dep = self.dependencies.get(task, \"None\")\n",
    "            summary += f\"\\nStep {i}: {task}\\n\"\n",
    "            summary += f\"  Agent: {agent}\\n\"\n",
    "            summary += f\"  Depends on: {dep or 'None'}\\n\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Create and test the planner\n",
    "planner = HierarchicalPlanner(CAMPAIGN_TASKS, TASK_DEPENDENCIES, AGENT_ASSIGNMENTS)\n",
    "print(planner.get_plan_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Error Recovery (Lab 12)\n",
    "\n",
    "Implementing resilient operations with retry logic and fallbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "class RetryConfig:\n",
    "    \"\"\"Configuration for retry behavior.\"\"\"\n",
    "    max_retries: int = 3\n",
    "    initial_delay: float = 1.0\n",
    "    backoff_multiplier: float = 2.0\n",
    "    max_delay: float = 30.0\n",
    "\n",
    "def with_retry(max_retries: int = 3, delay: float = 1.0, backoff: float = 2.0):\n",
    "    \"\"\"\n",
    "    Decorator for automatic retry with exponential backoff.\n",
    "    \n",
    "    Args:\n",
    "        max_retries: Maximum number of retry attempts\n",
    "        delay: Initial delay between retries (seconds)\n",
    "        backoff: Multiplier for delay on each retry\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            current_delay = delay\n",
    "            last_exception = None\n",
    "            \n",
    "            for attempt in range(max_retries + 1):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    last_exception = e\n",
    "                    if attempt < max_retries:\n",
    "                        print(f\"‚ö†Ô∏è Attempt {attempt + 1} failed: {str(e)}\")\n",
    "                        print(f\"   Retrying in {current_delay:.1f}s...\")\n",
    "                        time.sleep(current_delay)\n",
    "                        current_delay *= backoff\n",
    "                    else:\n",
    "                        print(f\"‚ùå All {max_retries + 1} attempts failed\")\n",
    "            \n",
    "            raise last_exception\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "class ResilientAgent(Agent):\n",
    "    \"\"\"\n",
    "    Agent with built-in error recovery capabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, fallback_response: str = \"Unable to process request\"):\n",
    "        super().__init__(name)\n",
    "        self.fallback_response = fallback_response\n",
    "        self.error_count = 0\n",
    "        self.success_count = 0\n",
    "    \n",
    "    @with_retry(max_retries=2, delay=1.0, backoff=2.0)\n",
    "    def _call_llm_with_retry(self, user_message: str) -> str:\n",
    "        \"\"\"Call LLM with automatic retry.\"\"\"\n",
    "        return self._call_llm(user_message)\n",
    "    \n",
    "    def _select_action(self, sensors: dict) -> str:\n",
    "        \"\"\"Select action with error handling.\"\"\"\n",
    "        try:\n",
    "            result = self._call_llm_with_retry(\n",
    "                f\"Process this input: {json.dumps(sensors)}\"\n",
    "            )\n",
    "            self.success_count += 1\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self.error_count += 1\n",
    "            print(f\"‚ö†Ô∏è Agent {self.name} falling back due to: {str(e)}\")\n",
    "            return self.fallback_response\n",
    "    \n",
    "    def get_health_status(self) -> dict:\n",
    "        \"\"\"Get agent health metrics.\"\"\"\n",
    "        total = self.success_count + self.error_count\n",
    "        success_rate = (self.success_count / total * 100) if total > 0 else 100\n",
    "        \n",
    "        return {\n",
    "            \"agent\": self.name,\n",
    "            \"total_requests\": total,\n",
    "            \"successes\": self.success_count,\n",
    "            \"errors\": self.error_count,\n",
    "            \"success_rate\": f\"{success_rate:.1f}%\",\n",
    "            \"status\": \"healthy\" if success_rate >= 90 else \"degraded\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Error recovery patterns defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circuit Breaker Pattern\n",
    "class CircuitBreaker:\n",
    "    \"\"\"\n",
    "    Circuit breaker to prevent cascading failures.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, failure_threshold: int = 5, recovery_timeout: float = 60.0):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.recovery_timeout = recovery_timeout\n",
    "        self.failures = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n",
    "    \n",
    "    def record_failure(self):\n",
    "        \"\"\"Record a failure.\"\"\"\n",
    "        self.failures += 1\n",
    "        self.last_failure_time = time.time()\n",
    "        \n",
    "        if self.failures >= self.failure_threshold:\n",
    "            self.state = \"OPEN\"\n",
    "            print(f\"üî¥ Circuit breaker OPENED after {self.failures} failures\")\n",
    "    \n",
    "    def record_success(self):\n",
    "        \"\"\"Record a success.\"\"\"\n",
    "        self.failures = 0\n",
    "        self.state = \"CLOSED\"\n",
    "    \n",
    "    def can_proceed(self) -> bool:\n",
    "        \"\"\"Check if operation can proceed.\"\"\"\n",
    "        if self.state == \"CLOSED\":\n",
    "            return True\n",
    "        \n",
    "        if self.state == \"OPEN\":\n",
    "            # Check if recovery timeout has passed\n",
    "            if time.time() - self.last_failure_time >= self.recovery_timeout:\n",
    "                self.state = \"HALF_OPEN\"\n",
    "                print(\"üü° Circuit breaker HALF_OPEN, testing...\")\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        return True  # HALF_OPEN allows one request\n",
    "    \n",
    "    def get_status(self) -> dict:\n",
    "        \"\"\"Get circuit breaker status.\"\"\"\n",
    "        return {\n",
    "            \"state\": self.state,\n",
    "            \"failures\": self.failures,\n",
    "            \"threshold\": self.failure_threshold,\n",
    "            \"recovery_timeout\": self.recovery_timeout\n",
    "        }\n",
    "\n",
    "# Test circuit breaker\n",
    "cb = CircuitBreaker(failure_threshold=3)\n",
    "print(\"Circuit Breaker Status:\", cb.get_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Complete End-to-End Workflow (Lab 11)\n",
    "\n",
    "Bringing all components together into a complete campaign processing system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CampaignProcessingSystem:\n",
    "    \"\"\"\n",
    "    Complete end-to-end campaign processing system.\n",
    "    Integrates all course techniques into a production-ready workflow.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize agents\n",
    "        self.validation_agent = ValidationAgent()\n",
    "        self.data_prep_agent = DataPreparationAgent()\n",
    "        self.monitoring_agent = MonitoringAgent()\n",
    "        self.analysis_agent = AnalysisAgent()\n",
    "        self.scheduling_agent = SchedulingAgent()\n",
    "        self.presentation_agent = PresentationAgent()\n",
    "        \n",
    "        # Initialize rule-based validator\n",
    "        self.rule_validator = RuleBasedValidator()\n",
    "        \n",
    "        # Initialize hierarchical planner\n",
    "        self.planner = HierarchicalPlanner(\n",
    "            CAMPAIGN_TASKS, \n",
    "            TASK_DEPENDENCIES, \n",
    "            AGENT_ASSIGNMENTS\n",
    "        )\n",
    "        \n",
    "        # Initialize circuit breaker\n",
    "        self.circuit_breaker = CircuitBreaker()\n",
    "        \n",
    "        # Processing state\n",
    "        self.state = {}\n",
    "    \n",
    "    def process_campaign(self, campaign_data: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Process a campaign through the complete workflow.\n",
    "        \n",
    "        Args:\n",
    "            campaign_data: Raw campaign data dictionary\n",
    "            \n",
    "        Returns:\n",
    "            Processing results dictionary\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"CAMPAIGN PROCESSING SYSTEM\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Processing: {campaign_data.get('campaign_name', 'Unknown')}\")\n",
    "        print(f\"Campaign ID: {campaign_data.get('campaign_id', 'Unknown')}\")\n",
    "        \n",
    "        results = {\n",
    "            \"campaign_id\": campaign_data.get(\"campaign_id\"),\n",
    "            \"status\": \"processing\",\n",
    "            \"steps\": {}\n",
    "        }\n",
    "        \n",
    "        # Step 1: Rule-Based Validation\n",
    "        print(\"\\n--- Step 1: Rule-Based Validation ---\")\n",
    "        validation_result = self.rule_validator.validate(campaign_data)\n",
    "        results[\"steps\"][\"validation\"] = validation_result\n",
    "        \n",
    "        if not validation_result[\"valid\"]:\n",
    "            print(\"‚ùå Validation failed\")\n",
    "            results[\"status\"] = \"validation_failed\"\n",
    "            return results\n",
    "        print(\"‚úÖ Validation passed\")\n",
    "        \n",
    "        # Step 2: AI-Powered Analysis\n",
    "        print(\"\\n--- Step 2: AI-Powered Analysis ---\")\n",
    "        if self.circuit_breaker.can_proceed():\n",
    "            try:\n",
    "                analysis = self.analysis_agent.act({\"performance_data\": campaign_data})\n",
    "                results[\"steps\"][\"analysis\"] = analysis\n",
    "                self.circuit_breaker.record_success()\n",
    "                print(\"‚úÖ Analysis complete\")\n",
    "            except Exception as e:\n",
    "                self.circuit_breaker.record_failure()\n",
    "                results[\"steps\"][\"analysis\"] = f\"Error: {str(e)}\"\n",
    "                print(f\"‚ö†Ô∏è Analysis error: {str(e)}\")\n",
    "        else:\n",
    "            results[\"steps\"][\"analysis\"] = \"Circuit breaker open\"\n",
    "            print(\"‚ö†Ô∏è Analysis skipped (circuit breaker open)\")\n",
    "        \n",
    "        # Step 3: Data Preparation\n",
    "        print(\"\\n--- Step 3: Data Preparation ---\")\n",
    "        prepared_data = {\n",
    "            **campaign_data,\n",
    "            \"ctr\": round((campaign_data[\"clicks\"] / campaign_data[\"impressions\"]) * 100, 2),\n",
    "            \"cpa\": round(campaign_data[\"spend\"] / campaign_data[\"conversions\"], 2),\n",
    "            \"conversion_rate\": round((campaign_data[\"conversions\"] / campaign_data[\"clicks\"]) * 100, 2),\n",
    "            \"budget_utilization\": round((campaign_data[\"spend\"] / campaign_data[\"budget\"]) * 100, 2)\n",
    "        }\n",
    "        results[\"steps\"][\"prepared_data\"] = prepared_data\n",
    "        print(f\"‚úÖ Data prepared (CTR: {prepared_data['ctr']}%, CPA: ${prepared_data['cpa']})\")\n",
    "        \n",
    "        # Step 4: Presentation Generation\n",
    "        print(\"\\n--- Step 4: Presentation Generation ---\")\n",
    "        presentation = self.presentation_agent.act({\n",
    "            \"analysis\": results[\"steps\"].get(\"analysis\", \"\"),\n",
    "            \"campaign_data\": prepared_data\n",
    "        })\n",
    "        results[\"steps\"][\"presentation\"] = presentation\n",
    "        print(\"‚úÖ Presentation content generated\")\n",
    "        \n",
    "        # Step 5: Tool Actions\n",
    "        print(\"\\n--- Step 5: Tool Actions ---\")\n",
    "        ppt_result = create_ppt_file(\n",
    "            {\"slides\": [{}, {}, {}, {}, {}, {}]},\n",
    "            f\"{campaign_data['campaign_id']}_report.pptx\"\n",
    "        )\n",
    "        results[\"steps\"][\"ppt_created\"] = ppt_result\n",
    "        \n",
    "        upload_result = upload_to_sharepoint(\n",
    "            ppt_result[\"path\"],\n",
    "            f\"campaigns/{campaign_data['campaign_id']}/\"\n",
    "        )\n",
    "        results[\"steps\"][\"uploaded\"] = upload_result\n",
    "        \n",
    "        # Finalize\n",
    "        results[\"status\"] = \"completed\"\n",
    "        results[\"completed_at\"] = datetime.now().isoformat()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ CAMPAIGN PROCESSING COMPLETE\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"‚úÖ Complete processing system defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete workflow\n",
    "system = CampaignProcessingSystem()\n",
    "final_results = system.process_campaign(sample_campaign)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nStatus: {final_results['status']}\")\n",
    "print(f\"Campaign ID: {final_results['campaign_id']}\")\n",
    "print(f\"Completed: {final_results.get('completed_at', 'N/A')}\")\n",
    "\n",
    "print(\"\\nKey Metrics:\")\n",
    "if \"prepared_data\" in final_results[\"steps\"]:\n",
    "    pd = final_results[\"steps\"][\"prepared_data\"]\n",
    "    print(f\"  - CTR: {pd['ctr']}%\")\n",
    "    print(f\"  - CPA: ${pd['cpa']}\")\n",
    "    print(f\"  - Conversion Rate: {pd['conversion_rate']}%\")\n",
    "    print(f\"  - Budget Utilization: {pd['budget_utilization']}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Course Techniques Applied\n",
    "\n",
    "This notebook demonstrated the application of all 12 lab modules from GAI-3101 to the Campaign Execution & Committee Presentation use case:\n",
    "\n",
    "| Module | Technique | Implementation |\n",
    "|--------|-----------|----------------|\n",
    "| **Lab 1** | Simple Python Agent | `Agent` base class with `_select_action()` and `act()` methods |\n",
    "| **Lab 2** | Round Robin Communication | AutoGen `RoundRobinGroupChat` with validator, analyst, presenter |\n",
    "| **Lab 3** | Reactive Agent | Real-time monitoring patterns (implicit in tool responses) |\n",
    "| **Lab 4** | Deliberative Agent | LangGraph `StateGraph` with planner ‚Üí executor ‚Üí finalizer |\n",
    "| **Lab 5** | Long-Term Memory | Agent memory arrays and state persistence |\n",
    "| **Lab 6** | Observation Tools | `query_bigquery()`, `check_looker_dashboard()`, `get_stakeholder_calendars()` |\n",
    "| **Lab 7** | Action Tools | `create_ppt_file()`, `send_email()`, `schedule_meeting()`, `upload_to_sharepoint()` |\n",
    "| **Lab 8** | Hierarchical Planning | `HierarchicalPlanner` with task dependencies |\n",
    "| **Lab 9** | Rule-Based Reasoning | `RuleBasedValidator` with deterministic quality checks |\n",
    "| **Lab 10** | Robustness Evaluation | Validation testing with valid/invalid data |\n",
    "| **Lab 11** | Personal Assistant | `CampaignProcessingSystem` end-to-end workflow |\n",
    "| **Lab 12** | Error Recovery | `@with_retry` decorator, `CircuitBreaker`, `ResilientAgent` |\n",
    "\n",
    "### Business Impact\n",
    "\n",
    "- **Time Savings**: From 40 hours ‚Üí 16.5 hours (59% reduction)\n",
    "- **Error Reduction**: Rule-based validation catches data issues early\n",
    "- **Consistency**: Standardized analysis and presentation format\n",
    "- **Scalability**: Multi-agent architecture enables parallel processing\n",
    "- **Resilience**: Built-in error recovery ensures workflow completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Connect to Real Data Sources**: Replace simulated tools with actual BigQuery, Looker, and SharePoint integrations\n",
    "2. **Add Long-Term Memory**: Implement vector database for campaign history and learnings\n",
    "3. **Enhance Monitoring**: Add real-time alerts and dashboard updates\n",
    "4. **Production Deployment**: Containerize and deploy to Google Cloud Run\n",
    "5. **User Interface**: Build a Streamlit or Gradio interface for campaign submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
