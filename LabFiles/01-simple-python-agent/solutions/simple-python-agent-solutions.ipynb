{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing a Simple Agent in Python - SOLUTION\n",
    "\n",
    "> **Learning Objectives:**\n",
    "> - Understand the basic structure of an agent.\n",
    "> - Implement a simple agent in Python.\n",
    "> - Test the performance of the agent.\n",
    "\n",
    "## Introduction\n",
    "Agentic AI is most often developed using libraries such as [LangGraph](https://www.langchain.com/langgraph) or [AutoGen](https://microsoft.github.io/autogen/0.2/). However, it is also possible to create a simple agent using Python. In this notebook, we will create a simple agent that can interact with a basic environment. Our agent will be placed in a simple environment called the Wumpus World. This is a classic problem in the field of AI and provides a good starting point for observing how an agent can interact with an environment to achieve a goal but without specific instructions on how to do so.\n",
    "\n",
    "### The Wumpus World\n",
    "The Wumpus World is a cave consisting of rooms connected by passageways. The rooms are arranged in a 4x4 grid. In the cave is a **Wumpus** that eats any agents which enter the room. The agent can feel a **stench** in the room if the Wumpus is in a neighboring room.\n",
    "\n",
    "The cave also contains **pits**. If an agent enters a room with a pit, it falls in and dies. The agent can feel a **breeze** in the room if there is a pit in a neighboring room. The agent has a **gold** detector that beeps when the agent is in a room containing gold. The agent can pick up the gold and leave the cave. The agent can also climb out of the cave without the gold.\n",
    "\n",
    "### Performance\n",
    "The agent receives a reward of +1000 for climbing out of the cave with the gold, -1000 for falling into a pit or being eaten by the Wumpus, and -1 for each action taken. The game ends when the agent climbs out of the cave, dies, or takes more than 20 actions.\n",
    "\n",
    "### Environment\n",
    "The environment is represented by a 4x4 grid. The agent always starts in the bottom-left corner of the grid. The Wumpus, pits, and gold are placed randomly in the other rooms.\n",
    "\n",
    "### Actions\n",
    "The agent can take the following actions:\n",
    "\n",
    "- `Up`: Move up one room.\n",
    "- `Down`: Move down one room.\n",
    "- `Left`: Move left one room.\n",
    "- `Right`: Move right one room.\n",
    "- `Grab`: Grab the gold, if it is in the room.\n",
    "- `Climb`: Climb out of the cave, from the starting room.\n",
    "\n",
    "### Sensors\n",
    "The agent has the following sensors:\n",
    "\n",
    "* `Stench`: Detects a stench in adjacent rooms (not diagonally).\n",
    "* `Breeze`: Detects a breeze in adjacent rooms (not diagonally).\n",
    "* `Glitter`: Detects gold in the current room.\n",
    "* `Ladder`: Detects the ladder in the starting room.\n",
    "* `Bump`: Detects when the agent tries to move forward into a wall.\n",
    "\n",
    "### Example Board\n",
    "\n",
    "Here is an example of a Wumpus World board. Wind is represented by ‚òÅÔ∏è, gold by ü™ô, and stench by üëÉüèª.\n",
    "\n",
    "|       | Col 1  | Col 2   | Col 3   | Col 4       |\n",
    "|-------|--------|---------|---------|-------------|\n",
    "| Row 1 | ‚òÅÔ∏è     | ‚òÅÔ∏è      | Pit     | ‚òÅÔ∏è        |\n",
    "| Row 2 | Pit    | ‚òÅÔ∏è      | ‚òÅÔ∏è      | ü™ô, üëÉüèª    |\n",
    "| Row 3 | ‚òÅÔ∏è     |         | üëÉüèª     | Wumpus      |\n",
    "| Row 4 | Agent  |         |         | üëÉüèª         |\n",
    "\n",
    "\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Let's start by installing the required libraries and setting the OpenAI API key. The OpenAI API key is required to access the OpenAI models.\n",
    "\n",
    "Run the following cell to install the required libraries and set the OpenAI API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "%pip install -q openai==1.61.1\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core\n",
    "\n",
    "### Step 1 - Define the Environment\n",
    "For this lab, we have already written the code for the environment. The code is provided below. \n",
    "\n",
    "Run the cell below to define the environment and test the game.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Note:** Use the action enum codes to perform the actions. For example, to move up, enter `Up`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ P \n",
      "W P ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': True, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter action:  Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Over!\n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ P \n",
      "A P ‚Ä¢ ‚Ä¢ \n",
      "L ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 2), 'stench': False, 'breeze': True, 'glitter': False, 'ladder': False, 'bump': False}\n",
      "moves=1, game_over=True\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class Markers(Enum):\n",
    "    AGENT = 'A'\n",
    "    WUMPUS = 'W'\n",
    "    PIT = 'P'\n",
    "    GOLD = 'G'\n",
    "    LADDER = 'L'\n",
    "    EMPTY = '‚Ä¢'\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "class Actions(Enum):\n",
    "    MOVE_UP = 'Up'\n",
    "    MOVE_DOWN = 'Down'\n",
    "    MOVE_LEFT = 'Left'\n",
    "    MOVE_RIGHT = 'Right'\n",
    "    GRAB = 'Grab'\n",
    "    CLIMB = 'Climb'\n",
    "\n",
    "\n",
    "class WumpusWorld:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def random_empty(self):\n",
    "        while True:\n",
    "            x = random.randint(0, 3)\n",
    "            y = random.randint(0, 3)\n",
    "            if self.board[y, x] == Markers.EMPTY and (x, y) != (0, 3):\n",
    "                return (x, y)\n",
    "    \n",
    "    def set(self, x, y, value):\n",
    "        self.board[y, x] = value\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.full((4, 4), Markers.EMPTY)\n",
    "\n",
    "        # Add the ladder\n",
    "        self.set(0, 3, Markers.LADDER)\n",
    "\n",
    "        # Randomize Wumpus position\n",
    "        self.set(*self.random_empty(), Markers.WUMPUS)\n",
    "\n",
    "        # Add two pits\n",
    "        self.set(*self.random_empty(), Markers.PIT)\n",
    "        self.set(*self.random_empty(), Markers.PIT)\n",
    "\n",
    "        # Add the gold\n",
    "        self.set(*self.random_empty(), Markers.GOLD)\n",
    "\n",
    "        # Agent properties\n",
    "        self.has_gold = False\n",
    "        self.game_over = False\n",
    "        self.agent_direction = 0 # 0 = up, 1 = right, 2 = down, 3 = left\n",
    "        self.agent_position = (0, 3)\n",
    "        self.action_counter = 0\n",
    "\n",
    "        self.sensors = { }\n",
    "        self.update_sensors()\n",
    "    \n",
    "    def update_sensors(self):\n",
    "        x, y = self.agent_position\n",
    "        self.sensors['position'] = (x, y)\n",
    "        self.sensors['stench'] = any(self.board[ny, nx] == Markers.WUMPUS for nx, ny in [(x, y+1), (x, y-1), (x+1, y), (x-1, y)] if 0 <= nx < 4 and 0 <= ny < 4)\n",
    "        self.sensors['breeze'] = any(self.board[ny, nx] == Markers.PIT for nx, ny in [(x, y+1), (x, y-1), (x+1, y), (x-1, y)] if 0 <= nx < 4 and 0 <= ny < 4)\n",
    "        self.sensors['glitter'] = self.board[y, x] == Markers.GOLD\n",
    "        self.sensors['ladder'] = self.board[y, x] == Markers.LADDER\n",
    "\n",
    "        self.game_over = self.game_over \\\n",
    "            or self.board[y, x] == Markers.WUMPUS \\\n",
    "            or self.board[y, x] == Markers.PIT \\\n",
    "            or self.action_counter > 20\n",
    "    \n",
    "    def __str__(self):\n",
    "        r = ''\n",
    "        for y in range(4):\n",
    "            for x in range(4):\n",
    "                if (x, y) == self.agent_position:\n",
    "                    r += f'{Markers.AGENT} '\n",
    "                else:\n",
    "                    r += f'{self.board[y, x]} '\n",
    "            r += '\\n'\n",
    "        r += f'{self.sensors}\\n'\n",
    "        r += f'moves={self.action_counter}, game_over={self.game_over}'\n",
    "        return r\n",
    "    \n",
    "    def move(self, dx, dy):\n",
    "        x, y = self.agent_position\n",
    "        new_x = x + dx\n",
    "        new_y = y + dy\n",
    "\n",
    "        if new_x < 0 or new_x >= 4 or new_y < 0 or new_y >= 4:\n",
    "            self.update_sensors()\n",
    "            self.sensors['bump'] = True\n",
    "            return\n",
    "\n",
    "        self.agent_position = (new_x, new_y)\n",
    "        self.sensors['bump'] = False\n",
    "        self.update_sensors()\n",
    "    \n",
    "    def grab(self):\n",
    "        if self.sensors['glitter']:\n",
    "            self.has_gold = True\n",
    "            self.board[self.agent_position[1], self.agent_position[0]] = Markers.EMPTY\n",
    "        self.update_sensors()\n",
    "    \n",
    "    def climb(self):\n",
    "        if self.agent_position == (0, 3):\n",
    "            self.game_over = True\n",
    "        self.update_sensors()\n",
    "\n",
    "    def score(self):\n",
    "        score = -self.action_counter\n",
    "        if self.agent_position == (0, 3) and self.has_gold:\n",
    "            score += 1000\n",
    "        if self.board[self.agent_position[1], self.agent_position[0]] == Markers.WUMPUS or \\\n",
    "            self.board[self.agent_position[1], self.agent_position[0]] == Markers.PIT:\n",
    "            score -= 1000\n",
    "        return score\n",
    "    \n",
    "    def is_win(self):\n",
    "        return self.agent_position == (0, 3) and self.has_gold\n",
    "    \n",
    "    def act(self, action):\n",
    "        self.action_counter += 1\n",
    "\n",
    "        match action:\n",
    "            case Actions.MOVE_UP: self.move(0, -1)\n",
    "            case Actions.MOVE_DOWN: self.move(0, 1)\n",
    "            case Actions.MOVE_LEFT: self.move(-1, 0)\n",
    "            case Actions.MOVE_RIGHT: self.move(1, 0)\n",
    "            case Actions.GRAB: self.grab()\n",
    "            case Actions.CLIMB: self.climb()\n",
    "            \n",
    "\n",
    "\n",
    "world = WumpusWorld()\n",
    "\n",
    "while not world.game_over:\n",
    "    print(world)\n",
    "    action = input(\"Enter action: \")\n",
    "    world.act(Actions(action))\n",
    "\n",
    "print('Game Over!')\n",
    "print(world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this isn't the most advanced game, it provides a good starting point for understanding agentic AI. Let's review our definition of Agentic AI.\n",
    "\n",
    "> **Agentic AI** is...\n",
    ">   * AI agents\n",
    ">   * Operating in an environment\n",
    ">   * From a context\n",
    ">   * Using tools\n",
    ">   * To achieve goals.\n",
    "\n",
    "Fill out the table below with the components of Agentic AI for the Wumpus World game."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "| Component   | Description\n",
    "|-------------|------------\n",
    "| AI Agents   |\n",
    "| Environment |\n",
    "| Context     |\n",
    "| Tools       |\n",
    "| Goals       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Define a Sample Agent\n",
    "For our agent, we will create a simple Python class that can interact with the environment. The agent will have a `perceive` method to receive sensor information and a `decide` method to choose an action based on the sensor information. The decision-making process for this agent will be very simple: if the agent perceives glitter, it will grab the gold; if the agent perceives a breeze or stench, it will move in a different direction; otherwise, it will move randomly.\n",
    "\n",
    "Run the cell below to define the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"Wumpus World agent base class\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.rng = np.random.default_rng()\n",
    "        self.has_gold = False\n",
    "        self.actions = []\n",
    "        self.sensors = []\n",
    "\n",
    "    def _select_action(self, sensors):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def act(self, sensors):\n",
    "        action = self._select_action(sensors)\n",
    "        self.actions.append(action)\n",
    "        self.sensors.append(sensors)\n",
    "\n",
    "        if action == Actions.GRAB and sensors['glitter']:\n",
    "            self.has_gold = True\n",
    "\n",
    "        return action\n",
    "\n",
    "class RandomAgent(Agent):\n",
    "    \"\"\"Wumpus World agent that acts randomly\"\"\"\n",
    "    def _select_action(self, sensors):   \n",
    "        if sensors['glitter']:\n",
    "            return Actions.GRAB\n",
    "        \n",
    "        if sensors['ladder'] and self.has_gold:\n",
    "            return Actions.CLIMB\n",
    "        \n",
    "        return self.rng.choice([\n",
    "            Actions.MOVE_UP, Actions.MOVE_DOWN, Actions.MOVE_LEFT, Actions.MOVE_RIGHT\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this simple agent, we can test how it performs in the Wumpus World environment.\n",
    "\n",
    "Run the cell below to test the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "Agent action: Actions.MOVE_LEFT\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True, 'bump': True}\n",
      "moves=1, game_over=False\n",
      "Agent action: Actions.MOVE_RIGHT\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "L A ‚Ä¢ P \n",
      "{'position': (1, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': False, 'bump': False}\n",
      "moves=2, game_over=False\n",
      "Agent action: Actions.MOVE_LEFT\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True, 'bump': False}\n",
      "moves=3, game_over=False\n",
      "Agent action: Actions.MOVE_LEFT\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True, 'bump': True}\n",
      "moves=4, game_over=False\n",
      "Agent action: Actions.MOVE_LEFT\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True, 'bump': True}\n",
      "moves=5, game_over=False\n",
      "Agent action: Actions.MOVE_DOWN\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True, 'bump': True}\n",
      "moves=6, game_over=False\n",
      "Agent action: Actions.MOVE_LEFT\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True, 'bump': True}\n",
      "moves=7, game_over=False\n",
      "Agent action: Actions.MOVE_LEFT\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True, 'bump': True}\n",
      "moves=8, game_over=False\n",
      "Agent action: Actions.MOVE_UP\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "L ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 2), 'stench': False, 'breeze': False, 'glitter': True, 'ladder': False, 'bump': False}\n",
      "moves=9, game_over=False\n",
      "Agent action: Actions.GRAB\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "L ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 2), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': False, 'bump': False}\n",
      "moves=10, game_over=False\n",
      "Agent action: Actions.MOVE_DOWN\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True, 'bump': False}\n",
      "moves=11, game_over=False\n",
      "Agent action: Actions.CLIMB\n",
      "988\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True, 'bump': False}\n",
      "moves=12, game_over=True\n",
      "Agent won!\n"
     ]
    }
   ],
   "source": [
    "world = WumpusWorld()\n",
    "agent = RandomAgent()\n",
    "\n",
    "while not world.game_over:\n",
    "    print(world)\n",
    "    action = agent.act(world.sensors)\n",
    "    world.act(action)\n",
    "    print(f'Agent action: {action}')\n",
    "\n",
    "print(world.score())\n",
    "print(world)\n",
    "print(f'Agent {\"won\" if world.is_win() else \"lost\"}!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More likely than not, the random agent lost the game. This is because the agent is not making decisions based on the information it receives from the environment. However, this random agent provides a good metric for comparison when we create more advanced agents. If our new agent can't outperform the random agent, then we know we have a problem.\n",
    "\n",
    "In the next cell, write code to run 10,000 games with the random agent and calculate the average score. This should run in just a few seconds. You can also calculate the win rate of the random agent by using `world.is_win()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: -764.1258\n",
      "Wins: 671\n",
      "Win rate: 6.71%\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# [ SOLUTION ]\n",
    "\n",
    "MAX_EPISODES = 10_000\n",
    "\n",
    "agent = RandomAgent()\n",
    "world = WumpusWorld()\n",
    "\n",
    "score = 0\n",
    "wins = 0\n",
    "\n",
    "for _ in range(MAX_EPISODES):\n",
    "    agent.reset()\n",
    "    world.reset()\n",
    "\n",
    "    while not world.game_over:\n",
    "        agent_action = agent.act(world.sensors)\n",
    "        world.act(agent_action)\n",
    "\n",
    "    score += world.score()\n",
    "\n",
    "    if world.is_win():\n",
    "        wins += 1\n",
    "\n",
    "print(f'Average score: {score / MAX_EPISODES}')\n",
    "print(f'Wins: {wins}')\n",
    "print(f'Win rate: {wins / MAX_EPISODES:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The random agent should have an average score of about -764 and a win rate of about 6-7%. Because the world is randomly generated, the exact numbers may vary.\n",
    "\n",
    "## Step 3 - Create a Generative AI Agent\n",
    "Now that we have a baseline, let's create an Agent with a generative AI model. We will use the OpenAI GPT-4o-mini model to generate the agent's actions based on the information it receives from the environment. \n",
    "\n",
    "The following cell tests that the OpenAI API is working correctly. Run the cell to generate a response from the GPT-4o-mini model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To determine the best action in the Wumpus World, I need to understand the current state of the environment, including your position, any known hazards (like pits or the Wumpus), and any treasures you might want to collect (like gold). \n",
       "\n",
       "Here are some general strategies:\n",
       "\n",
       "1. **If you are next to a pit or the Wumpus**, avoid moving in that direction. Instead, move to a safer square.\n",
       "2. **If you smell the Wumpus**, take precautions by moving away from the source of the smell.\n",
       "3. **If you feel a breeze**, it indicates a pit nearby, so choose a different direction.\n",
       "4. **If you sense gold** in your current square, you can pick it up if it is present.\n",
       "5. **If you have arrows left**, you may want to shoot the Wumpus if you believe you are in a position to do so safely.\n",
       "\n",
       "If you provide me with specifics about your current surroundings, I can suggest a more targeted action!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a Wumpus World agent.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the best action to take?\"},\n",
    "    ],\n",
    "    max_completion_tokens = 300\n",
    ")\n",
    "\n",
    "display(Markdown(completion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without information about the environment, the model will not be able to generate an appropriate response. We need to provide the model with the information it needs to make a decision. We can do this by providing the model the following information:\n",
    "\n",
    "* The definition of the wumpus world environment. (System prompt)\n",
    "    ** You can use the definition from the introduction for this!\n",
    "* The previous actions the agent has taken. (Prompt)\n",
    "* The previous sensor information the agent has received. (Prompt)\n",
    "* The sensor information the agent receives. (Prompt)\n",
    "* The possible actions the agent can take. (Prompt)\n",
    "* Whether the agent has the gold. (Prompt)\n",
    "\n",
    "Given this information, the agent should know everything it needs about the environment, context, tools, and goals to make a decision. Here is a sample prompt that you can use to generate a response from the model:\n",
    "\n",
    "```\n",
    "I have already taken these actions with these sensor readings:\n",
    "    - {sensor} -> {action}\n",
    "\n",
    "I sense: {sensors}\n",
    "I have the gold: {self.has_gold}\n",
    "\n",
    "Explore cells until you find the gold.\n",
    "Do not climb out without the gold, unless you have explored all cells.\n",
    "Do not grab unless you sense glitter.\n",
    "Don't repeatedly move in the same direction if you bump into a wall.\n",
    "Once you sense a breeze or stench, avoid moving to unknown cells.\n",
    "\n",
    "What is the best action to take?\n",
    "\n",
    "Respond ONLY with one of these actions: Up, Down, Left, Right, Grab, Climb\n",
    "```\n",
    "\n",
    "In the next cell, define the `_select_action` method for the `GenerativeAgent` class. This method should generate a response from the OpenAI API using the prompt defined above and return the action generated by the model.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Note:** Our Wumpus World is a little different from the standard definition. Even if it seems like the model already know the game, it's important to provide our model with the correct information.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "class AIAgent(Agent):\n",
    "    \"\"\"Wumpus World agent that uses Generative AI to act\"\"\"\n",
    "    def _select_action(self, sensors):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "# [ SOLUTION ]\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "The Wumpus World is a cave consisting of rooms connected by passageways. The rooms are arranged in a 4x4 grid. In the cave is a **Wumpus** that eats any agents which enter the room. The agent can feel a **stench** in the room if the Wumpus is in a neighboring room.\n",
    "\n",
    "The cave also contains **pits**. If an agent enters a room with a pit, it falls in and dies. The agent can feel a **breeze** in the room if there is a pit in a neighboring room. The agent has a **gold** detector that beeps when the agent is in a room containing gold. The agent can pick up the gold and leave the cave. The agent can also climb out of the cave without the gold.\n",
    "\n",
    "### Environment\n",
    "4x4 grid with the agent starting in the bottom-left corner. The Wumpus, pits, and gold are placed randomly in the other rooms.\n",
    "\n",
    "### Actions\n",
    "- `Up`: Move up one room.\n",
    "- `Down`: Move down one room.\n",
    "- `Left`: Move left one room.\n",
    "- `Right`: Move right one room.\n",
    "- `Grab`: Grab the gold, if it is in the room.\n",
    "- `Climb`: Climb out of the cave, from the starting room.\n",
    "\n",
    "### Sensors\n",
    "* `Stench`: Detects a stench in adjacent rooms (not diagonally).\n",
    "* `Breeze`: Detects a breeze in adjacent rooms (not diagonally).\n",
    "* `Glitter`: Detects gold in the current room.\n",
    "* `Ladder`: Detects the ladder in the starting room.\n",
    "* `Bump`: Detects when the agent tries to move forward into a wall.\n",
    "\"\"\"\n",
    "\n",
    "class AIAgent(Agent):\n",
    "    \"\"\"Wumpus World agent that uses Generative AI to act\"\"\"\n",
    "    def _select_action(self, sensors):\n",
    "        readings = \"\\n\".join(f\"- {sensor} -> {action.value}\" for sensor, action in zip(self.sensors, self.actions))\n",
    "        prompt = f\"\"\"\n",
    "I have already taken these actions with these sensor readings:\n",
    "{readings}\n",
    "\n",
    "I sense: {sensors}\n",
    "I have the gold: {self.has_gold}\n",
    "\n",
    "Explore unvisited cells until you find the gold, then leave.\n",
    "Do not climb out without the gold, unless you have explored all cells.\n",
    "Do not grab unless you sense glitter.\n",
    "If you bump, try moving in a different direction.\n",
    "In cells with stench or breeze, be cautious and avoid visiting unknown cells.\n",
    "\n",
    "What is the best action to take?\n",
    "\n",
    "Respond ONLY with one of these actions: Up, Down, Left, Right, Grab, Climb\n",
    "\"\"\"\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a Wumpus World agent.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            max_completion_tokens = 2\n",
    "        )\n",
    "\n",
    "        action = completion.choices[0].message.content\n",
    "        return Actions(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a generative AI agent, let's test it in the Wumpus World environment. Run the cell below to test the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ä¢ P ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "W ‚Ä¢ G ‚Ä¢ \n",
      "A ‚Ä¢ P ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': True, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "Actions.MOVE_DOWN\n",
      "‚Ä¢ P ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "W ‚Ä¢ G ‚Ä¢ \n",
      "A ‚Ä¢ P ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': True, 'breeze': False, 'glitter': False, 'ladder': True, 'bump': True}\n",
      "moves=1, game_over=False\n",
      "Actions.MOVE_LEFT\n",
      "‚Ä¢ P ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "W ‚Ä¢ G ‚Ä¢ \n",
      "A ‚Ä¢ P ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': True, 'breeze': False, 'glitter': False, 'ladder': True, 'bump': True}\n",
      "moves=2, game_over=False\n",
      "Actions.MOVE_RIGHT\n",
      "‚Ä¢ P ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "W ‚Ä¢ G ‚Ä¢ \n",
      "L A P ‚Ä¢ \n",
      "{'position': (1, 3), 'stench': False, 'breeze': True, 'glitter': False, 'ladder': False, 'bump': False}\n",
      "moves=3, game_over=False\n",
      "Actions.MOVE_UP\n",
      "‚Ä¢ P ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "W A G ‚Ä¢ \n",
      "L ‚Ä¢ P ‚Ä¢ \n",
      "{'position': (1, 2), 'stench': True, 'breeze': False, 'glitter': False, 'ladder': False, 'bump': False}\n",
      "moves=4, game_over=False\n",
      "Actions.MOVE_DOWN\n",
      "‚Ä¢ P ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "W ‚Ä¢ G ‚Ä¢ \n",
      "L A P ‚Ä¢ \n",
      "{'position': (1, 3), 'stench': False, 'breeze': True, 'glitter': False, 'ladder': False, 'bump': False}\n",
      "moves=5, game_over=False\n",
      "Actions.MOVE_DOWN\n",
      "‚Ä¢ P ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "W ‚Ä¢ G ‚Ä¢ \n",
      "L A P ‚Ä¢ \n",
      "{'position': (1, 3), 'stench': False, 'breeze': True, 'glitter': False, 'ladder': False, 'bump': True}\n",
      "moves=6, game_over=False\n",
      "Actions.MOVE_RIGHT\n",
      "-1007\n",
      "Agent lost!\n"
     ]
    }
   ],
   "source": [
    "world = WumpusWorld()\n",
    "agent = AIAgent()\n",
    "\n",
    "while not world.game_over:\n",
    "    print(world)\n",
    "    action = agent.act(world.sensors)\n",
    "    print(action)\n",
    "    world.act(action)\n",
    "\n",
    "print(world.score())\n",
    "print(f'Agent {\"won\" if world.is_win() else \"lost\"}!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your Agent isn't behaving as expected, you may need to adjust the prompts you are sending to the model. Make sure to explicitly define what you want the model to do in the prompt and how the output should be structured.\n",
    "\n",
    "The AI agent may not win. Sometimes a pit or the Wumpus is placed in a way that the agent cannot avoid it. However, the AI agent should have a higher average score and win rate than the random agent.\n",
    "\n",
    "\n",
    "In the next cell, write code to run **25** games with the generative AI agent and calculate the average score. You can also calculate the win rate of the generative AI agent by using `world.is_win()`.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**Warning!** It's important that you only run 25 games with the generative AI agent. Running more games may take a long time and consume a lot of resources.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/25 - 0 wins\n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "P G ‚Ä¢ ‚Ä¢ \n",
      "W ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ P ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': True, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_LEFT\n",
      "Episode 2/25 - 0 wins\n",
      "W ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "P P ‚Ä¢ ‚Ä¢ \n",
      "A G ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': True, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "Episode 3/25 - 0 wins\n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ W ‚Ä¢ P \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ P \n",
      "A ‚Ä¢ G ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.GRAB\n",
      "\t Actions.CLIMB\n",
      "\t Actions.CLIMB\n",
      "\t Actions.CLIMB\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "Episode 4/25 - 0 wins\n",
      "‚Ä¢ P ‚Ä¢ ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ W ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ P ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "Episode 5/25 - 0 wins\n",
      "‚Ä¢ P ‚Ä¢ P \n",
      "‚Ä¢ W G ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "Episode 6/25 - 0 wins\n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ P \n",
      "P ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ G ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ W \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_RIGHT\n",
      "Episode 7/25 - 0 wins\n",
      "P ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ G \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ P \n",
      "A W ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': True, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_RIGHT\n",
      "Episode 8/25 - 0 wins\n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "P ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "G W ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ P ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_RIGHT\n",
      "Episode 9/25 - 0 wins\n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "W ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ P P ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "Episode 10/25 - 0 wins\n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P G \n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "Episode 11/25 - 0 wins\n",
      "‚Ä¢ ‚Ä¢ W G \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ P \n",
      "‚Ä¢ P ‚Ä¢ ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_RIGHT\n",
      "Episode 12/25 - 0 wins\n",
      "W ‚Ä¢ P ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ G ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A P ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': True, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "Episode 13/25 - 0 wins\n",
      "‚Ä¢ P ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ G P \n",
      "A ‚Ä¢ W ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "Episode 14/25 - 0 wins\n",
      "P ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ G P \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ W \n",
      "A ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_RIGHT\n",
      "Episode 15/25 - 0 wins\n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ G \n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_RIGHT\n",
      "Episode 16/25 - 0 wins\n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ G \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "Episode 17/25 - 0 wins\n",
      "‚Ä¢ ‚Ä¢ P ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "P ‚Ä¢ ‚Ä¢ G \n",
      "A ‚Ä¢ ‚Ä¢ W \n",
      "{'position': (0, 3), 'stench': False, 'breeze': True, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "Episode 18/25 - 0 wins\n",
      "W ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "P ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ P G \n",
      "A ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_UP\n",
      "Episode 19/25 - 0 wins\n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ P ‚Ä¢ W \n",
      "A P ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': True, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "Episode 20/25 - 0 wins\n",
      "‚Ä¢ G ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ W P \n",
      "A ‚Ä¢ P ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "Episode 21/25 - 0 wins\n",
      "P ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "G ‚Ä¢ W ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "A P ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': True, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "Episode 22/25 - 0 wins\n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ G ‚Ä¢ \n",
      "‚Ä¢ W ‚Ä¢ P \n",
      "A ‚Ä¢ ‚Ä¢ P \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_RIGHT\n",
      "Episode 23/25 - 0 wins\n",
      "‚Ä¢ ‚Ä¢ W P \n",
      "G ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ P \n",
      "A ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "Episode 24/25 - 0 wins\n",
      "‚Ä¢ W ‚Ä¢ ‚Ä¢ \n",
      "G ‚Ä¢ ‚Ä¢ P \n",
      "‚Ä¢ ‚Ä¢ ‚Ä¢ P \n",
      "A ‚Ä¢ ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': False, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_RIGHT\n",
      "\t Actions.MOVE_UP\n",
      "Episode 25/25 - 0 wins\n",
      "‚Ä¢ P ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ P ‚Ä¢ ‚Ä¢ \n",
      "‚Ä¢ ‚Ä¢ G ‚Ä¢ \n",
      "A W ‚Ä¢ ‚Ä¢ \n",
      "{'position': (0, 3), 'stench': True, 'breeze': False, 'glitter': False, 'ladder': True}\n",
      "moves=0, game_over=False\n",
      "\t Actions.MOVE_LEFT\n",
      "\t Actions.MOVE_DOWN\n",
      "\t Actions.MOVE_RIGHT\n",
      "Average score: -771.12\n",
      "Wins: 0\n",
      "Win rate: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# [ SOLUTION ]\n",
    "\n",
    "MAX_EPISODES = 25  # Don;t change the value here\n",
    "\n",
    "agent = AIAgent()\n",
    "world = WumpusWorld()\n",
    "\n",
    "score = 0\n",
    "wins = 0\n",
    "\n",
    "for episode in range(MAX_EPISODES):\n",
    "    print(f'Episode {episode + 1}/{MAX_EPISODES} - {wins} wins')\n",
    "    agent.reset()\n",
    "    world.reset()\n",
    "    print(world)\n",
    "\n",
    "    while not world.game_over:\n",
    "        try:\n",
    "            action = agent.act(world.sensors)\n",
    "        except:\n",
    "            print('Invalid action.')\n",
    "            break\n",
    "        print('\\t', action)\n",
    "        world.act(action)\n",
    "\n",
    "    score += world.score()\n",
    "    if world.is_win(): wins += 1\n",
    "\n",
    "print(f'Average score: {score / MAX_EPISODES}')\n",
    "print(f'Wins: {wins}')\n",
    "print(f'Win rate: {wins / MAX_EPISODES:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average score of the AI Agent should be higher than the random agent. The win rate should also be higher. Since we have only run 25 games, it's possible that the agent does score lower than the random agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge 1\n",
    "You may have noticed that the AI Agent doesn't always behave optimally. Sometimes it will take actions that are repetitive or don't make sense. In our previous prompt, we provided the model with a list of actions and sensor readings that the agent has already taken.\n",
    "\n",
    "However, this may not be the best way to provide the model with the information it needs to make a decision. Because we know the structure of the Wumpus World environment, we can synthesize this information into a map of the environment. The map might look something like this:\n",
    "\n",
    "```\n",
    "|---------------|\n",
    "| A | B | ? | ? |\n",
    "| E | B | ? | ? |\n",
    "| E | E | ? | ? |\n",
    "| L | S | ? | ? |\n",
    "|---------------|\n",
    "```\n",
    "\n",
    "When providing the model with the map, we are compressing the information about the environment into a more information-dense representation. This should help the model make better decisions because it does not need to infer the state of the environment from the previous actions and sensor readings.\n",
    "\n",
    "### Step 1 - Define the Map\n",
    "In the next cell, create a class called `Map` that will represent the map of the Wumpus World environment. The map should have the following methods:\n",
    "\n",
    "* `__init__(self, size=4)`: Initializes the map with the given size.\n",
    "* `update(self, x, y, sensors)`: Updates the map with the sensor information at the given position.\n",
    "* `__str__(self)`: Returns a string representation of the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Create a New Agent\n",
    "In the next cell, create a new agent called `MapAgent` that uses the map to make decisions. You can begin with the `AIAgent` and modify your prompt to use the map.\n",
    "\n",
    "Take away any information which is now redundant because it is represented in the map. For example, you no longer need to provide the model with the previous actions and sensor readings.\n",
    "\n",
    "If you use symbols to represent the environment, make sure to include a legend in your prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Test the Agent\n",
    "Now that you have the agent, test it in the Wumpus World environment. Run the agent 25 times and calculate the average score and win rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
