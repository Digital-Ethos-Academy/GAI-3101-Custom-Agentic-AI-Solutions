{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph: Zero to Hero Guide\n",
    "\n",
    "## Building Stateful, Multi-Step AI Agent Workflows\n",
    "\n",
    "**Objective:** This comprehensive notebook takes you from beginner to advanced LangGraph user. Learn how to build complex, stateful agent workflows with nodes, edges, conditional routing, and human-in-the-loop interactions.\n",
    "\n",
    "**Target Audience:** Software engineers from complete beginners to experts looking to master LangGraph.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction & Core Philosophy](#1-introduction--core-philosophy)\n",
    "2. [Prerequisites & Setup](#2-prerequisites--setup)\n",
    "3. [Core Concepts: Graphs, Nodes & Edges](#3-core-concepts-graphs-nodes--edges)\n",
    "4. [Your First Graph](#4-your-first-graph)\n",
    "5. [State Management](#5-state-management)\n",
    "6. [Conditional Routing](#6-conditional-routing)\n",
    "7. [Tool Integration](#7-tool-integration)\n",
    "8. [Checkpointing & Persistence](#8-checkpointing--persistence)\n",
    "9. [Human-in-the-Loop](#9-human-in-the-loop)\n",
    "10. [Subgraphs & Composition](#10-subgraphs--composition)\n",
    "11. [Multi-Agent Patterns](#11-multi-agent-patterns)\n",
    "12. [Best Practices & Common Pitfalls](#12-best-practices--common-pitfalls)\n",
    "13. [Conclusion & Next Steps](#13-conclusion--next-steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction & Core Philosophy\n",
    "\n",
    "### What is LangGraph?\n",
    "\n",
    "**LangGraph** is a library for building stateful, multi-actor applications with LLMs. It extends LangChain with:\n",
    "\n",
    "- **Graph-based workflows**: Model complex logic as nodes and edges\n",
    "- **State management**: Automatic state tracking across nodes\n",
    "- **Cycles**: Support for loops and iterative refinement\n",
    "- **Persistence**: Built-in checkpointing for long-running workflows\n",
    "\n",
    "### Core Philosophy\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                LangGraph Philosophy                             ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îÇ   \"Control + Flexibility\"                                      ‚îÇ\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îÇ   ‚Ä¢ Explicit control flow (unlike autonomous agents)           ‚îÇ\n",
    "‚îÇ   ‚Ä¢ Stateful by design                                         ‚îÇ\n",
    "‚îÇ   ‚Ä¢ Cyclic graphs for iteration                                ‚îÇ\n",
    "‚îÇ   ‚Ä¢ Human-in-the-loop support                                  ‚îÇ\n",
    "‚îÇ   ‚Ä¢ Streaming & persistence built-in                           ‚îÇ\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### When to Use LangGraph?\n",
    "\n",
    "‚úÖ **Good for:**\n",
    "- Complex multi-step workflows\n",
    "- Agents that need explicit control flow\n",
    "- Human-in-the-loop approval systems\n",
    "- Long-running tasks with checkpointing\n",
    "- Multi-agent orchestration\n",
    "\n",
    "‚ùå **Consider alternatives when:**\n",
    "- Simple single-shot tasks (use LangChain)\n",
    "- Autonomous multi-agent debates (use AutoGen)\n",
    "- Role-based agent teams (use CrewAI)\n",
    "\n",
    "### LangGraph vs Other Frameworks\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ              Agent Framework Comparison                    ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ LangGraph      ‚îÇ State machines, explicit control flow    ‚îÇ\n",
    "‚îÇ LangChain      ‚îÇ Single agent, tool calling               ‚îÇ\n",
    "‚îÇ AutoGen        ‚îÇ Multi-agent conversations                ‚îÇ\n",
    "‚îÇ CrewAI         ‚îÇ Role-playing agent crews                 ‚îÇ\n",
    "‚îÇ SmolAgents     ‚îÇ Minimal, code-first agents               ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Prerequisites & Setup\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- **Python 3.9+**\n",
    "- **OpenAI API Key**\n",
    "- **Tavily API Key** (optional, for search examples)\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "pip install langgraph langchain-openai langchain-community\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment to run)\n",
    "# !pip install langgraph langchain-openai langchain-community python-dotenv tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API keys\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "print(\"üîë API KEY STATUS\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"OpenAI API Key: {'‚úÖ Found' if openai_key else '‚ùå Missing'}\")\n",
    "print(f\"Tavily API Key: {'‚úÖ Found' if tavily_key else '‚ö†Ô∏è Optional'}\")\n",
    "\n",
    "if not openai_key:\n",
    "    print(\"\\n‚ùå Please add OPENAI_API_KEY to your .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Core Concepts: Graphs, Nodes & Edges\n",
    "\n",
    "LangGraph models workflows as directed graphs:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                    LangGraph Concepts                           ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îÇ   NODES: Functions that transform state                        ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ\n",
    "‚îÇ   ‚îÇ  Node   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Node   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Node   ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îÇ   A     ‚îÇ    ‚îÇ   B     ‚îÇ    ‚îÇ   C     ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îÇ   EDGES: Connections between nodes                             ‚îÇ\n",
    "‚îÇ   - Normal edges: Always follow                                ‚îÇ\n",
    "‚îÇ   - Conditional edges: Route based on state                    ‚îÇ\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îÇ   STATE: Shared data passed between nodes                      ‚îÇ\n",
    "‚îÇ   - Defined as TypedDict or Pydantic model                     ‚îÇ\n",
    "‚îÇ   - Each node can read and update state                        ‚îÇ\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îÇ   SPECIAL NODES:                                               ‚îÇ\n",
    "‚îÇ   - START: Entry point                                         ‚îÇ\n",
    "‚îÇ   - END: Exit point(s)                                         ‚îÇ\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### Key Terms\n",
    "\n",
    "| Term | Description |\n",
    "|------|-------------|\n",
    "| **StateGraph** | The graph builder class |\n",
    "| **Node** | A function that processes state |\n",
    "| **Edge** | A connection between nodes |\n",
    "| **Conditional Edge** | Routes based on state values |\n",
    "| **Checkpoint** | Saved state for resumption |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Your First Graph\n",
    "\n",
    "Let's build a simple sequential graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Step 1: Define the state schema\n",
    "class SimpleState(TypedDict):\n",
    "    \"\"\"State for our simple graph.\"\"\"\n",
    "    messages: list[str]  # List of messages\n",
    "    counter: int         # A simple counter\n",
    "\n",
    "print(\"‚úÖ State schema defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define node functions\n",
    "# Each node receives state and returns updates\n",
    "\n",
    "def node_a(state: SimpleState) -> dict:\n",
    "    \"\"\"First node: Initialize and greet.\"\"\"\n",
    "    print(\"üîµ Node A executing...\")\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [\"Hello from Node A!\"],\n",
    "        \"counter\": state[\"counter\"] + 1\n",
    "    }\n",
    "\n",
    "def node_b(state: SimpleState) -> dict:\n",
    "    \"\"\"Second node: Process and add message.\"\"\"\n",
    "    print(\"üü¢ Node B executing...\")\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [\"Processed by Node B!\"],\n",
    "        \"counter\": state[\"counter\"] + 1\n",
    "    }\n",
    "\n",
    "def node_c(state: SimpleState) -> dict:\n",
    "    \"\"\"Third node: Finalize.\"\"\"\n",
    "    print(\"üî¥ Node C executing...\")\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [f\"Completed! Total steps: {state['counter'] + 1}\"],\n",
    "        \"counter\": state[\"counter\"] + 1\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Node functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build the graph\n",
    "\n",
    "# Create a new graph with our state schema\n",
    "builder = StateGraph(SimpleState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"node_a\", node_a)\n",
    "builder.add_node(\"node_b\", node_b)\n",
    "builder.add_node(\"node_c\", node_c)\n",
    "\n",
    "# Add edges (define the flow)\n",
    "builder.add_edge(START, \"node_a\")  # Start -> A\n",
    "builder.add_edge(\"node_a\", \"node_b\")  # A -> B\n",
    "builder.add_edge(\"node_b\", \"node_c\")  # B -> C\n",
    "builder.add_edge(\"node_c\", END)  # C -> End\n",
    "\n",
    "# Compile the graph\n",
    "simple_graph = builder.compile()\n",
    "\n",
    "print(\"‚úÖ Graph compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Run the graph\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ RUNNING GRAPH\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Initial state\n",
    "initial_state = {\n",
    "    \"messages\": [\"Starting workflow...\"],\n",
    "    \"counter\": 0\n",
    "}\n",
    "\n",
    "# Invoke the graph\n",
    "result = simple_graph.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã FINAL STATE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Messages: {result['messages']}\")\n",
    "print(f\"Counter: {result['counter']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Key Takeaways\n",
    "\n",
    "1. **State** is defined as a TypedDict\n",
    "2. **Nodes** are functions that transform state\n",
    "3. **Edges** connect nodes in sequence\n",
    "4. **START/END** are special nodes\n",
    "5. **compile()** creates the runnable graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. State Management\n",
    "\n",
    "LangGraph provides powerful state management with reducers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from operator import add\n",
    "\n",
    "# State with a reducer (accumulates messages)\n",
    "class AccumulatingState(TypedDict):\n",
    "    \"\"\"State that accumulates messages using a reducer.\"\"\"\n",
    "    # Annotated with 'add' means new messages are appended, not replaced\n",
    "    messages: Annotated[list[str], add]\n",
    "    current_step: str\n",
    "\n",
    "print(\"‚úÖ State with reducer defined!\")\n",
    "print(\"   Using 'add' reducer: messages will accumulate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes for accumulating state\n",
    "\n",
    "def step_1(state: AccumulatingState) -> dict:\n",
    "    return {\n",
    "        \"messages\": [\"Step 1 completed\"],\n",
    "        \"current_step\": \"step_1\"\n",
    "    }\n",
    "\n",
    "def step_2(state: AccumulatingState) -> dict:\n",
    "    return {\n",
    "        \"messages\": [\"Step 2 completed\"],\n",
    "        \"current_step\": \"step_2\"\n",
    "    }\n",
    "\n",
    "def step_3(state: AccumulatingState) -> dict:\n",
    "    return {\n",
    "        \"messages\": [\"Step 3 completed\"],\n",
    "        \"current_step\": \"step_3\"\n",
    "    }\n",
    "\n",
    "# Build graph\n",
    "accum_builder = StateGraph(AccumulatingState)\n",
    "accum_builder.add_node(\"step_1\", step_1)\n",
    "accum_builder.add_node(\"step_2\", step_2)\n",
    "accum_builder.add_node(\"step_3\", step_3)\n",
    "accum_builder.add_edge(START, \"step_1\")\n",
    "accum_builder.add_edge(\"step_1\", \"step_2\")\n",
    "accum_builder.add_edge(\"step_2\", \"step_3\")\n",
    "accum_builder.add_edge(\"step_3\", END)\n",
    "\n",
    "accum_graph = accum_builder.compile()\n",
    "\n",
    "print(\"‚úÖ Accumulating graph compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and see accumulation\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ RUNNING WITH REDUCER\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "result = accum_graph.invoke({\n",
    "    \"messages\": [\"Starting...\"],\n",
    "    \"current_step\": \"init\"\n",
    "})\n",
    "\n",
    "print(\"üìã Messages accumulated:\")\n",
    "for i, msg in enumerate(result[\"messages\"]):\n",
    "    print(f\"  {i+1}. {msg}\")\n",
    "print(f\"\\nFinal step: {result['current_step']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Conditional Routing\n",
    "\n",
    "The real power of LangGraph: dynamic routing based on state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State for conditional routing\n",
    "class RouterState(TypedDict):\n",
    "    query: str\n",
    "    category: str\n",
    "    response: str\n",
    "\n",
    "# Classifier node\n",
    "def classify_query(state: RouterState) -> dict:\n",
    "    \"\"\"Classify the query into a category.\"\"\"\n",
    "    query = state[\"query\"].lower()\n",
    "    \n",
    "    if any(word in query for word in [\"weather\", \"temperature\", \"rain\"]):\n",
    "        category = \"weather\"\n",
    "    elif any(word in query for word in [\"calculate\", \"math\", \"sum\", \"multiply\"]):\n",
    "        category = \"math\"\n",
    "    else:\n",
    "        category = \"general\"\n",
    "    \n",
    "    print(f\"üè∑Ô∏è Classified as: {category}\")\n",
    "    return {\"category\": category}\n",
    "\n",
    "# Handler nodes\n",
    "def handle_weather(state: RouterState) -> dict:\n",
    "    print(\"üå§Ô∏è Weather handler\")\n",
    "    return {\"response\": f\"Weather response for: {state['query']}\"}\n",
    "\n",
    "def handle_math(state: RouterState) -> dict:\n",
    "    print(\"üßÆ Math handler\")\n",
    "    return {\"response\": f\"Math response for: {state['query']}\"}\n",
    "\n",
    "def handle_general(state: RouterState) -> dict:\n",
    "    print(\"üí¨ General handler\")\n",
    "    return {\"response\": f\"General response for: {state['query']}\"}\n",
    "\n",
    "print(\"‚úÖ Nodes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing function\n",
    "def route_query(state: RouterState) -> str:\n",
    "    \"\"\"Route to the appropriate handler based on category.\"\"\"\n",
    "    category = state[\"category\"]\n",
    "    if category == \"weather\":\n",
    "        return \"handle_weather\"\n",
    "    elif category == \"math\":\n",
    "        return \"handle_math\"\n",
    "    else:\n",
    "        return \"handle_general\"\n",
    "\n",
    "# Build conditional graph\n",
    "router_builder = StateGraph(RouterState)\n",
    "\n",
    "# Add nodes\n",
    "router_builder.add_node(\"classify\", classify_query)\n",
    "router_builder.add_node(\"handle_weather\", handle_weather)\n",
    "router_builder.add_node(\"handle_math\", handle_math)\n",
    "router_builder.add_node(\"handle_general\", handle_general)\n",
    "\n",
    "# Add edges\n",
    "router_builder.add_edge(START, \"classify\")\n",
    "\n",
    "# Add CONDITIONAL edge from classify\n",
    "router_builder.add_conditional_edges(\n",
    "    \"classify\",  # Source node\n",
    "    route_query,  # Routing function\n",
    "    {  # Mapping: route_query return -> node name\n",
    "        \"handle_weather\": \"handle_weather\",\n",
    "        \"handle_math\": \"handle_math\",\n",
    "        \"handle_general\": \"handle_general\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# All handlers go to END\n",
    "router_builder.add_edge(\"handle_weather\", END)\n",
    "router_builder.add_edge(\"handle_math\", END)\n",
    "router_builder.add_edge(\"handle_general\", END)\n",
    "\n",
    "router_graph = router_builder.compile()\n",
    "\n",
    "print(\"‚úÖ Conditional router graph compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the router with different queries\n",
    "\n",
    "test_queries = [\n",
    "    \"What's the weather in Paris?\",\n",
    "    \"Calculate 15 times 8\",\n",
    "    \"Tell me about AI agents\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"üìù Query: {query}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = router_graph.invoke({\n",
    "        \"query\": query,\n",
    "        \"category\": \"\",\n",
    "        \"response\": \"\"\n",
    "    })\n",
    "    \n",
    "    print(f\"üìã Response: {result['response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Tool Integration\n",
    "\n",
    "LangGraph works seamlessly with LangChain tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city.\"\"\"\n",
    "    weather_data = {\n",
    "        \"paris\": \"Cloudy, 18¬∞C\",\n",
    "        \"london\": \"Rainy, 12¬∞C\",\n",
    "        \"tokyo\": \"Sunny, 22¬∞C\",\n",
    "    }\n",
    "    return weather_data.get(city.lower(), f\"Unknown weather for {city}\")\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Calculate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"Result: {result}\"\n",
    "    except:\n",
    "        return \"Error in calculation\"\n",
    "\n",
    "tools = [get_weather, calculate]\n",
    "\n",
    "print(\"‚úÖ Tools defined!\")\n",
    "print(f\"   Available: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# State for tool-using agent\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Initialize LLM with tools\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Agent node: calls LLM\n",
    "def agent_node(state: AgentState) -> dict:\n",
    "    \"\"\"Call the LLM to decide what to do.\"\"\"\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Tool node: executes tools\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "print(\"‚úÖ Agent and tool nodes ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router function: continue with tools or end?\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Decide whether to continue with tools or end.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # If there are tool calls, route to tools\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, end\n",
    "    return \"end\"\n",
    "\n",
    "# Build the agent graph\n",
    "agent_builder = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"agent\", agent_node)\n",
    "agent_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Add edges\n",
    "agent_builder.add_edge(START, \"agent\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"end\": END}\n",
    ")\n",
    "agent_builder.add_edge(\"tools\", \"agent\")  # After tools, back to agent\n",
    "\n",
    "agent_graph = agent_builder.compile()\n",
    "\n",
    "print(\"‚úÖ Tool-using agent graph compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ TESTING TOOL-USING AGENT\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "result = agent_graph.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What's the weather in Tokyo? Also, calculate 25 * 4\")]\n",
    "})\n",
    "\n",
    "print(\"üìã CONVERSATION:\")\n",
    "for msg in result[\"messages\"]:\n",
    "    if isinstance(msg, HumanMessage):\n",
    "        print(f\"\\nüë§ Human: {msg.content}\")\n",
    "    elif isinstance(msg, AIMessage):\n",
    "        if msg.content:\n",
    "            print(f\"\\nü§ñ AI: {msg.content}\")\n",
    "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "            print(f\"   üîß Tool calls: {[tc['name'] for tc in msg.tool_calls]}\")\n",
    "    elif isinstance(msg, ToolMessage):\n",
    "        print(f\"   üì¶ Tool result: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Checkpointing & Persistence\n",
    "\n",
    "LangGraph can save state for long-running workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Create a memory checkpointer\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Recompile agent with checkpointing\n",
    "persistent_agent = agent_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"‚úÖ Agent with checkpointing ready!\")\n",
    "print(\"   State will be saved between invocations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First conversation turn\n",
    "config = {\"configurable\": {\"thread_id\": \"conversation_1\"}}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí¨ TURN 1\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "result1 = persistent_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What's the weather in Paris?\")]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Get the AI response\n",
    "ai_response = [m for m in result1[\"messages\"] if isinstance(m, AIMessage) and m.content]\n",
    "if ai_response:\n",
    "    print(f\"ü§ñ AI: {ai_response[-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second conversation turn - uses same thread_id\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí¨ TURN 2 (continues conversation)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "result2 = persistent_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"How about London?\")]},\n",
    "    config=config  # Same thread_id\n",
    ")\n",
    "\n",
    "ai_response = [m for m in result2[\"messages\"] if isinstance(m, AIMessage) and m.content]\n",
    "if ai_response:\n",
    "    print(f\"ü§ñ AI: {ai_response[-1].content}\")\n",
    "\n",
    "print(f\"\\nüìä Total messages in thread: {len(result2['messages'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Human-in-the-Loop\n",
    "\n",
    "LangGraph supports interrupting for human approval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State for approval workflow\n",
    "class ApprovalState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    approved: bool\n",
    "    result: str\n",
    "\n",
    "def create_plan(state: ApprovalState) -> dict:\n",
    "    \"\"\"Create a plan for the task.\"\"\"\n",
    "    print(\"üìù Creating plan...\")\n",
    "    plan = f\"Plan for '{state['task']}': Step 1, Step 2, Step 3\"\n",
    "    return {\"plan\": plan}\n",
    "\n",
    "def execute_plan(state: ApprovalState) -> dict:\n",
    "    \"\"\"Execute the approved plan.\"\"\"\n",
    "    print(\"‚ö° Executing plan...\")\n",
    "    return {\"result\": f\"Successfully executed: {state['plan']}\"}\n",
    "\n",
    "def check_approval(state: ApprovalState) -> str:\n",
    "    \"\"\"Check if plan is approved.\"\"\"\n",
    "    if state.get(\"approved\"):\n",
    "        return \"execute\"\n",
    "    return \"wait_for_approval\"\n",
    "\n",
    "print(\"‚úÖ Approval workflow nodes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build approval workflow\n",
    "approval_builder = StateGraph(ApprovalState)\n",
    "\n",
    "approval_builder.add_node(\"create_plan\", create_plan)\n",
    "approval_builder.add_node(\"execute\", execute_plan)\n",
    "\n",
    "approval_builder.add_edge(START, \"create_plan\")\n",
    "approval_builder.add_conditional_edges(\n",
    "    \"create_plan\",\n",
    "    check_approval,\n",
    "    {\n",
    "        \"execute\": \"execute\",\n",
    "        \"wait_for_approval\": END  # Stops here for approval\n",
    "    }\n",
    ")\n",
    "approval_builder.add_edge(\"execute\", END)\n",
    "\n",
    "# Compile with checkpointer for state persistence\n",
    "approval_checkpointer = MemorySaver()\n",
    "approval_graph = approval_builder.compile(checkpointer=approval_checkpointer)\n",
    "\n",
    "print(\"‚úÖ Approval workflow compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Start workflow (will stop at approval)\n",
    "approval_config = {\"configurable\": {\"thread_id\": \"approval_1\"}}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ STEP 1: CREATE PLAN\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "result = approval_graph.invoke(\n",
    "    {\"task\": \"Deploy new feature\", \"approved\": False, \"plan\": \"\", \"result\": \"\"},\n",
    "    config=approval_config\n",
    ")\n",
    "\n",
    "print(f\"üìã Plan created: {result['plan']}\")\n",
    "print(\"\\n‚è∏Ô∏è Workflow paused - waiting for human approval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Resume with approval\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ STEP 2: APPROVE AND CONTINUE\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Update state with approval\n",
    "approved_state = {**result, \"approved\": True}\n",
    "\n",
    "# Create new graph execution with approval\n",
    "final_result = approval_graph.invoke(\n",
    "    approved_state,\n",
    "    config={\"configurable\": {\"thread_id\": \"approval_2\"}}\n",
    ")\n",
    "\n",
    "print(f\"üìã Result: {final_result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Subgraphs & Composition\n",
    "\n",
    "Build complex workflows by composing smaller graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subgraph states\n",
    "class ResearchState(TypedDict):\n",
    "    topic: str\n",
    "    findings: str\n",
    "\n",
    "class WritingState(TypedDict):\n",
    "    content: str\n",
    "    draft: str\n",
    "\n",
    "# Research subgraph\n",
    "def research_node(state: ResearchState) -> dict:\n",
    "    print(f\"üîç Researching: {state['topic']}\")\n",
    "    return {\"findings\": f\"Research findings on {state['topic']}\"}\n",
    "\n",
    "research_builder = StateGraph(ResearchState)\n",
    "research_builder.add_node(\"research\", research_node)\n",
    "research_builder.add_edge(START, \"research\")\n",
    "research_builder.add_edge(\"research\", END)\n",
    "research_subgraph = research_builder.compile()\n",
    "\n",
    "# Writing subgraph\n",
    "def writing_node(state: WritingState) -> dict:\n",
    "    print(f\"‚úçÔ∏è Writing about: {state['content']}\")\n",
    "    return {\"draft\": f\"Draft based on {state['content']}\"}\n",
    "\n",
    "writing_builder = StateGraph(WritingState)\n",
    "writing_builder.add_node(\"write\", writing_node)\n",
    "writing_builder.add_edge(START, \"write\")\n",
    "writing_builder.add_edge(\"write\", END)\n",
    "writing_subgraph = writing_builder.compile()\n",
    "\n",
    "print(\"‚úÖ Subgraphs defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main graph that uses subgraphs\n",
    "class MainState(TypedDict):\n",
    "    topic: str\n",
    "    findings: str\n",
    "    draft: str\n",
    "\n",
    "def do_research(state: MainState) -> dict:\n",
    "    result = research_subgraph.invoke({\"topic\": state[\"topic\"], \"findings\": \"\"})\n",
    "    return {\"findings\": result[\"findings\"]}\n",
    "\n",
    "def do_writing(state: MainState) -> dict:\n",
    "    result = writing_subgraph.invoke({\"content\": state[\"findings\"], \"draft\": \"\"})\n",
    "    return {\"draft\": result[\"draft\"]}\n",
    "\n",
    "main_builder = StateGraph(MainState)\n",
    "main_builder.add_node(\"research\", do_research)\n",
    "main_builder.add_node(\"write\", do_writing)\n",
    "main_builder.add_edge(START, \"research\")\n",
    "main_builder.add_edge(\"research\", \"write\")\n",
    "main_builder.add_edge(\"write\", END)\n",
    "\n",
    "main_graph = main_builder.compile()\n",
    "\n",
    "print(\"‚úÖ Main graph with subgraphs compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run composed graph\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ RUNNING COMPOSED WORKFLOW\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "result = main_graph.invoke({\n",
    "    \"topic\": \"AI Agents\",\n",
    "    \"findings\": \"\",\n",
    "    \"draft\": \"\"\n",
    "})\n",
    "\n",
    "print(f\"\\nüìã Final Output:\")\n",
    "print(f\"  Findings: {result['findings']}\")\n",
    "print(f\"  Draft: {result['draft']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Multi-Agent Patterns\n",
    "\n",
    "LangGraph supports various multi-agent coordination patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State for multi-agent system\n",
    "class MultiAgentState(TypedDict):\n",
    "    task: str\n",
    "    researcher_output: str\n",
    "    analyst_output: str\n",
    "    writer_output: str\n",
    "    final_report: str\n",
    "\n",
    "# Agent nodes\n",
    "def researcher_agent(state: MultiAgentState) -> dict:\n",
    "    print(\"üî¨ Researcher: Gathering information...\")\n",
    "    return {\"researcher_output\": f\"Research data on {state['task']}\"}\n",
    "\n",
    "def analyst_agent(state: MultiAgentState) -> dict:\n",
    "    print(\"üìä Analyst: Analyzing data...\")\n",
    "    return {\"analyst_output\": f\"Analysis of {state['researcher_output']}\"}\n",
    "\n",
    "def writer_agent(state: MultiAgentState) -> dict:\n",
    "    print(\"‚úçÔ∏è Writer: Creating report...\")\n",
    "    return {\"writer_output\": f\"Report based on {state['analyst_output']}\"}\n",
    "\n",
    "def supervisor(state: MultiAgentState) -> dict:\n",
    "    print(\"üëî Supervisor: Reviewing and finalizing...\")\n",
    "    return {\"final_report\": f\"Final: {state['writer_output']}\"}\n",
    "\n",
    "print(\"‚úÖ Multi-agent nodes defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build multi-agent graph (pipeline pattern)\n",
    "multi_builder = StateGraph(MultiAgentState)\n",
    "\n",
    "multi_builder.add_node(\"researcher\", researcher_agent)\n",
    "multi_builder.add_node(\"analyst\", analyst_agent)\n",
    "multi_builder.add_node(\"writer\", writer_agent)\n",
    "multi_builder.add_node(\"supervisor\", supervisor)\n",
    "\n",
    "# Pipeline: researcher -> analyst -> writer -> supervisor\n",
    "multi_builder.add_edge(START, \"researcher\")\n",
    "multi_builder.add_edge(\"researcher\", \"analyst\")\n",
    "multi_builder.add_edge(\"analyst\", \"writer\")\n",
    "multi_builder.add_edge(\"writer\", \"supervisor\")\n",
    "multi_builder.add_edge(\"supervisor\", END)\n",
    "\n",
    "multi_agent_graph = multi_builder.compile()\n",
    "\n",
    "print(\"‚úÖ Multi-agent pipeline compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multi-agent workflow\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ RUNNING MULTI-AGENT PIPELINE\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "result = multi_agent_graph.invoke({\n",
    "    \"task\": \"AI Agent Frameworks Comparison\",\n",
    "    \"researcher_output\": \"\",\n",
    "    \"analyst_output\": \"\",\n",
    "    \"writer_output\": \"\",\n",
    "    \"final_report\": \"\"\n",
    "})\n",
    "\n",
    "print(f\"\\nüìã FINAL REPORT:\")\n",
    "print(result[\"final_report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Best Practices & Common Pitfalls\n",
    "\n",
    "### ‚úÖ Best Practices\n",
    "\n",
    "1. **Define clear state schemas** - Use TypedDict with proper types\n",
    "2. **Use reducers for lists** - Annotated with add for accumulation\n",
    "3. **Keep nodes focused** - Single responsibility principle\n",
    "4. **Add checkpointing** - For long-running workflows\n",
    "5. **Test subgraphs independently** - Before composing\n",
    "\n",
    "### ‚ùå Common Pitfalls\n",
    "\n",
    "1. **Forgetting END edges** - Graph won't terminate\n",
    "2. **Missing conditional routes** - Causes runtime errors\n",
    "3. **State mutation** - Always return new state, don't mutate\n",
    "4. **Complex routing logic** - Keep routing functions simple\n",
    "5. **No thread_id for persistence** - Required for checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production-ready graph template\n",
    "\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "def create_production_graph():\n",
    "    \"\"\"Template for a production-ready LangGraph workflow.\"\"\"\n",
    "    \n",
    "    # 1. Define state with proper types and reducers\n",
    "    class ProductionState(TypedDict):\n",
    "        messages: Annotated[list[str], add]\n",
    "        status: str\n",
    "        error: str | None\n",
    "    \n",
    "    # 2. Define nodes with error handling\n",
    "    def process_node(state: ProductionState) -> dict:\n",
    "        try:\n",
    "            # Processing logic\n",
    "            return {\n",
    "                \"messages\": [\"Processed successfully\"],\n",
    "                \"status\": \"completed\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"messages\": [f\"Error: {str(e)}\"],\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    # 3. Build graph\n",
    "    builder = StateGraph(ProductionState)\n",
    "    builder.add_node(\"process\", process_node)\n",
    "    builder.add_edge(START, \"process\")\n",
    "    builder.add_edge(\"process\", END)\n",
    "    \n",
    "    # 4. Add checkpointing\n",
    "    checkpointer = MemorySaver()\n",
    "    \n",
    "    return builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"‚úÖ Production graph template created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Conclusion & Next Steps\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "| Topic | Key Takeaway |\n",
    "|-------|-------------|\n",
    "| StateGraph | Build workflows as graphs |\n",
    "| Nodes & Edges | Define processing and flow |\n",
    "| Conditional Routing | Dynamic path selection |\n",
    "| Checkpointing | Persist state for resumption |\n",
    "| Human-in-the-loop | Interrupt for approval |\n",
    "| Multi-agent | Coordinate multiple agents |\n",
    "\n",
    "### When to Choose LangGraph\n",
    "\n",
    "‚úÖ Choose LangGraph when:\n",
    "- You need explicit control over agent flow\n",
    "- Workflows require cycles or iteration\n",
    "- Human approval is required\n",
    "- Long-running tasks need persistence\n",
    "- Multi-agent coordination is complex\n",
    "\n",
    "‚ùå Consider alternatives when:\n",
    "- Simple single-shot tasks (LangChain)\n",
    "- Autonomous agent conversations (AutoGen)\n",
    "- Role-based agent teams (CrewAI)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Practice**: Build a workflow for your use case\n",
    "2. **Explore**: LangGraph Studio for visualization\n",
    "3. **Deploy**: LangGraph Cloud for production\n",
    "4. **Compare**: See how other frameworks differ\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [LangGraph GitHub](https://github.com/langchain-ai/langgraph)\n",
    "- [LangGraph Studio](https://studio.langchain.com/)\n",
    "- [LangChain Blog](https://blog.langchain.dev/)\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You've completed the LangGraph Zero to Hero guide! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
