{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Introducing Single Agents with LangGraph\n",
        "\n",
        "> **Learning Outcomes:**\n",
        "> - Understand LangGraph's state management with TypedDict\n",
        "> - Build a StateGraph with nodes and edges\n",
        "> - Implement stateful persistence using checkpointers\n",
        "> - Create a conversational agent that maintains context\n",
        "> - Use thread IDs for multi-session conversations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "In this lab, you'll build your first single-agent system using LangGraph. This agent will:\n",
        "\n",
        "- **Remember conversations** across multiple interactions\n",
        "- **Maintain context** using LangGraph's state management\n",
        "- **Persist history** with checkpointers\n",
        "- **Handle multiple users** through thread IDs\n",
        "\n",
        "### What is LangGraph?\n",
        "\n",
        "LangGraph is a framework for building stateful, multi-actor applications with LLMs. It extends LangChain with:\n",
        "\n",
        "1. **StateGraph**: Directed graph of nodes (functions) and edges (control flow)\n",
        "2. **Checkpointing**: Automatic state persistence\n",
        "3. **Streaming**: Real-time output as the graph executes\n",
        "4. **Thread-based sessions**: Isolated conversation histories\n",
        "\n",
        "### The Scenario\n",
        "\n",
        "You'll build a customer support chatbot that:\n",
        "- Answers questions about a fictional product (\"SuperWidget\")\n",
        "- Remembers what the user asked before\n",
        "- Can be reset to start fresh conversations\n",
        "- Supports multiple concurrent users via thread IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-2",
      "metadata": {},
      "source": [
        "## Setup and Installation\n",
        "\n",
        "Install LangGraph 1.0+ and LangChain 1.0+:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cell-3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langgraph langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cell-4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Environment configured\n"
          ]
        }
      ],
      "source": [
        "from typing import Annotated, TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# API key setup\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "print(\"✓ Environment configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-5",
      "metadata": {},
      "source": [
        "## Step 1: Define the Agent's State\n",
        "\n",
        "In LangGraph, **state** is the data that flows through your graph. We use a `TypedDict` to define what data the agent tracks.\n",
        "\n",
        "For a conversational agent, we need:\n",
        "- **messages**: The conversation history\n",
        "\n",
        "The `Annotated[list, add_messages]` tells LangGraph to **append** new messages rather than replacing the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cell-6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ State defined\n",
            "  - messages: list (appends new messages)\n"
          ]
        }
      ],
      "source": [
        "class State(TypedDict):\n",
        "    \"\"\"State for customer support chatbot.\"\"\"\n",
        "    messages: Annotated[list, add_messages]  # Conversation history\n",
        "\n",
        "print(\"✓ State defined\")\n",
        "print(\"  - messages: list (appends new messages)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {},
      "source": [
        "## Step 2: Create the Agent Node\n",
        "\n",
        "A **node** in LangGraph is a Python function that:\n",
        "1. Takes the current state as input\n",
        "2. Does some work (like calling an LLM)\n",
        "3. Returns a dictionary with state updates\n",
        "\n",
        "Our `chatbot` node:\n",
        "- Gets the conversation history from `state[\"messages\"]`\n",
        "- Adds a system prompt about SuperWidget\n",
        "- Calls the LLM\n",
        "- Returns the LLM's response to be added to messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cell-8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Chatbot node created\n",
            "  Model: gpt-4o-mini\n",
            "  System prompt: 633 characters\n"
          ]
        }
      ],
      "source": [
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "\n",
        "# System prompt with product knowledge\n",
        "SYSTEM_PROMPT = \"\"\"You are a helpful customer support agent for SuperWidget, \n",
        "a revolutionary smart home device that controls all your appliances with voice commands.\n",
        "\n",
        "SuperWidget features:\n",
        "- Voice control for lights, thermostats, locks, and appliances\n",
        "- Works with Alexa, Google Assistant, and Siri\n",
        "- Easy 5-minute setup via mobile app\n",
        "- 24/7 customer support\n",
        "- Price: $199\n",
        "\n",
        "Common issues:\n",
        "- \"Can't connect to WiFi\" → Check 2.4GHz network, restart device\n",
        "- \"Voice not recognized\" → Retrain voice profile in app settings\n",
        "- \"Device offline\" → Check power cable and WiFi connection\n",
        "\n",
        "Be friendly, concise, and helpful. Ask clarifying questions if needed.\n",
        "\"\"\"\n",
        "\n",
        "def chatbot(state: State) -> dict:\n",
        "    \"\"\"Customer support chatbot node.\"\"\"\n",
        "    # Build messages with system prompt\n",
        "    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"]\n",
        "    \n",
        "    # Call LLM\n",
        "    response = llm.invoke(messages)\n",
        "    \n",
        "    # Return state update (new message to append)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "print(\"✓ Chatbot node created\")\n",
        "print(f\"  Model: gpt-4o-mini\")\n",
        "print(f\"  System prompt: {len(SYSTEM_PROMPT)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-9",
      "metadata": {},
      "source": [
        "## Step 3: Build the StateGraph\n",
        "\n",
        "Now we create a graph with:\n",
        "1. **One node**: `chatbot` (the function we defined)\n",
        "2. **Two edges**:\n",
        "   - START → chatbot (entry point)\n",
        "   - chatbot → END (exit point)\n",
        "\n",
        "This creates a simple linear flow:\n",
        "```\n",
        "START → chatbot → END\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cell-10",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Graph structure defined\n",
            "  Nodes: chatbot\n",
            "  Flow: START → chatbot → END\n"
          ]
        }
      ],
      "source": [
        "# Create graph\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Add node\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# Add edges\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "print(\"✓ Graph structure defined\")\n",
        "print(\"  Nodes: chatbot\")\n",
        "print(\"  Flow: START → chatbot → END\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-11",
      "metadata": {},
      "source": [
        "## Step 4: Enable Persistence with Checkpointing\n",
        "\n",
        "**Persistence** means the agent remembers previous conversations.\n",
        "\n",
        "We use a **checkpointer** to automatically save state after each execution:\n",
        "- `MemorySaver()`: In-memory storage (for development/testing)\n",
        "- **Production alternatives**: SqliteSaver, PostgresSaver\n",
        "\n",
        "When you compile the graph with a checkpointer, it:\n",
        "1. Saves state after each execution\n",
        "2. Loads previous state when you provide the same `thread_id`\n",
        "3. Enables conversation history across multiple `invoke()` calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cell-12",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Agent compiled with persistence\n",
            "  Checkpointer: MemorySaver (in-memory)\n",
            "  Ready to remember conversations!\n"
          ]
        }
      ],
      "source": [
        "# Create checkpointer\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Compile graph with persistence\n",
        "agent = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "print(\"✓ Agent compiled with persistence\")\n",
        "print(\"  Checkpointer: MemorySaver (in-memory)\")\n",
        "print(\"  Ready to remember conversations!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-13",
      "metadata": {},
      "source": [
        "## Step 5: Test the Agent\n",
        "\n",
        "Let's have a multi-turn conversation to see persistence in action.\n",
        "\n",
        "**Key concept**: `thread_id` identifies the conversation session.\n",
        "- Same `thread_id` = continue existing conversation\n",
        "- Different `thread_id` = start new conversation\n",
        "\n",
        "### Helper Function\n",
        "\n",
        "We'll create a helper to make chatting easier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cell-14",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper function ready\n",
            "  Usage: chat('your message', thread_id='session1')\n"
          ]
        }
      ],
      "source": [
        "def chat(user_message: str, thread_id: str = \"default\") -> str:\n",
        "    \"\"\"\n",
        "    Send a message and get the agent's response.\n",
        "    \n",
        "    Args:\n",
        "        user_message: What the user says\n",
        "        thread_id: Conversation session ID (default: \"default\")\n",
        "    \n",
        "    Returns:\n",
        "        The agent's response text\n",
        "    \"\"\"\n",
        "    # Create config with thread ID\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "    \n",
        "    # Invoke agent with user message\n",
        "    result = agent.invoke(\n",
        "        {\"messages\": [HumanMessage(content=user_message)]},\n",
        "        config\n",
        "    )\n",
        "    \n",
        "    # Return last message (agent's response)\n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "print(\"✓ Helper function ready\")\n",
        "print(\"  Usage: chat('your message', thread_id='session1')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-15",
      "metadata": {},
      "source": [
        "### Test 1: Basic Conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cell-16",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: Hi! What is SuperWidget?\n",
            "Agent: Hi there! SuperWidget is a revolutionary smart home device that allows you to control all your appliances using voice commands. It works seamlessly with Alexa, Google Assistant, and Siri, making it super easy to manage your lights, thermostats, locks, and other devices. The setup process is quick—just five minutes via our mobile app! Plus, we offer 24/7 customer support if you need any assistance. The price is $199. How can I help you today?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Start conversation\n",
        "response1 = chat(\"Hi! What is SuperWidget?\", thread_id=\"user1\")\n",
        "print(f\"User: Hi! What is SuperWidget?\")\n",
        "print(f\"Agent: {response1}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-17",
      "metadata": {},
      "source": [
        "### Test 2: Follow-up Question (Tests Persistence)\n",
        "\n",
        "The agent should remember what \"it\" refers to (SuperWidget):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cell-18",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: How much does it cost?\n",
            "Agent: SuperWidget costs $199. If you have any other questions or need more information, feel free to ask!\n",
            "\n",
            "✓ Agent remembered the conversation context!\n"
          ]
        }
      ],
      "source": [
        "# Follow-up (same thread)\n",
        "response2 = chat(\"How much does it cost?\", thread_id=\"user1\")\n",
        "print(f\"User: How much does it cost?\")\n",
        "print(f\"Agent: {response2}\")\n",
        "print()\n",
        "print(\"✓ Agent remembered the conversation context!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-19",
      "metadata": {},
      "source": [
        "### Test 3: New User (Different Thread)\n",
        "\n",
        "A different `thread_id` starts a fresh conversation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cell-20",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: I can't connect to WiFi. Help!\n",
            "Agent: I’d be happy to help you with that! Here are a few steps you can try:\n",
            "\n",
            "1. **Check your WiFi Network**: Make sure you are connected to a 2.4GHz network, as SuperWidget does not support 5GHz networks.\n",
            "\n",
            "2. **Restart Your Device**: Unplug your SuperWidget, wait for about 10 seconds, and then plug it back in.\n",
            "\n",
            "3. **Reboot Your Router**: Sometimes, restarting your router can help establish a better connection.\n",
            "\n",
            "After trying these steps, let me know if you're still having trouble connecting!\n",
            "\n",
            "✓ New thread = isolated conversation\n"
          ]
        }
      ],
      "source": [
        "# Different user (new thread)\n",
        "response3 = chat(\"I can't connect to WiFi. Help!\", thread_id=\"user2\")\n",
        "print(f\"User: I can't connect to WiFi. Help!\")\n",
        "print(f\"Agent: {response3}\")\n",
        "print()\n",
        "print(\"✓ New thread = isolated conversation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-21",
      "metadata": {},
      "source": [
        "## Step 6: Inspect Conversation State\n",
        "\n",
        "You can view the saved state for any thread:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cell-22",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State for user1:\n",
            "  Total messages: 4\n",
            "\n",
            "Conversation history:\n",
            "  1. User: Hi! What is SuperWidget?\n",
            "  2. Agent: Hi there! SuperWidget is a revolutionary smart home device that allows you to co...\n",
            "  3. User: How much does it cost?\n",
            "  4. Agent: SuperWidget costs $199. If you have any other questions or need more information...\n"
          ]
        }
      ],
      "source": [
        "# Get state for user1's conversation\n",
        "state_user1 = agent.get_state({\"configurable\": {\"thread_id\": \"user1\"}})\n",
        "\n",
        "print(\"State for user1:\")\n",
        "print(f\"  Total messages: {len(state_user1.values['messages'])}\")\n",
        "print(f\"\\nConversation history:\")\n",
        "for i, msg in enumerate(state_user1.values['messages']):\n",
        "    role = \"User\" if isinstance(msg, HumanMessage) else \"Agent\"\n",
        "    content = msg.content[:80] + \"...\" if len(msg.content) > 80 else msg.content\n",
        "    print(f\"  {i+1}. {role}: {content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-23",
      "metadata": {},
      "source": [
        "## Challenge: Add User Preferences\n",
        "\n",
        "**Goal**: Extend the agent to remember user preferences beyond just messages.\n",
        "\n",
        "**Requirements**:\n",
        "1. Add a `user_name` field to the `State` TypedDict\n",
        "2. Create a new node `extract_name` that checks if the user introduced themselves\n",
        "3. If they did, extract and save their name to `state[\"user_name\"]`\n",
        "4. Modify the `chatbot` node to greet users by name if known\n",
        "5. Update the graph flow:\n",
        "   ```\n",
        "   START → extract_name → chatbot → END\n",
        "   ```\n",
        "\n",
        "**Hints**:\n",
        "- Use the LLM to extract names: \"Did the user introduce themselves? If so, what's their name?\"\n",
        "- Check `if state.get(\"user_name\")` to see if name is set\n",
        "- Update system prompt to include: `f\"The user's name is {user_name}\" if user_name else \"\"`\n",
        "\n",
        "**Test**:\n",
        "```python\n",
        "chat(\"Hi, I'm Alice!\", thread_id=\"alice\")\n",
        "chat(\"What's my name?\", thread_id=\"alice\")  # Should remember \"Alice\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cell-24",
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-25",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this lab, you learned how to build a stateful single agent with LangGraph:\n",
        "\n",
        "✅ **State Management** - Used TypedDict with `add_messages` to track conversation history\n",
        "\n",
        "✅ **Nodes** - Created functions that process state and return updates\n",
        "\n",
        "✅ **Edges** - Defined control flow with START → node → END\n",
        "\n",
        "✅ **Persistence** - Enabled checkpointing to remember conversations across sessions\n",
        "\n",
        "✅ **Thread IDs** - Used thread IDs to isolate conversations for different users\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "**StateGraph Workflow**:\n",
        "1. Define state schema (TypedDict)\n",
        "2. Create nodes (functions)\n",
        "3. Build graph (add nodes + edges)\n",
        "4. Compile with checkpointer\n",
        "5. Invoke with config (thread_id)\n",
        "\n",
        "**When to Use Single Agents**:\n",
        "- Simple conversational bots\n",
        "- Customer support with FAQ\n",
        "- Task-specific assistants (scheduling, summarization)\n",
        "- Any scenario where one LLM call per turn is sufficient\n",
        "\n",
        "**Next Steps**:\n",
        "- **Multi-agent systems**: Coordinate multiple specialized agents\n",
        "- **Tool use**: Give agents access to external APIs\n",
        "- **Conditional routing**: Dynamic paths based on state\n",
        "- **Streaming**: Real-time output during execution"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gai-3101",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
